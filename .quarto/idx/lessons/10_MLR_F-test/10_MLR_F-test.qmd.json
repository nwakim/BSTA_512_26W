{"title":"Lesson 10: MLR: Using the F-test","markdown":{"yaml":{"title":"Lesson 10: MLR: Using the F-test","author":"Nicky Wakim","title-slide-attributes":{"data-background-color":"#213c96"},"date":"02/10/2025","categories":["Week 5"],"format":{"revealjs":{"theme":"../simple_NW.scss","chalkboard":true,"slide-number":true,"show-slide-number":"all","width":1955,"height":1100,"footer":"Lesson 10: MLR 2","html-math-method":"mathjax","highlight-style":"ayu"}},"execute":{"echo":true,"freeze":"auto"}},"headingText":"new packages","containsRefs":false,"markdown":"\n\n```{r}\n#| label: \"setup\" \n#| include: false\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(knitr)\nlibrary(broom)\nlibrary(rstatix)\nlibrary(gt)\nlibrary(readxl)\n#----------\n# install.packages(\"describedata\")\nlibrary(describedata) # gladder()\nlibrary(gridExtra)   # grid.arrange()\nlibrary(ggfortify)  # autoplot(model)\n# New Day 6\nlibrary(gtsummary)\n\n# New Day 7\nlibrary(plotly) # for plot_ly() command\nlibrary(GGally) # for ggpairs() command \nlibrary(ggiraphExtra)   # for ggPredict() command\n\n# Load the data - update code if the csv file is not in the same location on your computer\n# If you need to download the file, please go to ur shared folder under Data > Slides\ngapm <- read_excel(\"data/Gapminder_vars_2011.xlsx\", \n                   na = \"NA\")  # important!!!! \n\ngapm_sub <- gapm %>% \n  drop_na(LifeExpectancyYrs, FemaleLiteracyRate, FoodSupplykcPPD)\n\nglimpse(gapm_sub)\n\nmr1 <- lm(LifeExpectancyYrs ~ FemaleLiteracyRate + FoodSupplykcPPD, \n          data = gapm_sub)\n```\n\n# Learning Objectives\n\n1.  Understand the use of the general F-test and interpret what it measures.\n2.  Understand the context of the **Overall F-test**, conduct the needed hypothesis test, and interpret the results.\n3.  Understand the context of the **single covariate/coefficient F-test**, conduct the needed hypothesis test, and interpret the results.\n4.  Understand the context of the **group of covariates/coefficients F-test**, conduct the needed hypothesis test, and interpret the results.\n\n```{css, echo=FALSE}\n.reveal code {\n  max-height: 100% !important;\n}\n```\n\n## Let's map that to our regression analysis process\n\n::: box\n![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"62.1%\" width=\"155\"} ![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"28.4%\" width=\"155\"}![](../img_slides/arrow_back4.png){.absolute top=\"7.5%\" right=\"30.5%\" width=\"820\"} ![](../img_slides/arrow_down.png){.absolute top=\"60.5%\" right=\"48%\" width=\"85\"}\n\n::: columns\n::: {.column width=\"30%\"}\n::: RAP1\n::: RAP1-title\nModel Selection\n:::\n\n::: RAP1-cont\n-   Building a model\n\n-   Selecting variables\n\n-   Prediction vs interpretation\n\n-   Comparing potential models\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP2\n::: RAP2-title\nModel Fitting\n:::\n\n::: RAP2-cont\n-   Find best fit line\n\n-   Using OLS in this class\n\n-   Parameter estimation\n\n-   Categorical covariates\n\n-   Interactions\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP3\n::: RAP3-title\nModel Evaluation\n:::\n\n::: RAP3-cont\n-   Evaluation of model fit\n-   Testing model assumptions\n-   Residuals\n-   Transformations\n-   Influential points\n-   Multicollinearity\n:::\n:::\n:::\n:::\n:::\n\n::: RAP4\n::: RAP4-title\nModel Use (Inference)\n:::\n\n::: RAP4-cont\n::: columns\n::: {.column width=\"50%\"}\n-   Inference for coefficients\n-   Hypothesis testing for coefficients\n:::\n\n::: {.column width=\"50%\"}\n-   Inference for expected $Y$ given $X$\n:::\n:::\n:::\n:::\n\n# Learning Objectives\n\n::: lob\n1.  Understand the use of the general F-test and interpret what it measures.\n:::\n\n2.  Understand the context of the **Overall F-test**, conduct the needed hypothesis test, and interpret the results.\n3.  Understand the context of the **single covariate/coefficient F-test**, conduct the needed hypothesis test, and interpret the results.\n4.  Understand the context of the **group of covariates/coefficients F-test**, conduct the needed hypothesis test, and interpret the results.\n\n## We must revisit our dear friend, the F-test!\n\n![https://www.writerswrite.co.za/foreshadowing/](../img_slides/foreshadowing.jpg){fig-align=\"center\"}\n\n## *Remember from Lesson 5:* F-test vs. t-test for the population slope\n\nThe square of a $t$-distribution with $df = \\nu$ is an $F$-distribution with $df = 1, \\nu$\n\n$$T_{\\nu}^2 \\sim F_{1,\\nu}$$\n\n-   We can use **either F-test** or **t-test** to run the following hypothesis test:\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1 = 0\\\\\n\\text{vs. } H_A&: \\beta_1 \\neq 0\n\\end{align}\n```\n-   Note that the F-test does not support one-sided alternative tests, but the t-test does!\n\n## *Remember from Lesson 5:* Planting a seed about the F-test\n\nWe can think about the hypothesis test for the slope...\n\n::: columns\n::: {.column width=\"17%\"}\n:::\n\n::: {.column width=\"33%\"}\n::: proof1\n::: proof-title\nNull $H_0$\n:::\n\n::: proof-cont\n$\\beta_1=0$\n:::\n:::\n:::\n\n::: {.column width=\"33%\"}\n::: definition\n::: def-title\nAlternative $H_1$\n:::\n\n::: def-cont\n$\\beta_1\\neq0$\n:::\n:::\n:::\n:::\n\nin a slightly different way...\n\n::: columns\n::: {.column width=\"17%\"}\n:::\n\n::: {.column width=\"33%\"}\n::: proof1\n::: proof-title\nNull model ($\\beta_1=0$)\n:::\n\n::: proof-cont\n-   $Y = \\beta_0 + \\epsilon$\n-   Smaller (reduced) model\n:::\n:::\n:::\n\n::: {.column width=\"33%\"}\n::: definition\n::: def-title\nAlternative model ($\\beta_1\\neq0$)\n:::\n\n::: def-cont\n-   $Y = \\beta_0 + \\beta_1 X + \\epsilon$\n-   Larger (full) model\n:::\n:::\n:::\n:::\n\n-   In multiple linear regression, we can start using this framework to test multiple coefficient parameters at once\n\n    -   Decide whether or not to reject the smaller reduced model in favor of the larger full model\n\n    -   Cannot do this with the t-test!\n\n## We can extend this!!\n\nWe can create a hypothesis test for more than one coefficient at a time...\n\n::: columns\n::: {.column width=\"17%\"}\n:::\n\n::: {.column width=\"33%\"}\n::: proof1\n::: proof-title\nNull $H_0$\n:::\n\n::: proof-cont\n$\\beta_1=\\beta_2=0$\n:::\n:::\n:::\n\n::: {.column width=\"33%\"}\n::: definition\n::: def-title\nAlternative $H_1$\n:::\n\n::: def-cont\n$\\beta_1\\neq0$ and/or $\\beta_2\\neq0$\n:::\n:::\n:::\n:::\n\nin a slightly different way...\n\n::: columns\n::: {.column width=\"17%\"}\n:::\n\n::: {.column width=\"33%\"}\n::: proof1\n::: proof-title\nNull model\n:::\n\n::: proof-cont\n-   $Y = \\beta_0 + \\epsilon$\n-   Smaller (reduced) model\n:::\n:::\n:::\n\n::: {.column width=\"33%\"}\n::: definition\n::: def-title\nAlternative\\* model\n:::\n\n::: def-cont\n-   $Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon$\n-   Larger (full) model\n:::\n:::\n:::\n:::\n\n\\*This is **not quite** the alternative, but if we reject the null, then this is the model we move forward with\n\n## Poll Everywhere Question 1\n\n## Building a very important toolkit: three types of tests\n\n::: fact\n::: fact-title\nOverall test\n:::\n\n::: fact-cont\nDoes at least one of the covariates/predictors contribute significantly to the prediction of Y?\n:::\n:::\n\n::: example\n::: ex-title\nTest for addition of a single variable's coefficient (covariate subset test)\n:::\n\n::: ex-cont\nDoes the addition of one particular covariate (with a single coefficient) add significantly to the prediction of Y achieved by other covariates already present in the model?\n:::\n:::\n\n::: proposition\n::: prop-title\nTest for addition of group of variables' coefficient (covariate subset test)\n:::\n\n::: prop-cont\nDoes the addition of some group of covariates (or one covariate with multiple coefficients) add significantly to the prediction of Y achieved by other covariates already present in the model?\n:::\n:::\n\n## Variation: Explained vs. Unexplained\n\n$$\\begin{aligned}\n\\sum_{i=1}^n (Y_i - \\overline{Y})^2 &= \\sum_{i=1}^n (\\widehat{Y}_i- \\overline{Y})^2 + \\sum_{i=1}^n (Y_i - \\widehat{Y}_i)^2 \\\\\nSSY &= SSR + SSE\n\\end{aligned}$$\n\n-   $Y_i - \\overline{Y}$ = the deviation of $Y_i$ around the mean $\\overline{Y}$\n    -   the **total** amount deviation\n-   $\\widehat{Y}_i- \\overline{Y}$ = the deviation of the fitted value $\\widehat{Y}_i$ around the mean $\\overline{Y}$\n    -   the amount deviation **explained** by the regression at $X_{i1},\\ldots,X_{ik}$\n-   $Y_i - \\widehat{Y}_i$ = the deviation of the observation $Y$ around the fitted regression line\n    -   the amount deviation **unexplained** by the regression at $X_{i1},\\ldots,X_{ik}$\n\n\n\n\n## *SLR*: Another way to think of SSY, SSR, and SSE {visibility=\"hidden\"}\n\n-   Let's create a data frame of each component within the SS's\n\n    -   Deviation in SSY: $Y_i - \\overline{Y}$\n    -   Deviation in SSR: $\\widehat{Y}_i- \\overline{Y}$\n    -   Deviation in SSE: $Y_i - \\widehat{Y}_i$\n\n-   Using our simple linear regression model as an example:\n\n```{r}\nslr1 <- gapm_sub %>% \n  lm(formula = LifeExpectancyYrs ~ FemaleLiteracyRate)\naug_slr1 = augment(slr1)\nSS_dev_slr = gapm_sub %>% select(LifeExpectancyYrs) %>%\n  mutate(SSY_dev = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         y_hat = aug_slr1$.fitted, \n         SSR_dev = y_hat - mean(LifeExpectancyYrs), \n         SSE_dev = aug_slr1$.resid)\n```\n\n## Plot histogram of deviations for $LE = \\beta_0 + \\beta_1 FLR + \\epsilon$\n\n```{r}\n#| eval: false\n#| code-fold: true\n#| code-summary: \"Code to make the below plots\"\n\nSSY_plot = ggplot(SS_dev_slr, aes(SSY_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y)))\nSSR_plot = ggplot(SS_dev_slr, aes(SSR_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y)))\nSSE_plot = ggplot(SS_dev_slr, aes(SSE_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i]))\ngrid.arrange(SSY_plot, SSR_plot, SSE_plot, nrow = 3)\n```\n\n::: columns\n::: column\n```{r}\n#| fig-align: right\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_slr = ggplot(SS_dev_slr, aes(SSY_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot_slr = ggplot(SS_dev_slr, aes(SSR_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot_slr = ggplot(SS_dev_slr, aes(SSE_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot_slr, SSR_plot_slr, SSE_plot_slr, nrow = 3)\n```\n:::\n\n::: column\n$$SSY = \\sum_{i=1}^n (Y_i - \\overline{Y})^2 = `r round(var(SS_dev_slr$SSY_dev), 2)`$$ \n\n \n\n$$SSR = \\sum_{i=1}^n (\\widehat{Y}_i- \\overline{Y})^2 = `r round(var(SS_dev_slr$SSR_dev), 2)`$$\n\n \n\n$$SSE =\\sum_{i=1}^n (Y_i - \\widehat{Y}_i)^2 = `r round(var(SS_dev_slr$SSE_dev), 2)`$$\n:::\n:::\n\n## *MLR:* Another way to think of SSY, SSR, and SSE {visibility=\"hidden\"}\n\n-   Let's create a data frame of each component within the SS's\n\n    -   Deviation in SSY: $Y_i - \\overline{Y}$\n    -   Deviation in SSR: $\\widehat{Y}_i- \\overline{Y}$\n    -   Deviation in SSE: $Y_i - \\widehat{Y}_i$\n\n-   Using our simple linear regression model as an example:\n\n```{r}\nmr1 <- gapm_sub %>% \n  lm(formula = LifeExpectancyYrs ~ FemaleLiteracyRate + FoodSupplykcPPD)\naug_mlr1 = augment(mr1)\nSS_df = gapm_sub %>% select(LifeExpectancyYrs) %>%\n  mutate(SSY_dev = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         y_hat = aug_mlr1$.fitted, \n         SSR_dev = y_hat - mean(LifeExpectancyYrs), \n         SSE_dev = aug_mlr1$.resid)\n```\n\n## Plot histogram of deviations for $LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\epsilon$\n\n```{r}\n#| eval: false\n#| code-fold: true\n#| code-summary: \"Code to make the below plots\"\n\nSSY_plot = ggplot(SS_df, aes(SSY_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y)))\nSSR_plot = ggplot(SS_df, aes(SSR_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y)))\nSSE_plot = ggplot(SS_df, aes(SSE_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i]))\ngrid.arrange(SSY_plot, SSR_plot, SSE_plot, nrow = 3)\n```\n\n::: columns\n::: column\n```{r}\n#| fig-align: right\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot = ggplot(SS_df, aes(SSY_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot = ggplot(SS_df, aes(SSR_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot = ggplot(SS_df, aes(SSE_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot, SSR_plot, SSE_plot, nrow = 3)\n```\n:::\n\n::: column\n$$SSY = \\sum_{i=1}^n (Y_i - \\overline{Y})^2 = `r round(var(SS_df$SSY_dev), 2)`$$ \n\n \n\n$$SSR = \\sum_{i=1}^n (\\widehat{Y}_i- \\overline{Y})^2 = `r round(var(SS_df$SSR_dev), 2)`$$\n\n \n\n$$SSE =\\sum_{i=1}^n (Y_i - \\widehat{Y}_i)^2 = `r round(var(SS_df$SSE_dev), 2)`$$\n:::\n:::\n\n## What did you notice in the plots?\n\n::: columns\n::: {.column width=\"50%\"}\n::: L1\nSimple Linear Regression\n:::\n:::\n::: {.column width=\"50%\"}\n::: E1\nMultiple Linear Regression\n:::\n:::\n:::\n\n::: columns\n::: {.column width=\"35%\"}\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\ngrid.arrange(SSY_plot_slr, SSR_plot_slr, SSE_plot_slr, nrow = 3)\n```\n:::\n\n::: {.column width=\"15%\"}\n$$SSY = `r round(var(SS_dev_slr$SSY_dev), 2)`$$ \n\n \n\n \n\n$$SSR = `r round(var(SS_dev_slr$SSR_dev), 2)`$$\n\n \n\n \n\n$$SSE =`r round(var(SS_dev_slr$SSE_dev), 2)`$$\n:::\n\n::: {.column width=\"35%\"}\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\ngrid.arrange(SSY_plot, SSR_plot, SSE_plot, nrow = 3)\n```\n:::\n::: {.column width=\"15%\"}\n$$SSY = `r round(var(SS_df$SSY_dev), 2)`$$ \n\n \n\n \n\n$$SSR = `r round(var(SS_df$SSR_dev), 2)`$$\n\n \n\n \n\n$$SSE =`r round(var(SS_df$SSE_dev), 2)`$$\n:::\n:::\n\n## When running a F-test for linear models...\n\n-   We need to define a larger, full model (more parameters)\n-   We need to define a smaller, reduced model (fewer parameters)\n-   Use the F-statistic to decide whether or not we reject the smaller model\n    -   The F-statistic compares the SSE of each model to determine if the full model explains a significant amount of additional variance\n\n::: columns\n::: {.column width=\"30%\"}\n \n\n$$\nF = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}}\n$$\n:::\n\n::: {.column width=\"70%\"}\n-   $SSE(R) \\geq SSE(F)$\n-   Numerator measures difference in **unexplained** variation between the models\n    -   Big difference = added parameters greatly reduce the unexplained variation (increase explained variation)\n    -   Smaller difference = added parameters don't reduce the unexplained variation\n-   Take ratio of difference to the unexplained variation in the full model\n:::\n:::\n\n## Poll Everywhere Question 2\n\n## We will keep working with the MLR model from last class\n\nNew population model for example:\n\n$$\\text{LE} = \\beta_0 + \\beta_1 \\text{FLR} + \\beta_2 \\text{FS} + \\epsilon$$\n\n```{r}\n# Fit regression model:\nmr1 <- gapm_sub %>% \n  lm(formula = LifeExpectancyYrs ~ FemaleLiteracyRate + FoodSupplykcPPD)\ntidy(mr1, conf.int=T) %>% gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n```{r}\n#| echo: false\n\nmr1_tidy = tidy(mr1, conf.int=T)\n```\n\nFitted multiple regression model:\n\n$$\\begin{aligned}\n\\widehat{\\text{LE}} &= \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\text{FLR} + \\widehat{\\beta}_2 \\text{FS} \\\\\n\\widehat{\\text{LE}} &= `r round(mr1_tidy$estimate[1], 3)` + `r round(mr1_tidy$estimate[2], 3)` \\ \\text{FLR} \n+ `r round(mr1_tidy$estimate[3], 3)`\\ \\text{FS}\n\\end{aligned}$$\n\n# Learning Objectives\n\n1.  Understand the use of the general F-test and interpret what it measures.\n\n::: lob\n2.  Understand the context of the **Overall F-test**, conduct the needed hypothesis test, and interpret the results.\n:::\n\n3.  Understand the context of the **single covariate/coefficient F-test**, conduct the needed hypothesis test, and interpret the results.\n4.  Understand the context of the **group of covariates/coefficients F-test**, conduct the needed hypothesis test, and interpret the results.\n\n## Overall F-test\n\nDoes at least one of the covariates/predictors contribute significantly to the prediction of Y?\n\n-   For a general population MLR model, $$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2+ \\ldots + \\beta_k X_k + \\epsilon$$\n\nWe can create a hypothesis test for all the covariate coefficients...\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull $H_0$\n:::\n\n::: proof-cont\n$\\beta_1=\\beta_2= \\ldots=\\beta_k=0$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative $H_1$\n:::\n\n::: def-cont\nAt least one $\\beta_j\\neq0$ (for $j=1, 2, \\ldots, k$)\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n:::\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull / Smaller / Reduced model\n:::\n\n::: proof-cont\n$Y = \\beta_0 + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative / Larger / Full model\n:::\n\n::: def-cont\n$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_k X_k + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n:::\n\n## Overall F-test: general steps for hypothesis test\n\n::: columns\n::: {.column width=\"48%\"}\n::: highlight-container\n::: highlight\n1.  Met underlying LINE assumptions\n:::\n:::\n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis\n:::\n:::\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1=\\beta_2= \\ldots=\\beta_k=0\\\\\n\\text{vs. } H_A&: \\text{At least one } \\beta_j\\neq0, \\text{for }j=1, 2, \\ldots, k\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level.\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $F$, and follows an F-distribution with numerator $df=k$ and denominator $df=n-k-1$. ($n$ = \\# obversation, $k$ = \\# covariates)\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic\n:::\n:::\n\nThe calculated **test statistic** is\n\n$$F^ = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}} = \\frac{MSR_{full}}{MSE_{full}}$$\n\n::: highlight-container\n::: highlight\n6.  Calculate the p-value\n:::\n:::\n\nWe are generally calculating: $P(F_{k, n-k-1} > F)$\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for hypothesis test\n:::\n:::\n\n-   Reject if: $P(F_{k, n-k-1} > F) < \\alpha$\n\nWe (reject/fail to reject) the null hypothesis at the $100\\alpha\\%$ significance level. There is (sufficient/insufficient) evidence that at least one predictor's coefficient is not 0 (p-value = $P(F_{1, n-2} > F)$).\n:::\n:::\n\n## Overall F-test: a word on the conclusion\n\n-   If $H_0$ is rejected, we conclude there is sufficient evidence that at least one predictor's coefficient is different from zero.\n-   Same as: at least one independent variable contributes significantly to the prediction of $Y$\n\n \n\n-   If $H_0$ is not rejected, we conclude there is insufficient evidence that at least one predictor's coefficient is different from zero.\n-   Same as: Not enough evidence that at least one independent variable contributes significantly to the prediction of $Y$\n\n## Let's think about our MLR example for life expectancy\n\nOur proposed population model\n\n$$\\text{LE} = \\beta_0 + \\beta_1 \\text{FLR} + \\beta_2 \\text{FS} + \\epsilon$$\n\nFitted multiple regression model:\n\n$$\\begin{aligned}\n\\widehat{\\text{LE}} &= \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\text{FLR} + \\widehat{\\beta}_2 \\text{FS} \\\\\n\\widehat{\\text{LE}} &= 33.595 + 0.157\\ \\text{FLR} \n+ 0.008\\ \\text{FS}\n\\end{aligned}$$\n\n**Our main question for the Overall F-test:** Is the regression model containing female literacy rate and food supply useful in estimating countries' life expectancy?\n\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull / Smaller / Reduced model\n:::\n\n::: proof-cont\n$LE = \\beta_0 + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative / Larger / Full model\n:::\n\n::: def-cont\n$LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\epsilon$\n:::\n:::\n:::\n:::\n\n## Comparing the SSY, SSR, and SSE for reduced and full model\n\n- Fit and get augmented values for reduced model:\n```{r}\nmod_red1 = gapm_sub %>% \n  lm(formula = LifeExpectancyYrs ~ 1)\naug_red1  = augment(mod_red1)\n```\n\n- Fit and get augmented values for full model:\n```{r}\nmod_full1 = gapm_sub %>% \n  lm(formula = LifeExpectancyYrs ~ FemaleLiteracyRate + FoodSupplykcPPD)\naug_full1  = augment(mod_full1)\n```\n\n- Calculate the deviances for each model:\n```{r}\nSS_df2 = gapm_sub %>% select(LifeExpectancyYrs) %>%\n  mutate(SSY_diff_r1 = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         SSR_diff_r1 = aug_red1$.fitted - mean(LifeExpectancyYrs), \n         SSE_diff_r1 = aug_red1$.resid, \n         SSY_diff_f1 = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         SSR_diff_f1 = aug_full1$.fitted - mean(LifeExpectancyYrs), \n         SSE_diff_f1 = aug_full1$.resid)\n```\n\n## Comparing the SSY, SSR, and SSE for reduced and full model\n\n::: columns\n::: column\n::: I1\nReduced / null model\n:::\n\n$$LE = \\beta_0 + \\epsilon$$\n\n::: columns\n::: column\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_r1 = ggplot(SS_df2, aes(SSY_diff_r1)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot_r1 = ggplot(SS_df2, aes(SSR_diff_r1)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot_r1 = ggplot(SS_df2, aes(SSE_diff_r1)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot_r1, SSR_plot_r1, SSE_plot_r1, nrow = 3)\n```\n:::\n\n::: {.column width=\"30%\"}\n$$SSY = `r round(var(SS_df2$SSY_diff_r1), 2)`$$ \n\n \n\n$$SSR = `r round(var(SS_df2$SSR_diff_r1), 2)`$$\n\n \n\n$$SSE = `r round(var(SS_df2$SSE_diff_r1), 2)`$$\n:::\n\n:::\n\n:::\n\n::: column\n::: L1\nFull / Alternative model\n:::\n\n$$LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\epsilon$$\n\n::: columns\n::: column\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_f1 = ggplot(SS_df2, aes(SSY_diff_f1)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) \nSSR_plot_f1 = ggplot(SS_df2, aes(SSR_diff_f1)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) \nSSE_plot_f1 = ggplot(SS_df2, aes(SSE_diff_f1)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) \ngrid.arrange(SSY_plot_f1, SSR_plot_f1, SSE_plot_f1, nrow = 3)\n```\n:::\n\n::: {.column width=\"30%\"}\n$$SSY = `r round(var(SS_df2$SSY_diff_f1), 2)`$$ \n\n \n\n$$SSR = `r round(var(SS_df2$SSR_diff_f1), 2)`$$\n\n \n\n$$SSE = `r round(var(SS_df2$SSE_diff_f1), 2)`$$\n:::\n\n:::\n\n:::\n:::\n\n## Poll Everywhere Question 3\n\n\n\n## So let's step through our hypothesis test (1/3)\n\n::: highlight-container\n::: highlight\n1.  Met underlying LINE assumptions\n:::\n:::\n\n \n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis\n:::\n:::\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1=\\beta_2=0\\\\\n\\text{vs. } H_A&: \\text{At least one } \\beta_1\\neq0 \\text{ or } \\beta_2\\neq0\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $F$, and follows an F-distribution with numerator $df=k =2$ and denominator $df=n-k-1 = 72 - 2-1=69$. ($n$ = \\# obversation, $k$ = \\# covariates)\n\n## So let's step through our hypothesis test (2/3)\n\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic / 6.  Calculate the p-value\n:::\n:::\n\nThe calculated **test statistic** is\n\n$$F^ = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}}=44.443$$\nOR use ANOVA table:\n\n```{r}\nanova(mod_red1, mod_full1) %>% tidy() %>% gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n## So let's step through our hypothesis test (3/3)\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for hypothesis test\n:::\n:::\n\n \n\nWe reject the null hypothesis at the 5% significance level. There is sufficient evidence that either countries' female literacy rate or the food supply (or both) contributes significantly to the prediction of life expectancy (p-value < 0.001).\n\n# Learning Objectives\n\n1.  Understand the use of the general F-test and interpret what it measures.\n2.  Understand the context of the **Overall F-test**, conduct the needed hypothesis test, and interpret the results.\n\n::: lob\n3.  Understand the context of the **single covariate/coefficient F-test**, conduct the needed hypothesis test, and interpret the results.\n:::\n\n4.  Understand the context of the **group of covariates/coefficients F-test**, conduct the needed hypothesis test, and interpret the results.\n\n## Covariate subset test: Single variable\n\nDoes the addition of one particular covariate of interest (a numeric covariate with only one coefficient) add significantly to the prediction of Y achieved by other covariates already present in the model?\n\n-   For a general population MLR model, $$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2+ \\beta_j X_j +\\ldots + \\beta_k X_k + \\epsilon$$\n\nWe can create a hypothesis test for a single $j$ covariate coefficient (where $j$ can be any value $1, 2, \\ldots, k$)...\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull $H_0$\n:::\n\n::: proof-cont\n$\\beta_j=0$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative $H_1$\n:::\n\n::: def-cont\n$\\beta_j\\neq0$\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n:::\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull / Smaller / Reduced model\n:::\n\n::: proof-cont\n$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_k X_k + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative / Larger / Full model\n:::\n\n::: def-cont\n$\\begin{aligned}Y = &\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_j X_j +\\\\ &\\ldots + \\beta_k X_k + \\epsilon \\end{aligned}$\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n:::\n\n## Single covariate F-test: general steps for hypothesis test (reference)\n\n::: columns\n::: {.column width=\"48%\"}\n::: highlight-container\n::: highlight\n1.  Met underlying LINE assumptions\n:::\n:::\n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis\n:::\n:::\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_j=0\\\\\n\\text{vs. } H_A&: \\beta_j\\neq 0\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $F$, and follows an F-distribution with numerator $df=k$ and denominator $df=n-k-1$. ($n$ = \\# obversation, $k$ = \\# covariates)\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic\n:::\n:::\n\nThe calculated **test statistic** is\n\n$$F^ = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}}$$\n\n::: highlight-container\n::: highlight\n6.  Calculate the p-value\n:::\n:::\n\nWe are generally calculating: $P(F_{k, n-k-1} > F)$\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for hypothesis test\n:::\n:::\n\nWe (reject/fail to reject) the null hypothesis at the $100\\alpha\\%$ significance level. There is (sufficient/insufficient) evidence that predictor/covariate $j$ significantly improves the prediction of Y, given all the other covariates are in the model (p-value = $P(F_{1, n-2} > F)$).\n:::\n:::\n\n## Let's think about our MLR example for life expectancy\n\nOur proposed population model\n\n$$\\text{LE} = \\beta_0 + \\beta_1 \\text{FLR} + \\beta_2 \\text{FS} + \\epsilon$$\n\nFitted multiple regression model:\n\n$$\\begin{aligned}\n\\widehat{\\text{LE}} &= \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\text{FLR} + \\widehat{\\beta}_2 \\text{FS} \\\\\n\\widehat{\\text{LE}} &= 33.595 + 0.157\\ \\text{FLR} \n+ 0.008\\ \\text{FS}\n\\end{aligned}$$\n\n**Our main question for the single covariate subset F-test:** Is the regression model containing food supply improve the estimation of countries' life expectancy, given female literacy rate is already in the model?\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull / Smaller / Reduced model\n:::\n\n::: proof-cont\n$LE = \\beta_0 + \\beta_1 FLR + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative / Larger / Full model\n:::\n\n::: def-cont\n$LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\epsilon$\n:::\n:::\n:::\n:::\n\n## Comparing the SSY, SSR, and SSE for reduced and full model\n\n```{r}\n#| echo: false\nmod_red2 = lm(LifeExpectancyYrs ~ FemaleLiteracyRate, data = gapm_sub)\naug_red2  = augment(mod_red2)\n\nmod_full2 = lm(LifeExpectancyYrs ~ FemaleLiteracyRate + FoodSupplykcPPD,\n               data = gapm_sub)\naug_full2  = augment(mod_full2)\n\nSS_df2 = gapm_sub %>% select(LifeExpectancyYrs) %>%\n  mutate(SSY_diff_r2 = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         SSR_diff_r2 = aug_red2$.fitted - mean(LifeExpectancyYrs), \n         SSE_diff_r2 = aug_red2$.resid, \n         SSY_diff_f2 = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         SSR_diff_f2 = aug_full2$.fitted - mean(LifeExpectancyYrs), \n         SSE_diff_f2 = aug_full2$.resid)\n```\n\n::: columns\n::: column\n**Reduced / null model** $$LE = \\beta_0 + \\beta_1 FLR + \\epsilon$$\n\n::: columns\n::: column\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_r2 = ggplot(SS_df2, aes(SSY_diff_r2)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot_r2 = ggplot(SS_df2, aes(SSR_diff_r2)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot_r2 = ggplot(SS_df2, aes(SSE_diff_r2)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot_r2, SSR_plot_r2, SSE_plot_r2, nrow = 3)\n```\n:::\n\n::: {.column width=\"30%\"}\n$$SSY = `r round(var(SS_df2$SSY_diff_r2), 2)`$$ \n\n \n\n$$SSR = `r round(var(SS_df2$SSR_diff_r2), 2)`$$\n\n \n\n$$SSE = `r round(var(SS_df2$SSE_diff_r2), 2)`$$\n:::\n\n:::\n\n:::\n\n::: column\n**Full / Alternative model** $$LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\epsilon$$\n\n::: columns\n::: column\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_f2 = ggplot(SS_df2, aes(SSY_diff_f2)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot_f2 = ggplot(SS_df2, aes(SSR_diff_f2)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot_f2 = ggplot(SS_df2, aes(SSE_diff_f2)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot_f2, SSR_plot_f2, SSE_plot_f2, nrow = 3)\n```\n:::\n\n::: {.column width=\"30%\"}\n$$SSY = `r round(var(SS_df2$SSY_diff_f2), 2)`$$ \n\n \n\n$$SSR = `r round(var(SS_df2$SSR_diff_f2), 2)`$$\n\n \n\n$$SSE = `r round(var(SS_df2$SSE_diff_f2), 2)`$$\n:::\n\n:::\n\n:::\n:::\n\n## Poll Everywhere Question 4\n\n## So let's step through our hypothesis test (1/3)\n\n::: highlight-container\n::: highlight\n1.  Met underlying LINE assumptions\n:::\n:::\n\n \n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis\n:::\n:::\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_2=0\\\\\n\\text{vs. } H_A&: \\beta_2\\neq0 \n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $F$, and follows an F-distribution with numerator $df=k =2$ and denominator $df=n-k-1 = 72 - 2-1=69$. ($n$ = \\# obversation, $k$ = \\# covariates)\n\n## So let's step through our hypothesis test (2/3)\n\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic / 6.  Calculate the p-value\n:::\n:::\n\nThe calculated **test statistic** is\n\n$$F^ = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}}$$\nANOVA table:\n\n```{r}\nanova(mod_red2, mod_full2) %>% tidy() %>% gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n## So let's step through our hypothesis test (3/3)\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for hypothesis test\n:::\n:::\n\n \n\nWe reject the null hypothesis at the 5% significance level. There is sufficient evidence that countries' food supply contributes significantly to the prediction of life expectancy, given that female literacy rate is already in the model (p-value < 0.001).\n\n# Learning Objectives\n\n1.  Understand the use of the general F-test and interpret what it measures.\n2.  Understand the context of the **Overall F-test**, conduct the needed hypothesis test, and interpret the results.\n3.  Understand the context of the **single covariate/coefficient F-test**, conduct the needed hypothesis test, and interpret the results.\n\n::: lob\n4.  Understand the context of the **group of covariates/coefficients F-test**, conduct the needed hypothesis test, and interpret the results.\n:::\n\n## Covariate subset test: group of coefficients\n\nDoes the addition of some group of covariates of interest (or a multi-level categorical variable) add significantly to the prediction of Y obtained through other independent variables already present in the model?\n\n-   For a general population MLR model, $$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2+ \\ldots + \\beta_k X_k + \\epsilon$$\n\nWe can create a hypothesis test for a group of covariate coefficients (subset of many)... **For example...**\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull $H_0$\n:::\n\n::: proof-cont\n$\\beta_1=\\beta_3 =0$ (this can be any coefficients)\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative $H_1$\n:::\n\n::: def-cont\nAt least one $\\beta_j\\neq0$ (for $j=2,3$)\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n:::\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull / Smaller / Reduced model\n:::\n\n::: proof-cont\n$Y = \\beta_0 + \\beta_2 X_2 + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative / Larger / Full model\n:::\n\n::: def-cont\n$Y = \\beta_0 + \\beta_1 X + \\beta_2 X + \\beta_3 X_3+\\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n:::\n\n## Covariate subset F-test: general steps for hypothesis test (reference)\n\n::: columns\n::: {.column width=\"48%\"}\n::: highlight-container\n::: highlight\n1.  Met underlying LINE assumptions\n:::\n:::\n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis\n:::\n:::\n\nFor example: \n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1 = \\beta_3 = 0\\\\\n\\text{vs. } H_A&: \\text{At least one } \\beta_j\\neq0, \\text{for }j=1,3\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $F$, and follows an F-distribution with numerator $df=k$ and denominator $df=n-k-1$. ($n$ = \\# obversation, $k$ = \\# covariates)\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic\n:::\n:::\n\nThe calculated **test statistic** is\n\n$$F^ = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}}$$\n\n::: highlight-container\n::: highlight\n6.  Calculate the p-value\n:::\n:::\n\nWe are generally calculating: $P(F_{k, n-k-1} > F)$\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for hypothesis test\n:::\n:::\n\nWe (reject/fail to reject) the null hypothesis at the $100\\alpha\\%$ significance level. There is (sufficient/insufficient) evidence that predictors/covariates $2,3$ significantly improve the prediction of Y, given all the other covariates are in the model (p-value = $P(F_{1, n-2} > F)$).\n:::\n:::\n\n## We need to slightly alter our MLR example for life expectancy\n\nOur proposed population model to include water source percent (WS):\n\n$$\\text{LE} = \\beta_0 + \\beta_1 \\text{FLR} + \\beta_2 \\text{FS} + \\beta_3 WS + \\epsilon$$\n\n-   We don't have a fitted multiple regression model for this yet!\n\n**Our main question for the group covariate subset F-test:** Is the regression model containing food supply and water source percent improve the estimation of countries' life expectancy, given percent female literacy rate is already in the model?\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull / Smaller / Reduced model\n:::\n\n::: proof-cont\n$LE = \\beta_0 + \\beta_1 FLR + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative / Larger / Full model\n:::\n\n::: def-cont\n$LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\beta_3 WS + \\epsilon$\n:::\n:::\n:::\n:::\n\n## Comparing the SSY, SSR, and SSE for reduced and full model\n\n```{r}\n#| echo: false\n\ngapm_sub2 = gapm %>%\n  drop_na(LifeExpectancyYrs, FemaleLiteracyRate, \n          FoodSupplykcPPD, WaterSourcePrct)\nmod_red3 = lm(LifeExpectancyYrs ~ FemaleLiteracyRate, data = gapm_sub2)\naug_red3  = augment(mod_red3)\n\nmod_full3 = lm(LifeExpectancyYrs ~ FemaleLiteracyRate + FoodSupplykcPPD + WaterSourcePrct,\n               data = gapm_sub2)\naug_full3  = augment(mod_full3)\n\nSS_df3 = gapm_sub2 %>% select(LifeExpectancyYrs) %>%\n  mutate(SSY_diff_r3 = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         SSR_diff_r3 = aug_red3$.fitted - mean(LifeExpectancyYrs), \n         SSE_diff_r3 = aug_red3$.resid, \n         SSY_diff_f3 = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         SSR_diff_f3 = aug_full3$.fitted - mean(LifeExpectancyYrs), \n         SSE_diff_f3 = aug_full3$.resid)\n```\n\n::: columns\n::: column\n**Reduced / null model** $$LE = \\beta_0 + \\beta_1 FLR + \\epsilon$$\n\n::: columns\n::: column\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_r3 = ggplot(SS_df3, aes(SSY_diff_r3)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot_r3 = ggplot(SS_df3, aes(SSR_diff_r3)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot_r3 = ggplot(SS_df3, aes(SSE_diff_r3)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot_r3, SSR_plot_r3, SSE_plot_r3, nrow = 3)\n```\n:::\n\n::: {.column width=\"30%\"}\n$$SSY = `r round(var(SS_df3$SSY_diff_r3), 2)`$$ \n\n \n\n$$SSR = `r round(var(SS_df3$SSR_diff_r3), 2)`$$\n\n \n\n$$SSE = `r round(var(SS_df3$SSE_diff_r3), 2)`$$\n:::\n\n:::\n\n:::\n\n::: column\n**Full / Alternative model** $$LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\beta_3 WS + \\epsilon$$\n\n::: columns\n::: column\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_f3 = ggplot(SS_df3, aes(SSY_diff_f3)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot_f3 = ggplot(SS_df3, aes(SSR_diff_f3)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot_f3 = ggplot(SS_df3, aes(SSE_diff_f3)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot_f3, SSR_plot_f3, SSE_plot_f3, nrow = 3)\n```\n:::\n\n::: {.column width=\"30%\"}\n$$SSY = `r round(var(SS_df3$SSY_diff_f3), 2)`$$ \n\n \n\n$$SSR = `r round(var(SS_df3$SSR_diff_f3), 2)`$$\n\n \n\n$$SSE = `r round(var(SS_df3$SSE_diff_f3), 2)`$$\n:::\n\n:::\n\n:::\n:::\n\n## So let's step through our hypothesis test (1/3)\n\n::: highlight-container\n::: highlight\n1.  Met underlying LINE assumptions\n:::\n:::\n\n \n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis\n:::\n:::\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_2=\\beta_3=0\\\\\n\\text{vs. } H_A&: \\beta_2\\neq0 \\text{ and/or } \\beta_3\\neq0\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $F$, and follows an F-distribution with numerator $df=k =2$ and denominator $df=n-k-1 = 72 - 2-1=69$. ($n$ = \\# obversation, $k$ = \\# covariates)\n\n## So let's step through our hypothesis test (2/3)\n\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic / 6.  Calculate the p-value\n:::\n:::\n\nThe calculated **test statistic** is\n\n$$F^ = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}}$$\nANOVA table:\n\n```{r}\nanova(mod_red3, mod_full3) %>% tidy() %>% gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n## So let's step through our hypothesis test (3/3)\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for hypothesis test\n:::\n:::\n\n \n\nWe reject the null hypothesis at the 5% significance level. There is sufficient evidence that countries' food supply or water source (or both) contribute significantly to the prediction of life expectancy, given that female literacy rate is already in the model (p-value < 0.001).\n\n## Other ways to word the hypothesis tests (reference)\n\n-   Single covariate subset F-test\n\n    -   $H_0:$ $X^*$ does not significantly improve the prediction of $Y$, given that $X_1, X_2, \\ldots, X_p$ are already in the model\n    -   $H_A:$ $X^*$ significantly improves the prediction of $Y$, given that $X_1, X_2, \\ldots, X_p$ are already in the model\n    \n-   Group covariate subset F-test\n\n    -   $H_0:$ The addition of the $s$ variables $X_1^*, X_2^*, \\ldots, X_s^*$ does not significantly improve the prediction of $Y$, given that $X_1, X_2, \\ldots, X_q$ are already in the model\n    -   $H_A:$ The addition of the $s$ variables $X_1^*, X_2^*, \\ldots, X_s^*$ significantly improves the prediction of $Y$, given that $X_1, X_2, \\ldots, X_q$ are already in the model","srcMarkdownNoYaml":"\n\n```{r}\n#| label: \"setup\" \n#| include: false\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(knitr)\nlibrary(broom)\nlibrary(rstatix)\nlibrary(gt)\nlibrary(readxl)\n#----------\n# new packages\n# install.packages(\"describedata\")\nlibrary(describedata) # gladder()\nlibrary(gridExtra)   # grid.arrange()\nlibrary(ggfortify)  # autoplot(model)\n# New Day 6\nlibrary(gtsummary)\n\n# New Day 7\nlibrary(plotly) # for plot_ly() command\nlibrary(GGally) # for ggpairs() command \nlibrary(ggiraphExtra)   # for ggPredict() command\n\n# Load the data - update code if the csv file is not in the same location on your computer\n# If you need to download the file, please go to ur shared folder under Data > Slides\ngapm <- read_excel(\"data/Gapminder_vars_2011.xlsx\", \n                   na = \"NA\")  # important!!!! \n\ngapm_sub <- gapm %>% \n  drop_na(LifeExpectancyYrs, FemaleLiteracyRate, FoodSupplykcPPD)\n\nglimpse(gapm_sub)\n\nmr1 <- lm(LifeExpectancyYrs ~ FemaleLiteracyRate + FoodSupplykcPPD, \n          data = gapm_sub)\n```\n\n# Learning Objectives\n\n1.  Understand the use of the general F-test and interpret what it measures.\n2.  Understand the context of the **Overall F-test**, conduct the needed hypothesis test, and interpret the results.\n3.  Understand the context of the **single covariate/coefficient F-test**, conduct the needed hypothesis test, and interpret the results.\n4.  Understand the context of the **group of covariates/coefficients F-test**, conduct the needed hypothesis test, and interpret the results.\n\n```{css, echo=FALSE}\n.reveal code {\n  max-height: 100% !important;\n}\n```\n\n## Let's map that to our regression analysis process\n\n::: box\n![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"62.1%\" width=\"155\"} ![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"28.4%\" width=\"155\"}![](../img_slides/arrow_back4.png){.absolute top=\"7.5%\" right=\"30.5%\" width=\"820\"} ![](../img_slides/arrow_down.png){.absolute top=\"60.5%\" right=\"48%\" width=\"85\"}\n\n::: columns\n::: {.column width=\"30%\"}\n::: RAP1\n::: RAP1-title\nModel Selection\n:::\n\n::: RAP1-cont\n-   Building a model\n\n-   Selecting variables\n\n-   Prediction vs interpretation\n\n-   Comparing potential models\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP2\n::: RAP2-title\nModel Fitting\n:::\n\n::: RAP2-cont\n-   Find best fit line\n\n-   Using OLS in this class\n\n-   Parameter estimation\n\n-   Categorical covariates\n\n-   Interactions\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP3\n::: RAP3-title\nModel Evaluation\n:::\n\n::: RAP3-cont\n-   Evaluation of model fit\n-   Testing model assumptions\n-   Residuals\n-   Transformations\n-   Influential points\n-   Multicollinearity\n:::\n:::\n:::\n:::\n:::\n\n::: RAP4\n::: RAP4-title\nModel Use (Inference)\n:::\n\n::: RAP4-cont\n::: columns\n::: {.column width=\"50%\"}\n-   Inference for coefficients\n-   Hypothesis testing for coefficients\n:::\n\n::: {.column width=\"50%\"}\n-   Inference for expected $Y$ given $X$\n:::\n:::\n:::\n:::\n\n# Learning Objectives\n\n::: lob\n1.  Understand the use of the general F-test and interpret what it measures.\n:::\n\n2.  Understand the context of the **Overall F-test**, conduct the needed hypothesis test, and interpret the results.\n3.  Understand the context of the **single covariate/coefficient F-test**, conduct the needed hypothesis test, and interpret the results.\n4.  Understand the context of the **group of covariates/coefficients F-test**, conduct the needed hypothesis test, and interpret the results.\n\n## We must revisit our dear friend, the F-test!\n\n![https://www.writerswrite.co.za/foreshadowing/](../img_slides/foreshadowing.jpg){fig-align=\"center\"}\n\n## *Remember from Lesson 5:* F-test vs. t-test for the population slope\n\nThe square of a $t$-distribution with $df = \\nu$ is an $F$-distribution with $df = 1, \\nu$\n\n$$T_{\\nu}^2 \\sim F_{1,\\nu}$$\n\n-   We can use **either F-test** or **t-test** to run the following hypothesis test:\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1 = 0\\\\\n\\text{vs. } H_A&: \\beta_1 \\neq 0\n\\end{align}\n```\n-   Note that the F-test does not support one-sided alternative tests, but the t-test does!\n\n## *Remember from Lesson 5:* Planting a seed about the F-test\n\nWe can think about the hypothesis test for the slope...\n\n::: columns\n::: {.column width=\"17%\"}\n:::\n\n::: {.column width=\"33%\"}\n::: proof1\n::: proof-title\nNull $H_0$\n:::\n\n::: proof-cont\n$\\beta_1=0$\n:::\n:::\n:::\n\n::: {.column width=\"33%\"}\n::: definition\n::: def-title\nAlternative $H_1$\n:::\n\n::: def-cont\n$\\beta_1\\neq0$\n:::\n:::\n:::\n:::\n\nin a slightly different way...\n\n::: columns\n::: {.column width=\"17%\"}\n:::\n\n::: {.column width=\"33%\"}\n::: proof1\n::: proof-title\nNull model ($\\beta_1=0$)\n:::\n\n::: proof-cont\n-   $Y = \\beta_0 + \\epsilon$\n-   Smaller (reduced) model\n:::\n:::\n:::\n\n::: {.column width=\"33%\"}\n::: definition\n::: def-title\nAlternative model ($\\beta_1\\neq0$)\n:::\n\n::: def-cont\n-   $Y = \\beta_0 + \\beta_1 X + \\epsilon$\n-   Larger (full) model\n:::\n:::\n:::\n:::\n\n-   In multiple linear regression, we can start using this framework to test multiple coefficient parameters at once\n\n    -   Decide whether or not to reject the smaller reduced model in favor of the larger full model\n\n    -   Cannot do this with the t-test!\n\n## We can extend this!!\n\nWe can create a hypothesis test for more than one coefficient at a time...\n\n::: columns\n::: {.column width=\"17%\"}\n:::\n\n::: {.column width=\"33%\"}\n::: proof1\n::: proof-title\nNull $H_0$\n:::\n\n::: proof-cont\n$\\beta_1=\\beta_2=0$\n:::\n:::\n:::\n\n::: {.column width=\"33%\"}\n::: definition\n::: def-title\nAlternative $H_1$\n:::\n\n::: def-cont\n$\\beta_1\\neq0$ and/or $\\beta_2\\neq0$\n:::\n:::\n:::\n:::\n\nin a slightly different way...\n\n::: columns\n::: {.column width=\"17%\"}\n:::\n\n::: {.column width=\"33%\"}\n::: proof1\n::: proof-title\nNull model\n:::\n\n::: proof-cont\n-   $Y = \\beta_0 + \\epsilon$\n-   Smaller (reduced) model\n:::\n:::\n:::\n\n::: {.column width=\"33%\"}\n::: definition\n::: def-title\nAlternative\\* model\n:::\n\n::: def-cont\n-   $Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon$\n-   Larger (full) model\n:::\n:::\n:::\n:::\n\n\\*This is **not quite** the alternative, but if we reject the null, then this is the model we move forward with\n\n## Poll Everywhere Question 1\n\n## Building a very important toolkit: three types of tests\n\n::: fact\n::: fact-title\nOverall test\n:::\n\n::: fact-cont\nDoes at least one of the covariates/predictors contribute significantly to the prediction of Y?\n:::\n:::\n\n::: example\n::: ex-title\nTest for addition of a single variable's coefficient (covariate subset test)\n:::\n\n::: ex-cont\nDoes the addition of one particular covariate (with a single coefficient) add significantly to the prediction of Y achieved by other covariates already present in the model?\n:::\n:::\n\n::: proposition\n::: prop-title\nTest for addition of group of variables' coefficient (covariate subset test)\n:::\n\n::: prop-cont\nDoes the addition of some group of covariates (or one covariate with multiple coefficients) add significantly to the prediction of Y achieved by other covariates already present in the model?\n:::\n:::\n\n## Variation: Explained vs. Unexplained\n\n$$\\begin{aligned}\n\\sum_{i=1}^n (Y_i - \\overline{Y})^2 &= \\sum_{i=1}^n (\\widehat{Y}_i- \\overline{Y})^2 + \\sum_{i=1}^n (Y_i - \\widehat{Y}_i)^2 \\\\\nSSY &= SSR + SSE\n\\end{aligned}$$\n\n-   $Y_i - \\overline{Y}$ = the deviation of $Y_i$ around the mean $\\overline{Y}$\n    -   the **total** amount deviation\n-   $\\widehat{Y}_i- \\overline{Y}$ = the deviation of the fitted value $\\widehat{Y}_i$ around the mean $\\overline{Y}$\n    -   the amount deviation **explained** by the regression at $X_{i1},\\ldots,X_{ik}$\n-   $Y_i - \\widehat{Y}_i$ = the deviation of the observation $Y$ around the fitted regression line\n    -   the amount deviation **unexplained** by the regression at $X_{i1},\\ldots,X_{ik}$\n\n\n\n\n## *SLR*: Another way to think of SSY, SSR, and SSE {visibility=\"hidden\"}\n\n-   Let's create a data frame of each component within the SS's\n\n    -   Deviation in SSY: $Y_i - \\overline{Y}$\n    -   Deviation in SSR: $\\widehat{Y}_i- \\overline{Y}$\n    -   Deviation in SSE: $Y_i - \\widehat{Y}_i$\n\n-   Using our simple linear regression model as an example:\n\n```{r}\nslr1 <- gapm_sub %>% \n  lm(formula = LifeExpectancyYrs ~ FemaleLiteracyRate)\naug_slr1 = augment(slr1)\nSS_dev_slr = gapm_sub %>% select(LifeExpectancyYrs) %>%\n  mutate(SSY_dev = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         y_hat = aug_slr1$.fitted, \n         SSR_dev = y_hat - mean(LifeExpectancyYrs), \n         SSE_dev = aug_slr1$.resid)\n```\n\n## Plot histogram of deviations for $LE = \\beta_0 + \\beta_1 FLR + \\epsilon$\n\n```{r}\n#| eval: false\n#| code-fold: true\n#| code-summary: \"Code to make the below plots\"\n\nSSY_plot = ggplot(SS_dev_slr, aes(SSY_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y)))\nSSR_plot = ggplot(SS_dev_slr, aes(SSR_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y)))\nSSE_plot = ggplot(SS_dev_slr, aes(SSE_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i]))\ngrid.arrange(SSY_plot, SSR_plot, SSE_plot, nrow = 3)\n```\n\n::: columns\n::: column\n```{r}\n#| fig-align: right\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_slr = ggplot(SS_dev_slr, aes(SSY_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot_slr = ggplot(SS_dev_slr, aes(SSR_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot_slr = ggplot(SS_dev_slr, aes(SSE_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot_slr, SSR_plot_slr, SSE_plot_slr, nrow = 3)\n```\n:::\n\n::: column\n$$SSY = \\sum_{i=1}^n (Y_i - \\overline{Y})^2 = `r round(var(SS_dev_slr$SSY_dev), 2)`$$ \n\n \n\n$$SSR = \\sum_{i=1}^n (\\widehat{Y}_i- \\overline{Y})^2 = `r round(var(SS_dev_slr$SSR_dev), 2)`$$\n\n \n\n$$SSE =\\sum_{i=1}^n (Y_i - \\widehat{Y}_i)^2 = `r round(var(SS_dev_slr$SSE_dev), 2)`$$\n:::\n:::\n\n## *MLR:* Another way to think of SSY, SSR, and SSE {visibility=\"hidden\"}\n\n-   Let's create a data frame of each component within the SS's\n\n    -   Deviation in SSY: $Y_i - \\overline{Y}$\n    -   Deviation in SSR: $\\widehat{Y}_i- \\overline{Y}$\n    -   Deviation in SSE: $Y_i - \\widehat{Y}_i$\n\n-   Using our simple linear regression model as an example:\n\n```{r}\nmr1 <- gapm_sub %>% \n  lm(formula = LifeExpectancyYrs ~ FemaleLiteracyRate + FoodSupplykcPPD)\naug_mlr1 = augment(mr1)\nSS_df = gapm_sub %>% select(LifeExpectancyYrs) %>%\n  mutate(SSY_dev = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         y_hat = aug_mlr1$.fitted, \n         SSR_dev = y_hat - mean(LifeExpectancyYrs), \n         SSE_dev = aug_mlr1$.resid)\n```\n\n## Plot histogram of deviations for $LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\epsilon$\n\n```{r}\n#| eval: false\n#| code-fold: true\n#| code-summary: \"Code to make the below plots\"\n\nSSY_plot = ggplot(SS_df, aes(SSY_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y)))\nSSR_plot = ggplot(SS_df, aes(SSR_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y)))\nSSE_plot = ggplot(SS_df, aes(SSE_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i]))\ngrid.arrange(SSY_plot, SSR_plot, SSE_plot, nrow = 3)\n```\n\n::: columns\n::: column\n```{r}\n#| fig-align: right\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot = ggplot(SS_df, aes(SSY_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot = ggplot(SS_df, aes(SSR_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot = ggplot(SS_df, aes(SSE_dev)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot, SSR_plot, SSE_plot, nrow = 3)\n```\n:::\n\n::: column\n$$SSY = \\sum_{i=1}^n (Y_i - \\overline{Y})^2 = `r round(var(SS_df$SSY_dev), 2)`$$ \n\n \n\n$$SSR = \\sum_{i=1}^n (\\widehat{Y}_i- \\overline{Y})^2 = `r round(var(SS_df$SSR_dev), 2)`$$\n\n \n\n$$SSE =\\sum_{i=1}^n (Y_i - \\widehat{Y}_i)^2 = `r round(var(SS_df$SSE_dev), 2)`$$\n:::\n:::\n\n## What did you notice in the plots?\n\n::: columns\n::: {.column width=\"50%\"}\n::: L1\nSimple Linear Regression\n:::\n:::\n::: {.column width=\"50%\"}\n::: E1\nMultiple Linear Regression\n:::\n:::\n:::\n\n::: columns\n::: {.column width=\"35%\"}\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\ngrid.arrange(SSY_plot_slr, SSR_plot_slr, SSE_plot_slr, nrow = 3)\n```\n:::\n\n::: {.column width=\"15%\"}\n$$SSY = `r round(var(SS_dev_slr$SSY_dev), 2)`$$ \n\n \n\n \n\n$$SSR = `r round(var(SS_dev_slr$SSR_dev), 2)`$$\n\n \n\n \n\n$$SSE =`r round(var(SS_dev_slr$SSE_dev), 2)`$$\n:::\n\n::: {.column width=\"35%\"}\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\ngrid.arrange(SSY_plot, SSR_plot, SSE_plot, nrow = 3)\n```\n:::\n::: {.column width=\"15%\"}\n$$SSY = `r round(var(SS_df$SSY_dev), 2)`$$ \n\n \n\n \n\n$$SSR = `r round(var(SS_df$SSR_dev), 2)`$$\n\n \n\n \n\n$$SSE =`r round(var(SS_df$SSE_dev), 2)`$$\n:::\n:::\n\n## When running a F-test for linear models...\n\n-   We need to define a larger, full model (more parameters)\n-   We need to define a smaller, reduced model (fewer parameters)\n-   Use the F-statistic to decide whether or not we reject the smaller model\n    -   The F-statistic compares the SSE of each model to determine if the full model explains a significant amount of additional variance\n\n::: columns\n::: {.column width=\"30%\"}\n \n\n$$\nF = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}}\n$$\n:::\n\n::: {.column width=\"70%\"}\n-   $SSE(R) \\geq SSE(F)$\n-   Numerator measures difference in **unexplained** variation between the models\n    -   Big difference = added parameters greatly reduce the unexplained variation (increase explained variation)\n    -   Smaller difference = added parameters don't reduce the unexplained variation\n-   Take ratio of difference to the unexplained variation in the full model\n:::\n:::\n\n## Poll Everywhere Question 2\n\n## We will keep working with the MLR model from last class\n\nNew population model for example:\n\n$$\\text{LE} = \\beta_0 + \\beta_1 \\text{FLR} + \\beta_2 \\text{FS} + \\epsilon$$\n\n```{r}\n# Fit regression model:\nmr1 <- gapm_sub %>% \n  lm(formula = LifeExpectancyYrs ~ FemaleLiteracyRate + FoodSupplykcPPD)\ntidy(mr1, conf.int=T) %>% gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n```{r}\n#| echo: false\n\nmr1_tidy = tidy(mr1, conf.int=T)\n```\n\nFitted multiple regression model:\n\n$$\\begin{aligned}\n\\widehat{\\text{LE}} &= \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\text{FLR} + \\widehat{\\beta}_2 \\text{FS} \\\\\n\\widehat{\\text{LE}} &= `r round(mr1_tidy$estimate[1], 3)` + `r round(mr1_tidy$estimate[2], 3)` \\ \\text{FLR} \n+ `r round(mr1_tidy$estimate[3], 3)`\\ \\text{FS}\n\\end{aligned}$$\n\n# Learning Objectives\n\n1.  Understand the use of the general F-test and interpret what it measures.\n\n::: lob\n2.  Understand the context of the **Overall F-test**, conduct the needed hypothesis test, and interpret the results.\n:::\n\n3.  Understand the context of the **single covariate/coefficient F-test**, conduct the needed hypothesis test, and interpret the results.\n4.  Understand the context of the **group of covariates/coefficients F-test**, conduct the needed hypothesis test, and interpret the results.\n\n## Overall F-test\n\nDoes at least one of the covariates/predictors contribute significantly to the prediction of Y?\n\n-   For a general population MLR model, $$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2+ \\ldots + \\beta_k X_k + \\epsilon$$\n\nWe can create a hypothesis test for all the covariate coefficients...\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull $H_0$\n:::\n\n::: proof-cont\n$\\beta_1=\\beta_2= \\ldots=\\beta_k=0$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative $H_1$\n:::\n\n::: def-cont\nAt least one $\\beta_j\\neq0$ (for $j=1, 2, \\ldots, k$)\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n:::\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull / Smaller / Reduced model\n:::\n\n::: proof-cont\n$Y = \\beta_0 + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative / Larger / Full model\n:::\n\n::: def-cont\n$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_k X_k + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n:::\n\n## Overall F-test: general steps for hypothesis test\n\n::: columns\n::: {.column width=\"48%\"}\n::: highlight-container\n::: highlight\n1.  Met underlying LINE assumptions\n:::\n:::\n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis\n:::\n:::\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1=\\beta_2= \\ldots=\\beta_k=0\\\\\n\\text{vs. } H_A&: \\text{At least one } \\beta_j\\neq0, \\text{for }j=1, 2, \\ldots, k\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level.\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $F$, and follows an F-distribution with numerator $df=k$ and denominator $df=n-k-1$. ($n$ = \\# obversation, $k$ = \\# covariates)\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic\n:::\n:::\n\nThe calculated **test statistic** is\n\n$$F^ = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}} = \\frac{MSR_{full}}{MSE_{full}}$$\n\n::: highlight-container\n::: highlight\n6.  Calculate the p-value\n:::\n:::\n\nWe are generally calculating: $P(F_{k, n-k-1} > F)$\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for hypothesis test\n:::\n:::\n\n-   Reject if: $P(F_{k, n-k-1} > F) < \\alpha$\n\nWe (reject/fail to reject) the null hypothesis at the $100\\alpha\\%$ significance level. There is (sufficient/insufficient) evidence that at least one predictor's coefficient is not 0 (p-value = $P(F_{1, n-2} > F)$).\n:::\n:::\n\n## Overall F-test: a word on the conclusion\n\n-   If $H_0$ is rejected, we conclude there is sufficient evidence that at least one predictor's coefficient is different from zero.\n-   Same as: at least one independent variable contributes significantly to the prediction of $Y$\n\n \n\n-   If $H_0$ is not rejected, we conclude there is insufficient evidence that at least one predictor's coefficient is different from zero.\n-   Same as: Not enough evidence that at least one independent variable contributes significantly to the prediction of $Y$\n\n## Let's think about our MLR example for life expectancy\n\nOur proposed population model\n\n$$\\text{LE} = \\beta_0 + \\beta_1 \\text{FLR} + \\beta_2 \\text{FS} + \\epsilon$$\n\nFitted multiple regression model:\n\n$$\\begin{aligned}\n\\widehat{\\text{LE}} &= \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\text{FLR} + \\widehat{\\beta}_2 \\text{FS} \\\\\n\\widehat{\\text{LE}} &= 33.595 + 0.157\\ \\text{FLR} \n+ 0.008\\ \\text{FS}\n\\end{aligned}$$\n\n**Our main question for the Overall F-test:** Is the regression model containing female literacy rate and food supply useful in estimating countries' life expectancy?\n\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull / Smaller / Reduced model\n:::\n\n::: proof-cont\n$LE = \\beta_0 + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative / Larger / Full model\n:::\n\n::: def-cont\n$LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\epsilon$\n:::\n:::\n:::\n:::\n\n## Comparing the SSY, SSR, and SSE for reduced and full model\n\n- Fit and get augmented values for reduced model:\n```{r}\nmod_red1 = gapm_sub %>% \n  lm(formula = LifeExpectancyYrs ~ 1)\naug_red1  = augment(mod_red1)\n```\n\n- Fit and get augmented values for full model:\n```{r}\nmod_full1 = gapm_sub %>% \n  lm(formula = LifeExpectancyYrs ~ FemaleLiteracyRate + FoodSupplykcPPD)\naug_full1  = augment(mod_full1)\n```\n\n- Calculate the deviances for each model:\n```{r}\nSS_df2 = gapm_sub %>% select(LifeExpectancyYrs) %>%\n  mutate(SSY_diff_r1 = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         SSR_diff_r1 = aug_red1$.fitted - mean(LifeExpectancyYrs), \n         SSE_diff_r1 = aug_red1$.resid, \n         SSY_diff_f1 = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         SSR_diff_f1 = aug_full1$.fitted - mean(LifeExpectancyYrs), \n         SSE_diff_f1 = aug_full1$.resid)\n```\n\n## Comparing the SSY, SSR, and SSE for reduced and full model\n\n::: columns\n::: column\n::: I1\nReduced / null model\n:::\n\n$$LE = \\beta_0 + \\epsilon$$\n\n::: columns\n::: column\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_r1 = ggplot(SS_df2, aes(SSY_diff_r1)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot_r1 = ggplot(SS_df2, aes(SSR_diff_r1)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot_r1 = ggplot(SS_df2, aes(SSE_diff_r1)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot_r1, SSR_plot_r1, SSE_plot_r1, nrow = 3)\n```\n:::\n\n::: {.column width=\"30%\"}\n$$SSY = `r round(var(SS_df2$SSY_diff_r1), 2)`$$ \n\n \n\n$$SSR = `r round(var(SS_df2$SSR_diff_r1), 2)`$$\n\n \n\n$$SSE = `r round(var(SS_df2$SSE_diff_r1), 2)`$$\n:::\n\n:::\n\n:::\n\n::: column\n::: L1\nFull / Alternative model\n:::\n\n$$LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\epsilon$$\n\n::: columns\n::: column\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_f1 = ggplot(SS_df2, aes(SSY_diff_f1)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) \nSSR_plot_f1 = ggplot(SS_df2, aes(SSR_diff_f1)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) \nSSE_plot_f1 = ggplot(SS_df2, aes(SSE_diff_f1)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) \ngrid.arrange(SSY_plot_f1, SSR_plot_f1, SSE_plot_f1, nrow = 3)\n```\n:::\n\n::: {.column width=\"30%\"}\n$$SSY = `r round(var(SS_df2$SSY_diff_f1), 2)`$$ \n\n \n\n$$SSR = `r round(var(SS_df2$SSR_diff_f1), 2)`$$\n\n \n\n$$SSE = `r round(var(SS_df2$SSE_diff_f1), 2)`$$\n:::\n\n:::\n\n:::\n:::\n\n## Poll Everywhere Question 3\n\n\n\n## So let's step through our hypothesis test (1/3)\n\n::: highlight-container\n::: highlight\n1.  Met underlying LINE assumptions\n:::\n:::\n\n \n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis\n:::\n:::\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1=\\beta_2=0\\\\\n\\text{vs. } H_A&: \\text{At least one } \\beta_1\\neq0 \\text{ or } \\beta_2\\neq0\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $F$, and follows an F-distribution with numerator $df=k =2$ and denominator $df=n-k-1 = 72 - 2-1=69$. ($n$ = \\# obversation, $k$ = \\# covariates)\n\n## So let's step through our hypothesis test (2/3)\n\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic / 6.  Calculate the p-value\n:::\n:::\n\nThe calculated **test statistic** is\n\n$$F^ = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}}=44.443$$\nOR use ANOVA table:\n\n```{r}\nanova(mod_red1, mod_full1) %>% tidy() %>% gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n## So let's step through our hypothesis test (3/3)\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for hypothesis test\n:::\n:::\n\n \n\nWe reject the null hypothesis at the 5% significance level. There is sufficient evidence that either countries' female literacy rate or the food supply (or both) contributes significantly to the prediction of life expectancy (p-value < 0.001).\n\n# Learning Objectives\n\n1.  Understand the use of the general F-test and interpret what it measures.\n2.  Understand the context of the **Overall F-test**, conduct the needed hypothesis test, and interpret the results.\n\n::: lob\n3.  Understand the context of the **single covariate/coefficient F-test**, conduct the needed hypothesis test, and interpret the results.\n:::\n\n4.  Understand the context of the **group of covariates/coefficients F-test**, conduct the needed hypothesis test, and interpret the results.\n\n## Covariate subset test: Single variable\n\nDoes the addition of one particular covariate of interest (a numeric covariate with only one coefficient) add significantly to the prediction of Y achieved by other covariates already present in the model?\n\n-   For a general population MLR model, $$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2+ \\beta_j X_j +\\ldots + \\beta_k X_k + \\epsilon$$\n\nWe can create a hypothesis test for a single $j$ covariate coefficient (where $j$ can be any value $1, 2, \\ldots, k$)...\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull $H_0$\n:::\n\n::: proof-cont\n$\\beta_j=0$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative $H_1$\n:::\n\n::: def-cont\n$\\beta_j\\neq0$\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n:::\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull / Smaller / Reduced model\n:::\n\n::: proof-cont\n$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\ldots + \\beta_k X_k + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative / Larger / Full model\n:::\n\n::: def-cont\n$\\begin{aligned}Y = &\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_j X_j +\\\\ &\\ldots + \\beta_k X_k + \\epsilon \\end{aligned}$\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n:::\n\n## Single covariate F-test: general steps for hypothesis test (reference)\n\n::: columns\n::: {.column width=\"48%\"}\n::: highlight-container\n::: highlight\n1.  Met underlying LINE assumptions\n:::\n:::\n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis\n:::\n:::\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_j=0\\\\\n\\text{vs. } H_A&: \\beta_j\\neq 0\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $F$, and follows an F-distribution with numerator $df=k$ and denominator $df=n-k-1$. ($n$ = \\# obversation, $k$ = \\# covariates)\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic\n:::\n:::\n\nThe calculated **test statistic** is\n\n$$F^ = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}}$$\n\n::: highlight-container\n::: highlight\n6.  Calculate the p-value\n:::\n:::\n\nWe are generally calculating: $P(F_{k, n-k-1} > F)$\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for hypothesis test\n:::\n:::\n\nWe (reject/fail to reject) the null hypothesis at the $100\\alpha\\%$ significance level. There is (sufficient/insufficient) evidence that predictor/covariate $j$ significantly improves the prediction of Y, given all the other covariates are in the model (p-value = $P(F_{1, n-2} > F)$).\n:::\n:::\n\n## Let's think about our MLR example for life expectancy\n\nOur proposed population model\n\n$$\\text{LE} = \\beta_0 + \\beta_1 \\text{FLR} + \\beta_2 \\text{FS} + \\epsilon$$\n\nFitted multiple regression model:\n\n$$\\begin{aligned}\n\\widehat{\\text{LE}} &= \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\text{FLR} + \\widehat{\\beta}_2 \\text{FS} \\\\\n\\widehat{\\text{LE}} &= 33.595 + 0.157\\ \\text{FLR} \n+ 0.008\\ \\text{FS}\n\\end{aligned}$$\n\n**Our main question for the single covariate subset F-test:** Is the regression model containing food supply improve the estimation of countries' life expectancy, given female literacy rate is already in the model?\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull / Smaller / Reduced model\n:::\n\n::: proof-cont\n$LE = \\beta_0 + \\beta_1 FLR + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative / Larger / Full model\n:::\n\n::: def-cont\n$LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\epsilon$\n:::\n:::\n:::\n:::\n\n## Comparing the SSY, SSR, and SSE for reduced and full model\n\n```{r}\n#| echo: false\nmod_red2 = lm(LifeExpectancyYrs ~ FemaleLiteracyRate, data = gapm_sub)\naug_red2  = augment(mod_red2)\n\nmod_full2 = lm(LifeExpectancyYrs ~ FemaleLiteracyRate + FoodSupplykcPPD,\n               data = gapm_sub)\naug_full2  = augment(mod_full2)\n\nSS_df2 = gapm_sub %>% select(LifeExpectancyYrs) %>%\n  mutate(SSY_diff_r2 = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         SSR_diff_r2 = aug_red2$.fitted - mean(LifeExpectancyYrs), \n         SSE_diff_r2 = aug_red2$.resid, \n         SSY_diff_f2 = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         SSR_diff_f2 = aug_full2$.fitted - mean(LifeExpectancyYrs), \n         SSE_diff_f2 = aug_full2$.resid)\n```\n\n::: columns\n::: column\n**Reduced / null model** $$LE = \\beta_0 + \\beta_1 FLR + \\epsilon$$\n\n::: columns\n::: column\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_r2 = ggplot(SS_df2, aes(SSY_diff_r2)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot_r2 = ggplot(SS_df2, aes(SSR_diff_r2)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot_r2 = ggplot(SS_df2, aes(SSE_diff_r2)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot_r2, SSR_plot_r2, SSE_plot_r2, nrow = 3)\n```\n:::\n\n::: {.column width=\"30%\"}\n$$SSY = `r round(var(SS_df2$SSY_diff_r2), 2)`$$ \n\n \n\n$$SSR = `r round(var(SS_df2$SSR_diff_r2), 2)`$$\n\n \n\n$$SSE = `r round(var(SS_df2$SSE_diff_r2), 2)`$$\n:::\n\n:::\n\n:::\n\n::: column\n**Full / Alternative model** $$LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\epsilon$$\n\n::: columns\n::: column\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_f2 = ggplot(SS_df2, aes(SSY_diff_f2)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot_f2 = ggplot(SS_df2, aes(SSR_diff_f2)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot_f2 = ggplot(SS_df2, aes(SSE_diff_f2)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot_f2, SSR_plot_f2, SSE_plot_f2, nrow = 3)\n```\n:::\n\n::: {.column width=\"30%\"}\n$$SSY = `r round(var(SS_df2$SSY_diff_f2), 2)`$$ \n\n \n\n$$SSR = `r round(var(SS_df2$SSR_diff_f2), 2)`$$\n\n \n\n$$SSE = `r round(var(SS_df2$SSE_diff_f2), 2)`$$\n:::\n\n:::\n\n:::\n:::\n\n## Poll Everywhere Question 4\n\n## So let's step through our hypothesis test (1/3)\n\n::: highlight-container\n::: highlight\n1.  Met underlying LINE assumptions\n:::\n:::\n\n \n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis\n:::\n:::\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_2=0\\\\\n\\text{vs. } H_A&: \\beta_2\\neq0 \n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $F$, and follows an F-distribution with numerator $df=k =2$ and denominator $df=n-k-1 = 72 - 2-1=69$. ($n$ = \\# obversation, $k$ = \\# covariates)\n\n## So let's step through our hypothesis test (2/3)\n\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic / 6.  Calculate the p-value\n:::\n:::\n\nThe calculated **test statistic** is\n\n$$F^ = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}}$$\nANOVA table:\n\n```{r}\nanova(mod_red2, mod_full2) %>% tidy() %>% gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n## So let's step through our hypothesis test (3/3)\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for hypothesis test\n:::\n:::\n\n \n\nWe reject the null hypothesis at the 5% significance level. There is sufficient evidence that countries' food supply contributes significantly to the prediction of life expectancy, given that female literacy rate is already in the model (p-value < 0.001).\n\n# Learning Objectives\n\n1.  Understand the use of the general F-test and interpret what it measures.\n2.  Understand the context of the **Overall F-test**, conduct the needed hypothesis test, and interpret the results.\n3.  Understand the context of the **single covariate/coefficient F-test**, conduct the needed hypothesis test, and interpret the results.\n\n::: lob\n4.  Understand the context of the **group of covariates/coefficients F-test**, conduct the needed hypothesis test, and interpret the results.\n:::\n\n## Covariate subset test: group of coefficients\n\nDoes the addition of some group of covariates of interest (or a multi-level categorical variable) add significantly to the prediction of Y obtained through other independent variables already present in the model?\n\n-   For a general population MLR model, $$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2+ \\ldots + \\beta_k X_k + \\epsilon$$\n\nWe can create a hypothesis test for a group of covariate coefficients (subset of many)... **For example...**\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull $H_0$\n:::\n\n::: proof-cont\n$\\beta_1=\\beta_3 =0$ (this can be any coefficients)\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative $H_1$\n:::\n\n::: def-cont\nAt least one $\\beta_j\\neq0$ (for $j=2,3$)\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n:::\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull / Smaller / Reduced model\n:::\n\n::: proof-cont\n$Y = \\beta_0 + \\beta_2 X_2 + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative / Larger / Full model\n:::\n\n::: def-cont\n$Y = \\beta_0 + \\beta_1 X + \\beta_2 X + \\beta_3 X_3+\\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n:::\n\n## Covariate subset F-test: general steps for hypothesis test (reference)\n\n::: columns\n::: {.column width=\"48%\"}\n::: highlight-container\n::: highlight\n1.  Met underlying LINE assumptions\n:::\n:::\n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis\n:::\n:::\n\nFor example: \n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1 = \\beta_3 = 0\\\\\n\\text{vs. } H_A&: \\text{At least one } \\beta_j\\neq0, \\text{for }j=1,3\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $F$, and follows an F-distribution with numerator $df=k$ and denominator $df=n-k-1$. ($n$ = \\# obversation, $k$ = \\# covariates)\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic\n:::\n:::\n\nThe calculated **test statistic** is\n\n$$F^ = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}}$$\n\n::: highlight-container\n::: highlight\n6.  Calculate the p-value\n:::\n:::\n\nWe are generally calculating: $P(F_{k, n-k-1} > F)$\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for hypothesis test\n:::\n:::\n\nWe (reject/fail to reject) the null hypothesis at the $100\\alpha\\%$ significance level. There is (sufficient/insufficient) evidence that predictors/covariates $2,3$ significantly improve the prediction of Y, given all the other covariates are in the model (p-value = $P(F_{1, n-2} > F)$).\n:::\n:::\n\n## We need to slightly alter our MLR example for life expectancy\n\nOur proposed population model to include water source percent (WS):\n\n$$\\text{LE} = \\beta_0 + \\beta_1 \\text{FLR} + \\beta_2 \\text{FS} + \\beta_3 WS + \\epsilon$$\n\n-   We don't have a fitted multiple regression model for this yet!\n\n**Our main question for the group covariate subset F-test:** Is the regression model containing food supply and water source percent improve the estimation of countries' life expectancy, given percent female literacy rate is already in the model?\n\n::: columns\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"45%\"}\n::: proof1\n::: proof-title\nNull / Smaller / Reduced model\n:::\n\n::: proof-cont\n$LE = \\beta_0 + \\beta_1 FLR + \\epsilon$\n:::\n:::\n:::\n\n::: {.column width=\"45%\"}\n::: definition\n::: def-title\nAlternative / Larger / Full model\n:::\n\n::: def-cont\n$LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\beta_3 WS + \\epsilon$\n:::\n:::\n:::\n:::\n\n## Comparing the SSY, SSR, and SSE for reduced and full model\n\n```{r}\n#| echo: false\n\ngapm_sub2 = gapm %>%\n  drop_na(LifeExpectancyYrs, FemaleLiteracyRate, \n          FoodSupplykcPPD, WaterSourcePrct)\nmod_red3 = lm(LifeExpectancyYrs ~ FemaleLiteracyRate, data = gapm_sub2)\naug_red3  = augment(mod_red3)\n\nmod_full3 = lm(LifeExpectancyYrs ~ FemaleLiteracyRate + FoodSupplykcPPD + WaterSourcePrct,\n               data = gapm_sub2)\naug_full3  = augment(mod_full3)\n\nSS_df3 = gapm_sub2 %>% select(LifeExpectancyYrs) %>%\n  mutate(SSY_diff_r3 = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         SSR_diff_r3 = aug_red3$.fitted - mean(LifeExpectancyYrs), \n         SSE_diff_r3 = aug_red3$.resid, \n         SSY_diff_f3 = LifeExpectancyYrs - mean(LifeExpectancyYrs),\n         SSR_diff_f3 = aug_full3$.fitted - mean(LifeExpectancyYrs), \n         SSE_diff_f3 = aug_full3$.resid)\n```\n\n::: columns\n::: column\n**Reduced / null model** $$LE = \\beta_0 + \\beta_1 FLR + \\epsilon$$\n\n::: columns\n::: column\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_r3 = ggplot(SS_df3, aes(SSY_diff_r3)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot_r3 = ggplot(SS_df3, aes(SSR_diff_r3)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot_r3 = ggplot(SS_df3, aes(SSE_diff_r3)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot_r3, SSR_plot_r3, SSE_plot_r3, nrow = 3)\n```\n:::\n\n::: {.column width=\"30%\"}\n$$SSY = `r round(var(SS_df3$SSY_diff_r3), 2)`$$ \n\n \n\n$$SSR = `r round(var(SS_df3$SSR_diff_r3), 2)`$$\n\n \n\n$$SSE = `r round(var(SS_df3$SSE_diff_r3), 2)`$$\n:::\n\n:::\n\n:::\n\n::: column\n**Full / Alternative model** $$LE = \\beta_0 + \\beta_1 FLR + \\beta_2 FS + \\beta_3 WS + \\epsilon$$\n\n::: columns\n::: column\n```{r}\n#| fig-align: center\n#| fig-width: 6\n#| fig-height: 8\n#| echo: false\n\nSSY_plot_f3 = ggplot(SS_df3, aes(SSY_diff_f3)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSR_plot_f3 = ggplot(SS_df3, aes(SSR_diff_f3)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) +xlab(expression(hat(Y)[i] - bar(Y))) + theme(axis.title.x = element_text(size = 22))\nSSE_plot_f3 = ggplot(SS_df3, aes(SSE_diff_f3)) + geom_histogram() + xlim(-30, 30) + ylim(0, 35) + xlab(expression(Y[i] - hat(Y)[i])) + theme(axis.title.x = element_text(size = 22))\ngrid.arrange(SSY_plot_f3, SSR_plot_f3, SSE_plot_f3, nrow = 3)\n```\n:::\n\n::: {.column width=\"30%\"}\n$$SSY = `r round(var(SS_df3$SSY_diff_f3), 2)`$$ \n\n \n\n$$SSR = `r round(var(SS_df3$SSR_diff_f3), 2)`$$\n\n \n\n$$SSE = `r round(var(SS_df3$SSE_diff_f3), 2)`$$\n:::\n\n:::\n\n:::\n:::\n\n## So let's step through our hypothesis test (1/3)\n\n::: highlight-container\n::: highlight\n1.  Met underlying LINE assumptions\n:::\n:::\n\n \n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis\n:::\n:::\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_2=\\beta_3=0\\\\\n\\text{vs. } H_A&: \\beta_2\\neq0 \\text{ and/or } \\beta_3\\neq0\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $F$, and follows an F-distribution with numerator $df=k =2$ and denominator $df=n-k-1 = 72 - 2-1=69$. ($n$ = \\# obversation, $k$ = \\# covariates)\n\n## So let's step through our hypothesis test (2/3)\n\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic / 6.  Calculate the p-value\n:::\n:::\n\nThe calculated **test statistic** is\n\n$$F^ = \\dfrac{\\frac{SSE(R) - SSE(F)}{df_R - df_F}}{\\frac{SSE(F)}{df_F}}$$\nANOVA table:\n\n```{r}\nanova(mod_red3, mod_full3) %>% tidy() %>% gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n## So let's step through our hypothesis test (3/3)\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for hypothesis test\n:::\n:::\n\n \n\nWe reject the null hypothesis at the 5% significance level. There is sufficient evidence that countries' food supply or water source (or both) contribute significantly to the prediction of life expectancy, given that female literacy rate is already in the model (p-value < 0.001).\n\n## Other ways to word the hypothesis tests (reference)\n\n-   Single covariate subset F-test\n\n    -   $H_0:$ $X^*$ does not significantly improve the prediction of $Y$, given that $X_1, X_2, \\ldots, X_p$ are already in the model\n    -   $H_A:$ $X^*$ significantly improves the prediction of $Y$, given that $X_1, X_2, \\ldots, X_p$ are already in the model\n    \n-   Group covariate subset F-test\n\n    -   $H_0:$ The addition of the $s$ variables $X_1^*, X_2^*, \\ldots, X_s^*$ does not significantly improve the prediction of $Y$, given that $X_1, X_2, \\ldots, X_q$ are already in the model\n    -   $H_A:$ The addition of the $s$ variables $X_1^*, X_2^*, \\ldots, X_s^*$ significantly improves the prediction of $Y$, given that $X_1, X_2, \\ldots, X_q$ are already in the model"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":"mathjax","slide-level":2,"to":"revealjs","highlight-style":"ayu","output-file":"10_MLR_F-test.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.8.25","auto-stretch":true,"title":"Lesson 10: MLR: Using the F-test","author":"Nicky Wakim","title-slide-attributes":{"data-background-color":"#213c96"},"date":"02/10/2025","categories":["Week 5"],"theme":"../simple_NW.scss","chalkboard":true,"slideNumber":true,"showSlideNumber":"all","width":1955,"height":1100,"footer":"Lesson 10: MLR 2"}}},"projectFormats":["html"]}