{"title":"Lesson 14: Purposeful model selection","markdown":{"yaml":{"title":"Lesson 14: Purposeful model selection","author":"Nicky Wakim","title-slide-attributes":{"data-background-color":"#213c96"},"date":"02/26/2025","format":{"revealjs":{"theme":"../simple_NW.scss","chalkboard":true,"slide-number":true,"show-slide-number":"all","width":1955,"height":1100,"footer":"Lesson 14: Purposeful Selection","highlight-style":"ayu","html-math-method":"mathjax"}},"execute":{"freeze":"auto"}},"headingText":"new packages","containsRefs":false,"markdown":"\n\n```{r}\n#| label: \"setup\" \n#| include: false\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\nlibrary(knitr)\nlibrary(broom)\nlibrary(rstatix)\nlibrary(gt)\nlibrary(readxl)\n#----------\n# install.packages(\"describedata\")\nlibrary(describedata) # gladder()\nlibrary(gridExtra)   # grid.arrange()\nlibrary(ggfortify)  # autoplot(model)\n# New Day 6\nlibrary(gtsummary)\n\n# New Day 7\nlibrary(plotly) # for plot_ly() command\nlibrary(GGally) # for ggpairs() command \nlibrary(ggiraphExtra)   # for ggPredict() command\n\n# Load the data - update code if the csv file is not in the same location on your computer\n# If you need to download the file, please go to ur shared folder under Data > Slides\ngapm <- read_excel(\"data/Gapminder_vars_2011.xlsx\", \n                   na = \"NA\")  # important!!!! \n\n\ngapm_sub1 <- gapm %>% # called it gapm2_sub3 to be consistent with Day 7 notes\n  mutate(four_regions = factor(four_regions, \n                               levels = c(\"africa\", \"americas\", \n                                          \"asia\", \"europe\"), \n                               labels = c(\"Africa\", \"Americas\", \n                                          \"Asia\", \"Europe\"))) %>%\n  rename(income_levels = `World bank, 4 income groups 2017`) %>%\n  mutate(income_levels1 = factor(income_levels, \n                                levels = c(\"Low income\", \n                                           \"Lower middle income\", \n                                           \"Upper middle income\", \n                                           \"High income\")) %>%\n                            relevel(ref = \"Low income\"), \n         income_levels2 = relevel(factor(income_levels, \n                                levels = c(\"Low income\", \n                                           \"Lower middle income\", \n                                           \"Upper middle income\", \n                                           \"High income\"), \n                                labels = c(\"Lower income\", \"Lower income\", \n                                            \"Higher income\", \"Higher income\")), \n                                ref = \"Lower income\")) %>%\n  mutate(population_mill = population/1000000) %>%\n  select(-population)\n\ngapm_sub <- gapm %>% # called it gapm2_sub3 to be consistent with Day 7 notes\n  drop_na(LifeExpectancyYrs, FemaleLiteracyRate, four_regions, FoodSupplykcPPD) %>%\n  mutate(four_regions = factor(four_regions, \n                               levels = c(\"africa\", \"americas\", \n                                          \"asia\", \"europe\"), \n                               labels = c(\"Africa\", \"Americas\", \n                                          \"Asia\", \"Europe\"))) %>%\n  rename(income_levels = `World bank, 4 income groups 2017`) %>%\n  mutate(income_levels1 = factor(income_levels, \n                                levels = c(\"Low income\", \n                                           \"Lower middle income\", \n                                           \"Upper middle income\", \n                                           \"High income\")), \n         income_levels2 = relevel(factor(income_levels, \n                                levels = c(\"Low income\", \n                                           \"Lower middle income\", \n                                           \"Upper middle income\", \n                                           \"High income\"), \n                                labels = c(\"Lower income\", \"Lower income\", \n                                            \"Higher income\", \"Higher income\")), \n                                ref = \"Lower income\"))\n\ngapm_ind = gapm_sub %>% select(LifeExpectancyYrs, country)\n\ngapm2 = gapm %>% select(-Longitude, -Latitude, -eight_regions, -six_regions, -geo, -`World bank, 4 income groups 2017`, -country, -population, -`World bank region`, -ElectricityUsePP)\n```\n\n# Learning Objectives\n\n1.  Understand the overall steps for purposeful selection as a model building strategy\n\n2.  Apply purposeful selection to a dataset using R\n\n3.  Use different approaches to assess the linear scale of continuous variables in logistic regression\n\n\n## Regression analysis process\n\n```{css, echo=FALSE}\n.reveal code {\n  max-height: 100% !important;\n}\n```\n\n::: box\n![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"62.1%\" width=\"155\"} ![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"28.4%\" width=\"155\"}![](../img_slides/arrow_back4.png){.absolute top=\"7.5%\" right=\"30.5%\" width=\"820\"} ![](../img_slides/arrow_down.png){.absolute top=\"60.5%\" right=\"48%\" width=\"85\"}\n\n::: columns\n::: {.column width=\"30%\"}\n::: RAP1\n::: RAP1-title\nModel Selection\n:::\n\n::: RAP1-cont\n-   Building a model\n\n-   Selecting variables\n\n-   Prediction vs interpretation\n\n-   Comparing potential models\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP2\n::: RAP2-title\nModel Fitting\n:::\n\n::: RAP2-cont\n-   Find best fit line\n\n-   Using OLS in this class\n\n-   Parameter estimation\n\n-   Categorical covariates\n\n-   Interactions\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP3\n::: RAP3-title\nModel Evaluation\n:::\n\n::: RAP3-cont\n-   Evaluation of model fit\n-   Testing model assumptions\n-   Residuals\n-   Transformations\n-   Influential points\n-   Multicollinearity\n:::\n:::\n:::\n:::\n:::\n\n::: RAP4\n::: RAP4-title\nModel Use (Inference)\n:::\n\n::: RAP4-cont\n::: columns\n::: {.column width=\"50%\"}\n-   Inference for coefficients\n-   Hypothesis testing for coefficients\n:::\n\n::: {.column width=\"50%\"}\n-   Inference for expected $Y$ given $X$\n-   Prediction of new $Y$ given $X$\n:::\n:::\n:::\n:::\n\n# Learning Objectives\n\n::: lob\n1.  Understand the overall steps for purposeful selection as a model building strategy\n:::\n\n2.  Apply purposeful selection to a dataset using R\n\n3.  Use different approaches to assess the linear scale of continuous variables in logistic regression\n\n## \n\n \n\n \n\n::: columns\n::: {.column width=\"20%\"}\n:::\n\n::: {.column width=\"60%\"}\n::: qt\n[\"Successful modeling of a complex data set is [**part science**]{style=\"color:#FF8021;\"}, [**part statistical methods**]{style=\"color:#34AC8B;\"}, and [**part experience and common sense**]{style=\"color:#4FADF3;\"}.\"]{style=\"font-size:60px;\"}\n:::\n\n \n\n::: qt-t\nHosmer, Lemeshow, and Sturdivant Textbook, pg. 101\n:::\n:::\n:::\n\n## Overall Process\n\n0.  Exploratory data analysis\n\n1.  Check unadjusted associations in simple linear regression\n\n2.  Enter all covariates in model that meet some threshold\n\n    -   [One textbook](https://onlinelibrary.wiley.com/doi/book/10.1002/9781118548387) suggest $p<0.2$ or $p<0.25$: great for modest sized datasets\n    -   PLEASE keep in mind sample size in your study\n    -   Can also use magnitude of association rather than, or along with, p-value\n\n3.  Remove those that no longer reach some threshold\n\n    -   Compare magnitude of associations to unadjusted version (univariable)\n\n4.  Check scaling of continuous and coding of categorical covariates\n\n5.  Check for interactions\n\n6.  Assess model fit\n\n    -   Model assumptions, diagnostics, overall fit\n\n## Process with snappier step names\n\n::: columns\n::: {.column width=\"10%\"}\n**Pre-step:**\n\n \n\n**Step 1:**\n\n \n\n**Step 2:**\n\n \n\n**Step 3:**\n\n \n\n**Step 4:**\n\n \n\n**Step 5:**\n\n \n\n**Step 6:**\n:::\n\n::: {.column width=\"50%\"}\nExploratory data analysis (EDA)\n\n \n\nSimple linear regressions / analysis\n\n \n\nPreliminary variable selection\n\n \n\nAssess change in coefficients\n\n \n\nAssess scale for continuous variables\n\n \n\nCheck for interactions\n\n \n\nAssess model fit\n:::\n:::\n\n# Learning Objectives\n\n1.  Understand the overall steps for purposeful selection as a model building strategy\n\n::: lob\n2.  Apply purposeful selection to a dataset using R\n:::\n\n3.  Use different approaches to assess the linear scale of continuous variables in logistic regression\n\n## Pre-step: Exploratory data analysis\n\n- The following slides are all reference until we get to Step 1\n- We have covered exploratory data analysis in other classes and have completed it in our previous labs\n\n## Pre-step: Exploratory data analysis\n\n-   Things we have been doing over the quarter in class and in our project\n\n-   I will not discuss some of the methods mentioned in our lab and data management class\n\n    -   I am only going to introduce additional exploratory functions\n\n \n\nA few things we can do:\n\n-   Check the data\n-   Study your variables\n-   Missing data?\n-   Explore simple relationships and assumptions\n\n## Pre-step: Exploratory data analysis: Check the data\n\n::: columns\n::: {.column width=\"50%\"}\n-   Get to know the potential values for the data\n\n    -   Categories\n\n    -   Units\n\n-   Then make sure the summary of values makes sense\n\n    -   If minimum or maximum look outside appropriate range\n    -   For example: a negative value for a measurement that is inherently positive (like population or income)\n:::\n\n::: {.column width=\"50%\"}\n[![https://www.gapminder.org/data/documentation/](../img_slides/Gapminder_doc.png){fig-align=\"center\"}](https://www.gapminder.org/data/documentation/)\n:::\n:::\n\n## Pre-step: Exploratory data analysis: Check the data\n\n::: columns\n::: {.column width=\"25%\"}\n-   Look at a summary for the raw data\n\n-   Typical use:\n\n```{r}\n#| echo: true\n#| output: false\nlibrary(skimr)\nskim(gapm)\n```\n\n-   [Some `skim()` help](https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html)\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"74%\"}\n:::\n:::\n\n## Pre-step: Exploratory data analysis: Check the data\n\n::: columns\n::: {.column width=\"25%\"}\n-   Look at a summary for the raw data\n\n-   Typical use:\n\n```{r}\n#| echo: true\n#| output: false\nlibrary(skimr)\nskim(gapm)\n```\n\n-   [Some `skim()` help](https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html)\n\n-   Note that `skim(gapm)` looks different because I had to create factors\n\n-   I am breaking down the `skim()` function into the categorical and continuous variables only because I want to show them on the slides\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"74%\"}\n```{r}\n#| echo: true\n#| size: small \nskim(gapm_sub1) %>% yank(\"factor\")\n```\n:::\n:::\n\n## Pre-step: Exploratory data analysis: Check the data {.smaller}\n\n```{r, skimr_digits = 2}\n#| echo: true\n#| size: small \nskim(gapm_sub1) %>% yank(\"numeric\")\n```\n\n## Poll Everywhere Question 1\n\n![](../img_slides/14_poll_ev_01.png)\n\n## Pre-step: Exploratory data analysis: Study your variables\n\n-   Started this a little bit in previous slide (`skim()`), but you may want to look at things like:\n\n    -   Sample size\n    -   Counts of missing data\n    -   Means and standard deviations\n    -   IQRs\n    -   Medians\n    -   Minimums and maximums\n\n-   Can also look at visuals\n\n    -   Continuous variables: histograms (in \\`skimr() a little)\n    -   Categorical variables: frequency plots\n\n## Pre-step: Exploratory data analysis: Study your variables {.smaller}\n\n```{r}\n#| echo: true\n\nlibrary(Hmisc)\nhist.data.frame(gapm %>% select(-Longitude, -Latitude, -eight_regions, -six_regions, -geo, -`World bank, 4 income groups 2017`, -country, -population, -`World bank region`, -ElectricityUsePP))\n```\n\n## Poll Everywhere Question 2\n\nQuestion: What function might you use to visualize or summarize the frequencies of categorical variables?\n\n## Pre-step: Exploratory data analysis: Missing data\n\n-   Why are there missing data?\n-   Which variables and observations should be excluded because of missing data?\n-   Will I impute missing data?\n\n \n\n-   Unfortunately, we don’t have time to discuss missing data more thoroughly\\\n-   I will try to cover this topic more thoroughly in BSTA 513\n\n \n\n-   For the Gapminder dataset, we chose to use complete cases\n\n## Pre-step / Step 1 : Explore simple relationships and assumptions {.smaller}\n\n```{r}\n#| fig-align: center\n#| echo: true\n\ngapm2 %>% ggpairs() # gapm2 is a new dataset with some variables selected\n```\n\n## Poll Everywhere Question 3\n\n![](../img_slides/14_poll_ev_03.png)\n\n## Step 1: Simple linear regressions / analysis\n\n-   For each covariate, we want to see how it relates to the outcome (without adjusting for other covariates)\n\n-   We can partially do this with **visualizations**\n\n    -   Helps us see the data we throw it into regression that makes assumptions (like our LINE assumptions)\n\n    -   `ggpairs()` can be a quick way to do it\n\n    -   `ggplot()` can make each plot\n\n        -   `+ geom_boxplot()` to make boxplots by groups for categorical covariates\n        -   `+ geom_jitter() + stat_summary()` to make non-overlaping points with group means for categorical covariates\n        -   `+ geom_point()` to make scatterplots for continuous covariates\n\n-   We need to run **simple linear regression**\n\n    -   We're calling regression with multi-level categories \"simple\" even though there are multiple coefficients\n\n## Step 1: Simple linear regressions / analysis\n\n-   Let's think back to our Gapminder dataset\n\n-   Always good to start with our main relationship: life expectancy vs. female literacy rate\n\n    -   *Throwback to Lesson 3 SLR when we first visualized and ran `lm()` for this relationship*\n\n```{r}\n#| echo: true\n#| eval: false\n\nmodel_FLR = lm(LifeExpectancyYrs ~ FemaleLiteracyRate, data = gapm_sub)\n```\n\n \n\n::: columns\n::: {.column width=\"45%\"}\n```{r}\n#| fig-height: 8\n#| fig-width: 11\n#| echo: false\n\nggplot(gapm_sub, aes(x = FemaleLiteracyRate,\n                 y = LifeExpectancyYrs)) +\n  geom_point(size = 4) +\n  geom_smooth(method = \"lm\", se = FALSE, size = 3, colour=\"#F14124\") +\n  labs(x = \"Female literacy rate (%)\", \n       y = \"Life expectancy (years)\",\n       title = \"Relationship between life expectancy and \\n the female literacy rate in 2011\") +\n    theme(axis.title = element_text(size = 30), \n        axis.text = element_text(size = 25), \n        title = element_text(size = 30))\n\n```\n:::\n\n::: {.column width=\"55%\"}\n```{r}\nmodel_FLR = lm(LifeExpectancyYrs ~ FemaleLiteracyRate, data = gapm_sub)\ntidy(model_FLR) %>% gt() %>% tab_options(table.font.size = 40) %>% \n  fmt_number(decimals = 3)\n```\n:::\n:::\n\n## Poll Everywhere Question 4\n\n## Step 1: Simple linear regressions / analysis\n\n-   Let's do this with one other variable before I show you a streamlined version of SLR\n\n```{r}\n#| echo: true\n\nmodel_WR = lm(LifeExpectancyYrs ~ four_regions, data = gapm_sub)\n```\n\n \n\n::: columns\n::: {.column width=\"45%\"}\n```{r fig.height=7, fig.width=7, warning=F, fig.align='center'}\n#| echo: true\n#| code-fold: true\nggplot(gapm_sub, aes(x = four_regions, y = LifeExpectancyYrs)) +\n  geom_jitter(size = 1, alpha = .6, width = 0.2) +\n  stat_summary(fun = mean, geom = \"point\", size = 8, shape = 18) +\n  labs(x = \"World region\", \n       y = \"Country life expectancy (years)\",\n       title = \"Life expectancy vs. world region\",\n       caption = \"Diamonds = region averages\") +\n  theme(axis.title = element_text(size = 20), \n        axis.text = element_text(size = 20), \n        title = element_text(size = 20))\n```\n:::\n\n::: {.column width=\"55%\"}\n```{r}\n#| echo: true\n\nanova(model_WR) %>% tidy() %>% gt() %>%\n   tab_options(table.font.size = 40) %>%\n   fmt_number(decimals = 3)\n\n```\n\n \n\n-   Recall from Lesson 5 (SLR: More inference + Evaluation):\n\n    -   `anova()` with one model name will compare the model (`model_WR`) to the intercept model\n:::\n:::\n\n```{r}\n\ngapm2 = gapm_sub %>% select(LifeExpectancyYrs, CO2emissions, FoodSupplykcPPD, \n                            IncomePP, FemaleLiteracyRate, WaterSourcePrct, \n                            four_regions, members_oecd_g77)\n```\n\n\n## Step 1: Simple linear regressions / analysis\n\n-   If we do a good job visualizing the relationship between our outcome and each covariate, then we can proceed to a streamlined version of the F-test for each relationship\n-   Run `add1()` to add each variable one at a time and separately\n- Output will include hypothesis test (using F-test) if coefficient(s) is 0 or not\n\n```{r}\n#| echo: true\n\nintercept_model = gapm2 %>% lm(formula = LifeExpectancyYrs ~ 1)\nadd1(intercept_model, scope = ~ FemaleLiteracyRate + CO2emissions + IncomePP + four_regions +\n       WaterSourcePrct + FoodSupplykcPPD + members_oecd_g77, test = \"F\")\n```\n\n## Step 2: Preliminary variable selection\n\n-   Identify candidates for your first multivariable model by performing an F-test on each covariate's SLR\n\n    -   Using p-values from previous slide\n    -   If the p-value of the test is less than 0.25, then consider the variable a candidate\n\n \n\n-   Candidates for first multivariable model\n\n    -   All clinically important variables (regardless of p-value)\n    -   Variables with univariate test with p-value \\< 0.25\n\n \n\n-   With more experience, you won’t need to rely on these strict rules as much\n\n## Step 2: Preliminary variable selection\n\n-   From the previous p-values from the F-test on each covariate's SLR\n\n    -   Decision: we keep all the covariates since they all have a p-value \\< 0.25\n\n```{r}\n#| echo: true\n\nadd1(intercept_model, scope = ~ FemaleLiteracyRate + CO2emissions + IncomePP + four_regions +\n       WaterSourcePrct + FoodSupplykcPPD + members_oecd_g77, test = \"F\")\n```\n\n## Step 2: Preliminary variable selection\n\n-   Fit an **initial model** including any independent variable with p-value \\< 0.25 and clinically important variables\n\n\n```{r}\n#| echo: true\n#| output-location: column\n\ninit_model = lm(LifeExpectancyYrs ~\n                  FemaleLiteracyRate + \n                  CO2emissions + \n                  IncomePP +\n                  four_regions + \n                  WaterSourcePrct + \n                  FoodSupplykcPPD + \n                  members_oecd_g77, \n                data = gapm2)\n\ntbl_regression(\n  init_model, \n  label = list(\n    FemaleLiteracyRate ~ \"Female literacy rate (%)\", \n    CO2emissions ~ \"CO2 emissions\", \n    IncomePP ~ \"Income  (GDP per capita)\", \n    four_regions ~ \"World region\",\n    WaterSourcePrct ~ \"Access to omproved water (%)\",\n    FoodSupplykcPPD ~ \"Food supply (kcal PPD)\",\n    members_oecd_g77 ~ \"Intergovernmental group\"\n    )) %>% \n  as_gt() %>% \n  tab_options(table.font.size = 26) \n```\n\n\n## Step 3: Assess change in coefficient\n\n::: columns\n::: {.column width=\"48%\"}\n-   This is where we start identifying covariates that we might remove\n\n \n\n-   I would start by using the p-value to guide me towards specific variables\n\n    -   Female literacy rate, but that's our main covariate\n    -   Intergovernmental group?\n    -   Maybe water source percent?\n\n \n\n-   Some people will say you can use the p-value alone\n\n    -   I like to double check that those variables do not have a large effect on the other coefficients\n:::\n\n::: {.column width=\"52%\"}\n```{r}\ntbl_regression(\n  init_model, \n  label = list(\n    FemaleLiteracyRate ~ \"Female literacy rate (%)\", \n    CO2emissions ~ \"CO2 emissions\", \n    IncomePP ~ \"Income  (GDP per capita)\", \n    four_regions ~ \"World region\",\n    WaterSourcePrct ~ \"Access to omproved water (%)\",\n    FoodSupplykcPPD ~ \"Food supply (kcal PPD)\",\n    members_oecd_g77 ~ \"Intergovernmental group\"\n    )) %>% \n  as_gt() %>% \n  tab_options(table.font.size = 26) \n```\n:::\n:::\n\n## Step 3: Assess change in coefficient\n\n-   Very similar to the process we used when looking at confounders\n\n \n\n-   One variable at a time, we run the multivariable model with and without a variable\n\n    -   We look at the p-value of the F-test for the coefficients of said variable\n    -   We look at the percent change for the coefficient ($\\Delta\\%$) of our **explanatory variable** (FLR in our example)\n\n \n\n-   General rule: We can remove a variable if...\n\n    -   p-value \\> 0.05 for the F-test of its own coefficients\n    -   AND change in coefficient ($\\Delta\\%$) of our explanatory variable is \\< 10%\n\n## F-test on dropping each covariate\n\n- Function `drop1()`: If we put in our initial model, the function will remove each covariate and perform the respective F-test to test if the coefficients are 0 (null) or not (alternative).\n```{r}\n#| echo: true\n\ndrop1(init_model, test=\"F\")\n```\n\n## Testing for percent change ( $\\Delta\\%$) in a coefficient\n\n-   Let's say we have $X_1$ and $X_2$, and we specifically want to see if $X_2$ is a confounder for $X_1$ (the explanatory variable or variable of interest)\n\n-   If we are only considering $X_1$ and $X_2$, then we need to run the following two models:\n\n    -   Fitted model 1 / reduced model (`mod1`): $\\widehat{Y} = \\widehat\\beta_0 + \\widehat\\beta_1X_1$\n\n        -   We call the above $\\widehat\\beta_1$ the reduced model coefficient: $\\widehat\\beta_{1, \\text{mod1}}$ or $\\widehat\\beta_{1, \\text{red}}$\n\n    -   Fitted model 2 / Full model (`mod2`): $\\widehat{Y} = \\widehat\\beta_0 + \\widehat\\beta_1X_1 +\\widehat\\beta_2X_2$\n\n        -   We call this $\\widehat\\beta_1$ the full model coefficient: $\\widehat\\beta_{1, \\text{mod2}}$ or $\\widehat\\beta_{1, \\text{full}}$\n\n::: columns\n::: {.column width=\"15%\"}\n:::\n\n::: {.column width=\"70%\"}\n::: fact\n::: fact-title\nCalculation for % change in coefficient\n:::\n\n::: fact-cont\n$$\n\\Delta\\% = 100\\% \\cdot\\frac{\\widehat\\beta_{1, \\text{mod1}} - \\widehat\\beta_{1, \\text{mod2}}}{\\widehat\\beta_{1, \\text{mod2}}} = 100\\% \\cdot \\frac{\\widehat\\beta_{1, \\text{red}} - \\widehat\\beta_{1, \\text{full}}}{\\widehat\\beta_{1, \\text{full}}}\n$$\n:::\n:::\n:::\n\n::: {.column width=\"15%\"}\n:::\n:::\n\n\n## Step 3: Assess change in coefficient\n\n-   Let's try this out on `members_oecd_g77`\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Display the ANOVA table with F-statistic and p-value\"\n\nmodel_full = init_model\nmodel_red = lm(LifeExpectancyYrs ~ FemaleLiteracyRate + CO2emissions + IncomePP +\n               four_regions + WaterSourcePrct + FoodSupplykcPPD, \n                 data = gapm2)\nanova(model_full, model_red) %>% tidy() %>% \n  gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Display the FLR coefficient for both models\"\n#| include: false\n\ntidy(model_full) %>% \n  gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\ntidy(model_red) %>% \n  gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n-   $\\widehat\\beta_{FLR, full} = `r round(tidy(model_full)[2,2], 4)`$, $\\widehat\\beta_{FLR, red} = `r round(tidy(model_red)[2,2], 4)`$\n\n$$\n\\Delta\\% = 100\\% \\cdot \\frac{\\widehat\\beta_{FLR, full} - \\widehat\\beta_{FLR, red}}{\\widehat\\beta_{FLR, full}} = 100\\% \\cdot \\frac{`r round(tidy(model_full)[2,2], 4)` - `r round(tidy(model_red)[2,2], 4)`}{`r round(tidy(model_full)[2,2], 4)`} = `r round(100*(tidy(model_full)[2,2] - tidy(model_red)[2,2])/tidy(model_full)[2,2], 2)`\\%\n$$\n\n-   Based off the percent change, I would keep this in the model\n\n## Step 3: Assess change in coefficient (Reference only)\n\n-   Let's try this out on water source percent (even though the p-value was \\< 0.05)\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Display the ANOVA table with F-statistic and p-value\"\n\nmodel_full = init_model\nmodel_red = lm(LifeExpectancyYrs ~ FemaleLiteracyRate + CO2emissions + IncomePP +\n               four_regions + members_oecd_g77 + FoodSupplykcPPD, \n                 data = gapm2)\nanova(model_full, model_red) %>% tidy() %>% \n  gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Display the FLR coefficient for both models\"\n#| include: false\n\ntidy(model_full) %>% \n  gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\ntidy(model_red) %>% \n  gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n-   $\\widehat\\beta_{FLR, full} = `r round(tidy(model_full)[2,2], 4)`$, $\\widehat\\beta_{FLR, red} = `r round(tidy(model_red)[2,2], 4)`$\n\n$$\n\\Delta\\% = 100\\% \\cdot \\frac{\\widehat\\beta_{FLR, full} - \\widehat\\beta_{FLR, red}}{\\widehat\\beta_{FLR, full}} = 100\\% \\cdot \\frac{`r round(tidy(model_full)[2,2], 4)` - `r round(tidy(model_red)[2,2], 4)`}{`r round(tidy(model_full)[2,2], 4)`} = `r round(100*(tidy(model_full)[2,2] - tidy(model_red)[2,2])/tidy(model_full)[2,2], 2)`\\%\n$$\n\n-   Based off the percent change (and p-value), I would keep this in the model\n\n## Poll Everywhere Question 5\n\n## Step 3: Assess change in coefficient: Summary\n\n-   At the end of this step, we have a **preliminary main effects model**\n\n-   Where the variables are excluded that met the following criteria:\n\n    -   P-value \\> 0.05 for the F-test of its own coefficients\n    -   Change in coefficient ($\\Delta\\%$) of our explanatory variable is \\< 10%\n\n-   In our example, the **preliminary main effects model** (end of Step 3) was the same as the **initial model** (end of Step 2)\n\n-   Preliminary main effects model includes:\n\n    -   `FemaleLiteracyRate`\n    -   `CO2emissions`\n    -   `IncomePP`\n    -   `four_regions`\n    -   `members_oecd_g77`\n    -   `FoodSupplykcPPD`\n    -   `WaterSupplePct`\n    \n    \n## Recap of Steps 1-3\n\n-   Pre-step: Exploratory data analysis\n\n-   Step 1: Simple linear regressions / analysis\n\n    -   Look at each covariate with outcome\n\n    -   Perform SLR for each covariate\n\n-   Step 2: Preliminary variable selection\n\n    -   From SLR, decide which variables go into the initial model\n\n    -   Use F-test to see if each covariate (on its own) explains enough variation in outcome\n\n    -   End with **initial model**\n        \n-   Step 3: Assess change in coefficients\n\n    -   From the initial model at end of step 2, we take a variable out of the model if:\n\n        -   P-value \\> 0.05 for the F-test of its own coefficients\n\n        -   Change in coefficient ($\\Delta\\%$) of our explanatory variable is \\< 10%\n        \n    -   End with **preliminary main effects model**\n\n# Learning Objectives\n\n1.  Understand the overall steps for purposeful selection as a model building strategy\n\n2.  Apply purposeful selection to a dataset using R\n\n::: lob\n3.  Use different approaches to assess the linear scale of continuous variables in logistic regression\n:::\n\n## Step 4: Assess scale for continuous variables\n\n-   We assume the linear regression model is linear for **each continuous variable**\n\n-   We need to assess linearity for continuous variables in the model\n\n    -   Do this through smoothed scatterplots that we introduced in Lesson 6 (SLR Diagnostics)\n    -   Residual plots (can be used in SLR) does not help us in MLR\n    -   Each term in MLR model needs to have linearity with outcome\n\n-   Three methods/approaches to address the violation of linearity assumption:\n\n    -   **Approach 1:** Categorize continuous variable\n    -   **Approach 2:** Fractional Polynomials\n    -   **Approach 3:** Spline functions\n    \n-   Approach will depend on the covariate!!\n\n-   For our class, only implement **Approach 1 or 2**\n\n-   Model at the end of Step 4 is the **main effects model**\n\n## Step 4: Assess scale for continuous variables {visibility=\"hidden\"}\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Residual plot does not help us with linearity in MLR\"\n#| fig-width: 10\n#| fig-height: 6\n#| fig-align: center\n\nlibrary(ggfortify)\nautoplot(model_full) + theme(text=element_text(size=14))\n```\n\n## Step 4: Assess scale for continuous variables: Smoothed scatterplots\n\n-   Smoother scatterplots **only check linearity**, not addressing linearity issues\n\n \n\n-   Can also identify extreme observations\n\n    -   Again, just want to flag these values \n\n    -   Can influence the assessment of linearity when using fractional polynomials or spline functions\n\n \n\n-   Helps us decide if the continuous variable can stay **as is** in the model\n\n    -   **Problem:** if not linear, then we need to represent the variable in a new way (Approaches 1-3)\n\n## Step 4: Assess scale for continuous variables: Smoothed scatterplots\n\n-   In Gapminder dataset, we have 5 continuous variables:\n\n    -   CO2 Emissions\n    -   Food Supply\n    -   Income\n    -   Female Literacy Rate\n    -   Water source percent\n\n-   Plot each of these agains the outcome, life expectancy\n\n## Step 4: Assess scale for continuous variables: Smoothed scatterplots\n\n```{r, fig.height=6, fig.width=11, fig.align='center'}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"We can quickly look at ggpairs() to identify variables\"\n\ngapm2 %>% select(where(is.numeric)) %>% \n  relocate(LifeExpectancyYrs, .after = last_col()) %>% ggpairs()\n\n```\n\n```{r}\n#| echo: false\n\ngapm2 = gapm_sub \n```\n\n## Step 4: Assess scale for continuous variables: Smoothed scatterplots\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Take a look at C02, Food Supply, and Income\"\n#| fig-width: 10\n#| fig-height: 3.5\n#| fig-align: center\n\nCO2 = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = CO2emissions)) + \n  geom_point() +\n  geom_smooth(se=F) + labs(x = \"CO2 Emissions (kt)\", y = \"Life Expectancy (yrs)\")\n\nFS = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = FoodSupplykcPPD)) + \n  geom_point() +\n  geom_smooth(se=F) + labs(x = \"Food Supply (kcal PPD)\", y = \"Life Expectancy (yrs)\")\n\nIncome = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = IncomePP)) + \n  geom_point() +\n  geom_smooth(se=F) + labs(x = \"Income (GDP per capita)\", y = \"Life Expectancy (yrs)\")\n\ngrid.arrange(CO2, FS, Income, nrow=1)\n```\n\n-   Food Supply looks admissible\n-   CO2 Emissions and Income do not look very linear, but I want to zoom into the area of the plots that have most of the data\n\n## Step 4: Assess scale for continuous variables: Smoothed scatterplots\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Zoom into areas on plots with more data\"\n#| fig-width: 10\n#| fig-height: 3.5\n#| fig-align: center\n\nCO2 = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = CO2emissions)) + \n  geom_point() + xlim(0,10) +\n  geom_smooth(se=F) + labs(x = \"CO2 Emissions (kt)\", y = \"Life Expectancy (yrs)\")\n\nFS = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = FoodSupplykcPPD)) + \n  geom_point() +\n  geom_smooth(se=F) + labs(x = \"Food Supply (kcal PPD)\", y = \"Life Expectancy (yrs)\")\n\nIncome = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = IncomePP)) + \n  geom_point() + xlim(0,40000) +\n  geom_smooth(se=F) + labs(x = \"Income (GDP per capita)\", y = \"Life Expectancy (yrs)\")\n\ngrid.arrange(CO2, FS, Income, nrow=1)\n```\n\n-   Food Supply still looks admissible\n-   CO2 Emissions and Income not linear: will address this!!\n\n## Step 4: Assess scale for continuous variables\n\n-   Three methods/approaches to address the violation of linearity assumption:\n\n     \n\n    -   **Approach 1:** Categorize continuous variable\n\n     \n\n    -   **Approach 2:** Fractional Polynomials\n    \n     \n\n    -   **Approach 3:** Spline functions\n    \n\n\n## Step 4: Approach 1: Categorize continuous variable\n\n-   Categorize continuous variables\n\n    -   Percentiles, quartiles, quantiles\n    \n        -   Create indicator variables corresponding to each quartile\n        \n    -   Meaningful thresholds\n    \n        -   Example: [income level groups](https://www.gapminder.org/fw/income-levels/) discussed by Gapminder\n        \n-   Disadvantages:\n\n    -   Takes some time to create new variables, especially with multiple continuous covariates\n\n    -   Start with quartiles, but might be more appropriate to use different splits\n\n        -   No set rules on this\n\n-   Advantage: graphical and visually helps\n\n## Step 4: Approach 1: Categorize continuous variable\n\n::: columns\n::: column\n-   For income, I would use [Gapminder's income level groups](https://www.gapminder.org/fw/income-levels/) \n\n    -   Discussed in Lesson 10 Categorical Covariates (slide 43)\n\n \n\n-   Experts in the field have developed these income groups\n\n    -   I think this is best solution for income (that was not meeting linearity as a continuous variable)\n:::\n\n::: column\n```{r fig.height=9, fig.width=8, warning=F, fig.align='center'}\n#| echo: false\nlevel_order <- c(\"Low income\", \"Lower middle income\", \n                 \"Upper middle income\", \"High income\") \nggplot(gapm2, aes(x = factor(income_levels1, level = level_order), y = LifeExpectancyYrs)) +\n  geom_jitter(size = 1, alpha = .6, width = 0.2) +\n  stat_summary(fun = mean, geom = \"point\", size = 8, shape = 18) +\n  labs(x = \"Income levels\", \n       y = \"Country life expectancy (years)\",\n       title = \"Life expectancy vs. income levels\",\n       caption = \"Diamonds = Income level averages\") +\n  theme(axis.title = element_text(size = 20), \n        axis.text = element_text(size = 20), \n        title = element_text(size = 20)) +\n  scale_x_discrete(labels = function(x) str_wrap(x, width = 10))\n```\n:::\n:::\n\n## Step 4: Approach 1: Categorize continuous variable\n\n::: columns\n::: {.column width=\"40%\"} \n-   Let's still try it out with CO2 Emissions (kt)\n\n-   I have plotted the quartile lines of food supply with red lines\n:::\n\n::: {.column width=\"60%\"} \n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Take a look at the quartiles within the scatterplot\"\n#| fig-width: 12\n#| fig-height: 8\n#| fig-align: center\n\nvline_coordinates= data.frame(Quantile_Name=names(quantile(gapm2$CO2emissions)),\n                          quantile_values=as.numeric(quantile(gapm2$CO2emissions)))\n\nggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = CO2emissions)) + \n  geom_point(size = 3) +\n  #geom_smooth(se=F) + \n  labs(x = \"CO2 Emissions (kt)\", y = \"Life Expectancy (yrs)\") +\n  geom_vline(data = vline_coordinates, aes(xintercept = quantile_values), \n             color = \"red\", linetype = \"dashed\", size = 2) +\n    theme(axis.title = element_text(size = 25), \n        axis.text = element_text(size = 25), \n        title = element_text(size = 25))\n  \n```\n\n```{r}\n#| echo: false\n#| eval: false\n#| \nvline_coordinates= data.frame(Quantile_Name=names(quantile(gapm2$IncomePP)),\n                          quantile_values=as.numeric(quantile(gapm2$IncomePP)))\n\nIncome = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = IncomePP)) +\n  geom_point(size = 1) +\n  #geom_smooth(se=F) +\n  labs(x = \"Income (GDP per capita)\", y = \"Life Expectancy (yrs)\")  +\n  geom_vline(data = vline_coordinates, aes(xintercept = quantile_values),\n             color = \"red\", linetype = \"dashed\", size = .9)\n\ngrid.arrange(CO2, Income, nrow=1)\n```\n:::\n\n:::\n\n## Step 4: Approach 1: Categorize continuous variable\n\n-   Let's make the quartiles for CO2 emissions:\n\n```{r}\n#| echo: true\nlibrary(dvmisc)\ngapm2 = gapm2 %>% \n  mutate(CO2_q = quant_groups(CO2emissions, groups = 4) %>% factor())\n```\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Take a look at the quartile means within the scatterplot\"\n#| fig-width: 12\n#| fig-height: 8\n#| fig-align: center\n\n\nggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = CO2_q)) + \n  # geom_point(size = 3, aes(y = LifeExpectancyYrs, x = CO2emissions)) +\n  stat_summary(fun = mean, geom = \"point\", size = 8, shape = 18) +\n  #geom_smooth(se=F) + \n  labs(x = \"CO2 Emissions (kt)\", y = \"Life Expectancy (yrs)\") +\n    theme(axis.title = element_text(size = 25), \n        axis.text = element_text(size = 25), \n        title = element_text(size = 25))\n```\n\n## Step 4: Approach 1: Categorize continuous variable\n\n::: columns\n::: {.column width=\"45%\"}\n\n \n\n-   Let's fit a new model with the two new representations for income and CO2 emissions\n\n \n\n-   Remember, this is the **main effects model** if we decide to make CO2 into quartiles\n\n```{r}\nmain_eff_model = lm(LifeExpectancyYrs ~ FemaleLiteracyRate + CO2_q + income_levels1 +\n               four_regions + WaterSourcePrct + FoodSupplykcPPD + members_oecd_g77, \n                 data = gapm2)\n```\n:::\n\n::: {.column width=\"55%\"}\n```{r}\ntbl_regression(\n  main_eff_model, \n  label = list(\n    FemaleLiteracyRate ~ \"Female literacy rate (%)\", \n    CO2_q ~ \"CO2 emissions quartiles\", \n    income_levels1 ~ \"Income levels\", \n    four_regions ~ \"World region\",\n    WaterSourcePrct ~ \"Access to omproved water (%)\",\n    FoodSupplykcPPD ~ \"Food supply (kcal PPD)\",\n    members_oecd_g77 ~ \"Intergovernmental group\"\n    )) %>% \n  as_gt() %>% \n  tab_options(table.font.size = 22) \n```\n:::\n:::\n\n## Step 4: Approach 2: Fractional Polynomials\n\n-   Main concepts and transformations presented in Lesson 7 SLR: Model Evaluation and Diagnostics (slide 33 on)\n\n-   Idea: test many transformations of a continuous covariate\n\n    -   [Based on Royston and Altman, Applied Statistics, 1994](https://www.jstor.org/stable/2986270)\n\n \n\n-   Recall Tukey's transformation (power) ladder\n\n    -   And can use `R`'s `gladder()` to see the transformations\n\n| Power p | -3              | -2              | -1            | -1/2                 | 0         | 1/2        | 1   | 2     | 3     |\n|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|\n|         | $\\frac{1}{x^3}$ | $\\frac{1}{x^2}$ | $\\frac{1}{x}$ | $\\frac{1}{\\sqrt{x}}$ | $\\log(x)$ | $\\sqrt{x}$ | $x$ | $x^2$ | $x^3$ |\n\n \n\n-   We can run through each and test different models, or use the approach from Lesson 7\n\n-   There is also a package we can use!\n\n    -   [mfp package in R](https://cran.r-project.org/web/packages/mfp/mfp.pdf) contains the fp() function\n\n## Step 4: Approach 2: Fractional Polynomials\n\n```{r}\n#| echo: true\n\nlibrary(mfp)\n\nfp_model_CO2 = mfp(LifeExpectancyYrs ~ FemaleLiteracyRate + \n                     fp(CO2emissions, df = 4) + income_levels1 + four_regions +\n                     WaterSourcePrct + FoodSupplykcPPD + members_oecd_g77,\n               data = gapm2, family = \"gaussian\")\n\nfp_model_CO2$fptable %>% gt(rownames_to_stub = T) %>% tab_options(table.font.size = 24)\n```\n\n## Step 4: Approach 2: Fractional Polynomials\n\n::: columns\n::: column\n```{r}\n#| echo: false\n\nlibrary(mfp)\n\nfp_model_CO2 = mfp(LifeExpectancyYrs ~ FemaleLiteracyRate + \n                     fp(CO2emissions, df = 4) + income_levels1 + four_regions +\n                     WaterSourcePrct + FoodSupplykcPPD + members_oecd_g77,\n               data = gapm2, family = \"gaussian\")\n\nfp_model_CO2$fptable %>% gt(rownames_to_stub = T) %>% tab_options(table.font.size = 24)\n```\n:::\n\n::: column \n\n-   Conclusion from fractional polynomial is that CO2 does not need to be transformed\n\n-   A little counter-intuitive to what we saw in quartiles\n\n-   Thus, I think leaving CO2 emissions as quartiles is best!\n:::\n\n:::\n\n## Step 4: Approach 3: Spline functions\n\n-   Spline function is to fit a series of smooth curves that joined at specific points (called knots)\n\n::: columns\n::: column \n![](../img_slides/spline1.png){fig-align=\"center\"}\n:::\n\n::: column \n![](../img_slides/spline2.png){fig-align=\"center\"}\n:::\n:::\n\n## Step 4: Approach 3: Spline functions\n\n-   Need to specify knots for spline functions\n\n    -   More knots are flexible, but requires more parameters to estimate\n    -   In most applications three to five knots are sufficient\n\n \n\n-   Within our class, fractional polynomials will be sufficient\n\n \n\n-   If you think this is cool, I highly suggest you look into Functional Data Analysis (FDA) or Functional Regression\n\n    -   Jeffrey Morris is a big name in that field\n\n \n\n-   In R there are a few options to incorporate splines\n\n    -   `pspline( )`: [More information](https://cran.r-project.org/web/packages/survival/vignettes/splines.pdf) \n\n    -   `smoothHR()`: [More information](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3876718/) \n\n## Step 4 Conclusion: main effects model\n\n::: columns\n::: {.column width=\"50%\"}\n-   We concluded that we will use:\n\n    -   Income levels (categorical) that Gapminder created\n    -   Quartiles for CO2 Emissions\n\n::: definition\n::: def-title\nNote\n:::\n::: def-cont\nThis is also a good step to decide if you would like to score a categorical variable (Lesson 5)\n:::\n:::\n:::\n\n- Question: Do you see any visual issues with my regression table?\n\n::: {.column width=\"50%\"}\n```{r}\ntbl_regression(\n  main_eff_model, \n  label = list(\n    FemaleLiteracyRate ~ \"Female literacy rate (%)\", \n    CO2_q ~ \"CO2 emissions quartiles\", \n    income_levels1 ~ \"Income levels\", \n    four_regions ~ \"World region\",\n    WaterSourcePrct ~ \"Access to omproved water (%)\",\n    FoodSupplykcPPD ~ \"Food supply (kcal PPD)\",\n    members_oecd_g77 ~ \"Intergovernmental group\"\n    )) %>% \n  as_gt() %>% \n  tab_options(table.font.size = 22) \n```\n:::\n:::\n\n\n# Learning Objectives\n\n1.  Understand the overall steps for purposeful selection as a model building strategy\n\n::: lob\n2.  Apply purposeful selection to a dataset using R\n:::\n\n3.  Use different approaches to assess the linear scale of continuous variables in logistic regression\n\n## Step 5: Check for interactions\n\n-   Create a list of interaction terms from variables in the \"main effects model\" that has clinical plausibility\n\n \n\n-   Add the interaction variables, one at a time, to the main effects model, and assess the significance using a F-test\n\n    -   May keep interaction terms with p-value \\< 0.10 (or 0.05)\n\n \n\n-   Keep the main effects untouched, only simplify the interaction terms\n\n \n\n-   Use methods from Step 2 (comparing model with all interactions to a smaller model with interactions) to determine which interactions to keep\n\n \n\n-   The model by the end of Step 5 is called the **preliminary final model**\n\n## Step 5: Check for interactions\n\n-   We test with $\\alpha = 0.10$\n\n-   Follow the F-test procedure in [Lesson 10 (MLR: Using the F-test)](.\\lessons\\10_MLR_F-test\\10_MLR_F-test.qmd)\n\n    -   This means we need to follow the 7 steps of the general F-test in previous slide (taken from Lesson 10)\n\n-   Use the hypothesis tests for the specific variable combo:\n\n::: columns\n::: column\n::: fact\n::: fact-title\nBinary & continuous variable (Lesson 11, LOB 2)\n:::\n\n::: fact-cont\nTesting a single coefficient for the interaction term using F-test comparing full model to reduced model\n:::\n:::\n:::\n\n::: column\n::: definition\n::: def-title\nMulti-level & continuous variables (Lesson 11, LOB 3)\n:::\n\n::: def-cont\nTesting group of coefficients for the interaction terms using F-test comparing full to reduced model\n:::\n:::\n:::\n:::\n\n::: columns\n::: column\n::: proposition\n::: prop-title\nBinary & multi-level variable (Lesson 12, LOB 4)\n:::\n\n::: prop-cont\nTesting group of coefficients for the interaction terms using F-test comparing full to reduced model\n:::\n:::\n:::\n\n::: column\n::: proof1\n::: proof-title\nTwo continuous variables (Lesson 12, LOB 5)\n:::\n\n::: proof-cont\nTesting a single coefficient for the interaction term using F-test comparing full to reduced model\n:::\n:::\n:::\n:::\n\n## Poll Everywhere Questions 6-8\n\n## Step 5: Check for interactions\n\n- Use `add1()` function to compare a full model (interactions with FLR) and reduced model (main effects model)\n\n```{r}\n#| echo: true\n\nadd1(main_eff_model, scope = ~ FemaleLiteracyRate * . ,  test = \"F\")\n```\n\n-   I went through all the ANOVA tables, and found the following significant interactions:\n\n    -   None!\n    \n-   **Think about it:** does that track with what we saw in our interactions lecture?\n\n## Step 6: Assess model fit\n\n-   Assess the adequacy of the model (diagnostics) and check its fit\n\n \n\n-   Methods for diagnostics will be discussed next class\n\n    -   Combination of diagnostics and model fit statistics!\n    \n    -   Looked at model fit statistics in last lesson\n    \n    -   Look at diagnostics in Lesson 15: MLR Diagnostics\n\n \n\n-   If the model is adequate and fits well, then it is the **Final model**\n\n## Step 6: Assess model fit\n\n```{r}\nfinal_model = main_eff_model\nprelim_me_model = model_full\nsave(final_model, prelim_me_model, gapm2, \n     file = here(\"./lessons/15_MLR_Diagnostics/final_mod.rda\"))\n```\n\n-   Our **final model** contains\n\n    -   Female Literacy Rate `FLR`\n    -   CO2 Emissions in quartiles `CO2_q`\n    -   Income levels in groups assigned by Gapminder `income_levels`\n    -   World regions `four_regions`\n    -   Membership of global and economic groups `members_oecd_g77`\n    \n        -   OECD: Organization for Economic Co-operation and Development\n        -   G77: Group of 77\n        -   Other\n        \n    -   Food Supply `FoodSupplykcPPD`\n    -   Clean Water Supply `WaterSupplePct`\n    \n## Step 6: Assess model fit: Model fit statistics\n\n-   Way I did it in the lab instructions (and last class)\n```{r}\n#| echo: true\n\nsum_fm = summary(final_model)\nmodel_fit_stats = data.frame(Model = \"Final model\", \n                             Adjusted_R_sq = sum_fm$adj.r.squared, \n                             AIC = AIC(final_model), BIC = BIC(final_model))\n\nmodel_fit_stats %>% gt() %>% \n  tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n-   Another (maybe faster?) way to do it (`glance()` in `broom` package)\n\n```{r}\n#| echo: true\nglance(final_model) %>% mutate(Model = \"Final model\") %>%\n  select(Model, adj.r.squared, AIC, BIC) %>% gt() %>% \n  tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n\n## Step 6: Assess model fit: Comparing model fits\n\n-   Remember the preliminary main effects model (at end of Step 3): same as final model but the continuous varaibles, income and CO2 emissions, were not categorized\n\n-   We can compare model fit statistics of the preliminary main effects model and the final model\n\n```{r}\n#| echo: true\nfm_glance = glance(final_model) %>% mutate(Model = \"Final model\") %>%\n  select(Model, `Adj R-squared` = adj.r.squared, AIC, BIC) \npmem_glance = glance(prelim_me_model) %>% \n  mutate(Model = \"Preliminary main effects model\") %>%\n  select(Model, `Adj R-squared` = adj.r.squared, AIC, BIC) \nrbind(fm_glance, pmem_glance) %>% gt() %>% \n  tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n-   Remember, adjusted $R^2$, AIC, and BIC penalize models for more coefficients\n\n-   Preliminary main effects model: better fit statistics, but violates linearity assumption\n\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: \"setup\" \n#| include: false\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\nlibrary(knitr)\nlibrary(broom)\nlibrary(rstatix)\nlibrary(gt)\nlibrary(readxl)\n#----------\n# new packages\n# install.packages(\"describedata\")\nlibrary(describedata) # gladder()\nlibrary(gridExtra)   # grid.arrange()\nlibrary(ggfortify)  # autoplot(model)\n# New Day 6\nlibrary(gtsummary)\n\n# New Day 7\nlibrary(plotly) # for plot_ly() command\nlibrary(GGally) # for ggpairs() command \nlibrary(ggiraphExtra)   # for ggPredict() command\n\n# Load the data - update code if the csv file is not in the same location on your computer\n# If you need to download the file, please go to ur shared folder under Data > Slides\ngapm <- read_excel(\"data/Gapminder_vars_2011.xlsx\", \n                   na = \"NA\")  # important!!!! \n\n\ngapm_sub1 <- gapm %>% # called it gapm2_sub3 to be consistent with Day 7 notes\n  mutate(four_regions = factor(four_regions, \n                               levels = c(\"africa\", \"americas\", \n                                          \"asia\", \"europe\"), \n                               labels = c(\"Africa\", \"Americas\", \n                                          \"Asia\", \"Europe\"))) %>%\n  rename(income_levels = `World bank, 4 income groups 2017`) %>%\n  mutate(income_levels1 = factor(income_levels, \n                                levels = c(\"Low income\", \n                                           \"Lower middle income\", \n                                           \"Upper middle income\", \n                                           \"High income\")) %>%\n                            relevel(ref = \"Low income\"), \n         income_levels2 = relevel(factor(income_levels, \n                                levels = c(\"Low income\", \n                                           \"Lower middle income\", \n                                           \"Upper middle income\", \n                                           \"High income\"), \n                                labels = c(\"Lower income\", \"Lower income\", \n                                            \"Higher income\", \"Higher income\")), \n                                ref = \"Lower income\")) %>%\n  mutate(population_mill = population/1000000) %>%\n  select(-population)\n\ngapm_sub <- gapm %>% # called it gapm2_sub3 to be consistent with Day 7 notes\n  drop_na(LifeExpectancyYrs, FemaleLiteracyRate, four_regions, FoodSupplykcPPD) %>%\n  mutate(four_regions = factor(four_regions, \n                               levels = c(\"africa\", \"americas\", \n                                          \"asia\", \"europe\"), \n                               labels = c(\"Africa\", \"Americas\", \n                                          \"Asia\", \"Europe\"))) %>%\n  rename(income_levels = `World bank, 4 income groups 2017`) %>%\n  mutate(income_levels1 = factor(income_levels, \n                                levels = c(\"Low income\", \n                                           \"Lower middle income\", \n                                           \"Upper middle income\", \n                                           \"High income\")), \n         income_levels2 = relevel(factor(income_levels, \n                                levels = c(\"Low income\", \n                                           \"Lower middle income\", \n                                           \"Upper middle income\", \n                                           \"High income\"), \n                                labels = c(\"Lower income\", \"Lower income\", \n                                            \"Higher income\", \"Higher income\")), \n                                ref = \"Lower income\"))\n\ngapm_ind = gapm_sub %>% select(LifeExpectancyYrs, country)\n\ngapm2 = gapm %>% select(-Longitude, -Latitude, -eight_regions, -six_regions, -geo, -`World bank, 4 income groups 2017`, -country, -population, -`World bank region`, -ElectricityUsePP)\n```\n\n# Learning Objectives\n\n1.  Understand the overall steps for purposeful selection as a model building strategy\n\n2.  Apply purposeful selection to a dataset using R\n\n3.  Use different approaches to assess the linear scale of continuous variables in logistic regression\n\n\n## Regression analysis process\n\n```{css, echo=FALSE}\n.reveal code {\n  max-height: 100% !important;\n}\n```\n\n::: box\n![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"62.1%\" width=\"155\"} ![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"28.4%\" width=\"155\"}![](../img_slides/arrow_back4.png){.absolute top=\"7.5%\" right=\"30.5%\" width=\"820\"} ![](../img_slides/arrow_down.png){.absolute top=\"60.5%\" right=\"48%\" width=\"85\"}\n\n::: columns\n::: {.column width=\"30%\"}\n::: RAP1\n::: RAP1-title\nModel Selection\n:::\n\n::: RAP1-cont\n-   Building a model\n\n-   Selecting variables\n\n-   Prediction vs interpretation\n\n-   Comparing potential models\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP2\n::: RAP2-title\nModel Fitting\n:::\n\n::: RAP2-cont\n-   Find best fit line\n\n-   Using OLS in this class\n\n-   Parameter estimation\n\n-   Categorical covariates\n\n-   Interactions\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP3\n::: RAP3-title\nModel Evaluation\n:::\n\n::: RAP3-cont\n-   Evaluation of model fit\n-   Testing model assumptions\n-   Residuals\n-   Transformations\n-   Influential points\n-   Multicollinearity\n:::\n:::\n:::\n:::\n:::\n\n::: RAP4\n::: RAP4-title\nModel Use (Inference)\n:::\n\n::: RAP4-cont\n::: columns\n::: {.column width=\"50%\"}\n-   Inference for coefficients\n-   Hypothesis testing for coefficients\n:::\n\n::: {.column width=\"50%\"}\n-   Inference for expected $Y$ given $X$\n-   Prediction of new $Y$ given $X$\n:::\n:::\n:::\n:::\n\n# Learning Objectives\n\n::: lob\n1.  Understand the overall steps for purposeful selection as a model building strategy\n:::\n\n2.  Apply purposeful selection to a dataset using R\n\n3.  Use different approaches to assess the linear scale of continuous variables in logistic regression\n\n## \n\n \n\n \n\n::: columns\n::: {.column width=\"20%\"}\n:::\n\n::: {.column width=\"60%\"}\n::: qt\n[\"Successful modeling of a complex data set is [**part science**]{style=\"color:#FF8021;\"}, [**part statistical methods**]{style=\"color:#34AC8B;\"}, and [**part experience and common sense**]{style=\"color:#4FADF3;\"}.\"]{style=\"font-size:60px;\"}\n:::\n\n \n\n::: qt-t\nHosmer, Lemeshow, and Sturdivant Textbook, pg. 101\n:::\n:::\n:::\n\n## Overall Process\n\n0.  Exploratory data analysis\n\n1.  Check unadjusted associations in simple linear regression\n\n2.  Enter all covariates in model that meet some threshold\n\n    -   [One textbook](https://onlinelibrary.wiley.com/doi/book/10.1002/9781118548387) suggest $p<0.2$ or $p<0.25$: great for modest sized datasets\n    -   PLEASE keep in mind sample size in your study\n    -   Can also use magnitude of association rather than, or along with, p-value\n\n3.  Remove those that no longer reach some threshold\n\n    -   Compare magnitude of associations to unadjusted version (univariable)\n\n4.  Check scaling of continuous and coding of categorical covariates\n\n5.  Check for interactions\n\n6.  Assess model fit\n\n    -   Model assumptions, diagnostics, overall fit\n\n## Process with snappier step names\n\n::: columns\n::: {.column width=\"10%\"}\n**Pre-step:**\n\n \n\n**Step 1:**\n\n \n\n**Step 2:**\n\n \n\n**Step 3:**\n\n \n\n**Step 4:**\n\n \n\n**Step 5:**\n\n \n\n**Step 6:**\n:::\n\n::: {.column width=\"50%\"}\nExploratory data analysis (EDA)\n\n \n\nSimple linear regressions / analysis\n\n \n\nPreliminary variable selection\n\n \n\nAssess change in coefficients\n\n \n\nAssess scale for continuous variables\n\n \n\nCheck for interactions\n\n \n\nAssess model fit\n:::\n:::\n\n# Learning Objectives\n\n1.  Understand the overall steps for purposeful selection as a model building strategy\n\n::: lob\n2.  Apply purposeful selection to a dataset using R\n:::\n\n3.  Use different approaches to assess the linear scale of continuous variables in logistic regression\n\n## Pre-step: Exploratory data analysis\n\n- The following slides are all reference until we get to Step 1\n- We have covered exploratory data analysis in other classes and have completed it in our previous labs\n\n## Pre-step: Exploratory data analysis\n\n-   Things we have been doing over the quarter in class and in our project\n\n-   I will not discuss some of the methods mentioned in our lab and data management class\n\n    -   I am only going to introduce additional exploratory functions\n\n \n\nA few things we can do:\n\n-   Check the data\n-   Study your variables\n-   Missing data?\n-   Explore simple relationships and assumptions\n\n## Pre-step: Exploratory data analysis: Check the data\n\n::: columns\n::: {.column width=\"50%\"}\n-   Get to know the potential values for the data\n\n    -   Categories\n\n    -   Units\n\n-   Then make sure the summary of values makes sense\n\n    -   If minimum or maximum look outside appropriate range\n    -   For example: a negative value for a measurement that is inherently positive (like population or income)\n:::\n\n::: {.column width=\"50%\"}\n[![https://www.gapminder.org/data/documentation/](../img_slides/Gapminder_doc.png){fig-align=\"center\"}](https://www.gapminder.org/data/documentation/)\n:::\n:::\n\n## Pre-step: Exploratory data analysis: Check the data\n\n::: columns\n::: {.column width=\"25%\"}\n-   Look at a summary for the raw data\n\n-   Typical use:\n\n```{r}\n#| echo: true\n#| output: false\nlibrary(skimr)\nskim(gapm)\n```\n\n-   [Some `skim()` help](https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html)\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"74%\"}\n:::\n:::\n\n## Pre-step: Exploratory data analysis: Check the data\n\n::: columns\n::: {.column width=\"25%\"}\n-   Look at a summary for the raw data\n\n-   Typical use:\n\n```{r}\n#| echo: true\n#| output: false\nlibrary(skimr)\nskim(gapm)\n```\n\n-   [Some `skim()` help](https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html)\n\n-   Note that `skim(gapm)` looks different because I had to create factors\n\n-   I am breaking down the `skim()` function into the categorical and continuous variables only because I want to show them on the slides\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"74%\"}\n```{r}\n#| echo: true\n#| size: small \nskim(gapm_sub1) %>% yank(\"factor\")\n```\n:::\n:::\n\n## Pre-step: Exploratory data analysis: Check the data {.smaller}\n\n```{r, skimr_digits = 2}\n#| echo: true\n#| size: small \nskim(gapm_sub1) %>% yank(\"numeric\")\n```\n\n## Poll Everywhere Question 1\n\n![](../img_slides/14_poll_ev_01.png)\n\n## Pre-step: Exploratory data analysis: Study your variables\n\n-   Started this a little bit in previous slide (`skim()`), but you may want to look at things like:\n\n    -   Sample size\n    -   Counts of missing data\n    -   Means and standard deviations\n    -   IQRs\n    -   Medians\n    -   Minimums and maximums\n\n-   Can also look at visuals\n\n    -   Continuous variables: histograms (in \\`skimr() a little)\n    -   Categorical variables: frequency plots\n\n## Pre-step: Exploratory data analysis: Study your variables {.smaller}\n\n```{r}\n#| echo: true\n\nlibrary(Hmisc)\nhist.data.frame(gapm %>% select(-Longitude, -Latitude, -eight_regions, -six_regions, -geo, -`World bank, 4 income groups 2017`, -country, -population, -`World bank region`, -ElectricityUsePP))\n```\n\n## Poll Everywhere Question 2\n\nQuestion: What function might you use to visualize or summarize the frequencies of categorical variables?\n\n## Pre-step: Exploratory data analysis: Missing data\n\n-   Why are there missing data?\n-   Which variables and observations should be excluded because of missing data?\n-   Will I impute missing data?\n\n \n\n-   Unfortunately, we don’t have time to discuss missing data more thoroughly\\\n-   I will try to cover this topic more thoroughly in BSTA 513\n\n \n\n-   For the Gapminder dataset, we chose to use complete cases\n\n## Pre-step / Step 1 : Explore simple relationships and assumptions {.smaller}\n\n```{r}\n#| fig-align: center\n#| echo: true\n\ngapm2 %>% ggpairs() # gapm2 is a new dataset with some variables selected\n```\n\n## Poll Everywhere Question 3\n\n![](../img_slides/14_poll_ev_03.png)\n\n## Step 1: Simple linear regressions / analysis\n\n-   For each covariate, we want to see how it relates to the outcome (without adjusting for other covariates)\n\n-   We can partially do this with **visualizations**\n\n    -   Helps us see the data we throw it into regression that makes assumptions (like our LINE assumptions)\n\n    -   `ggpairs()` can be a quick way to do it\n\n    -   `ggplot()` can make each plot\n\n        -   `+ geom_boxplot()` to make boxplots by groups for categorical covariates\n        -   `+ geom_jitter() + stat_summary()` to make non-overlaping points with group means for categorical covariates\n        -   `+ geom_point()` to make scatterplots for continuous covariates\n\n-   We need to run **simple linear regression**\n\n    -   We're calling regression with multi-level categories \"simple\" even though there are multiple coefficients\n\n## Step 1: Simple linear regressions / analysis\n\n-   Let's think back to our Gapminder dataset\n\n-   Always good to start with our main relationship: life expectancy vs. female literacy rate\n\n    -   *Throwback to Lesson 3 SLR when we first visualized and ran `lm()` for this relationship*\n\n```{r}\n#| echo: true\n#| eval: false\n\nmodel_FLR = lm(LifeExpectancyYrs ~ FemaleLiteracyRate, data = gapm_sub)\n```\n\n \n\n::: columns\n::: {.column width=\"45%\"}\n```{r}\n#| fig-height: 8\n#| fig-width: 11\n#| echo: false\n\nggplot(gapm_sub, aes(x = FemaleLiteracyRate,\n                 y = LifeExpectancyYrs)) +\n  geom_point(size = 4) +\n  geom_smooth(method = \"lm\", se = FALSE, size = 3, colour=\"#F14124\") +\n  labs(x = \"Female literacy rate (%)\", \n       y = \"Life expectancy (years)\",\n       title = \"Relationship between life expectancy and \\n the female literacy rate in 2011\") +\n    theme(axis.title = element_text(size = 30), \n        axis.text = element_text(size = 25), \n        title = element_text(size = 30))\n\n```\n:::\n\n::: {.column width=\"55%\"}\n```{r}\nmodel_FLR = lm(LifeExpectancyYrs ~ FemaleLiteracyRate, data = gapm_sub)\ntidy(model_FLR) %>% gt() %>% tab_options(table.font.size = 40) %>% \n  fmt_number(decimals = 3)\n```\n:::\n:::\n\n## Poll Everywhere Question 4\n\n## Step 1: Simple linear regressions / analysis\n\n-   Let's do this with one other variable before I show you a streamlined version of SLR\n\n```{r}\n#| echo: true\n\nmodel_WR = lm(LifeExpectancyYrs ~ four_regions, data = gapm_sub)\n```\n\n \n\n::: columns\n::: {.column width=\"45%\"}\n```{r fig.height=7, fig.width=7, warning=F, fig.align='center'}\n#| echo: true\n#| code-fold: true\nggplot(gapm_sub, aes(x = four_regions, y = LifeExpectancyYrs)) +\n  geom_jitter(size = 1, alpha = .6, width = 0.2) +\n  stat_summary(fun = mean, geom = \"point\", size = 8, shape = 18) +\n  labs(x = \"World region\", \n       y = \"Country life expectancy (years)\",\n       title = \"Life expectancy vs. world region\",\n       caption = \"Diamonds = region averages\") +\n  theme(axis.title = element_text(size = 20), \n        axis.text = element_text(size = 20), \n        title = element_text(size = 20))\n```\n:::\n\n::: {.column width=\"55%\"}\n```{r}\n#| echo: true\n\nanova(model_WR) %>% tidy() %>% gt() %>%\n   tab_options(table.font.size = 40) %>%\n   fmt_number(decimals = 3)\n\n```\n\n \n\n-   Recall from Lesson 5 (SLR: More inference + Evaluation):\n\n    -   `anova()` with one model name will compare the model (`model_WR`) to the intercept model\n:::\n:::\n\n```{r}\n\ngapm2 = gapm_sub %>% select(LifeExpectancyYrs, CO2emissions, FoodSupplykcPPD, \n                            IncomePP, FemaleLiteracyRate, WaterSourcePrct, \n                            four_regions, members_oecd_g77)\n```\n\n\n## Step 1: Simple linear regressions / analysis\n\n-   If we do a good job visualizing the relationship between our outcome and each covariate, then we can proceed to a streamlined version of the F-test for each relationship\n-   Run `add1()` to add each variable one at a time and separately\n- Output will include hypothesis test (using F-test) if coefficient(s) is 0 or not\n\n```{r}\n#| echo: true\n\nintercept_model = gapm2 %>% lm(formula = LifeExpectancyYrs ~ 1)\nadd1(intercept_model, scope = ~ FemaleLiteracyRate + CO2emissions + IncomePP + four_regions +\n       WaterSourcePrct + FoodSupplykcPPD + members_oecd_g77, test = \"F\")\n```\n\n## Step 2: Preliminary variable selection\n\n-   Identify candidates for your first multivariable model by performing an F-test on each covariate's SLR\n\n    -   Using p-values from previous slide\n    -   If the p-value of the test is less than 0.25, then consider the variable a candidate\n\n \n\n-   Candidates for first multivariable model\n\n    -   All clinically important variables (regardless of p-value)\n    -   Variables with univariate test with p-value \\< 0.25\n\n \n\n-   With more experience, you won’t need to rely on these strict rules as much\n\n## Step 2: Preliminary variable selection\n\n-   From the previous p-values from the F-test on each covariate's SLR\n\n    -   Decision: we keep all the covariates since they all have a p-value \\< 0.25\n\n```{r}\n#| echo: true\n\nadd1(intercept_model, scope = ~ FemaleLiteracyRate + CO2emissions + IncomePP + four_regions +\n       WaterSourcePrct + FoodSupplykcPPD + members_oecd_g77, test = \"F\")\n```\n\n## Step 2: Preliminary variable selection\n\n-   Fit an **initial model** including any independent variable with p-value \\< 0.25 and clinically important variables\n\n\n```{r}\n#| echo: true\n#| output-location: column\n\ninit_model = lm(LifeExpectancyYrs ~\n                  FemaleLiteracyRate + \n                  CO2emissions + \n                  IncomePP +\n                  four_regions + \n                  WaterSourcePrct + \n                  FoodSupplykcPPD + \n                  members_oecd_g77, \n                data = gapm2)\n\ntbl_regression(\n  init_model, \n  label = list(\n    FemaleLiteracyRate ~ \"Female literacy rate (%)\", \n    CO2emissions ~ \"CO2 emissions\", \n    IncomePP ~ \"Income  (GDP per capita)\", \n    four_regions ~ \"World region\",\n    WaterSourcePrct ~ \"Access to omproved water (%)\",\n    FoodSupplykcPPD ~ \"Food supply (kcal PPD)\",\n    members_oecd_g77 ~ \"Intergovernmental group\"\n    )) %>% \n  as_gt() %>% \n  tab_options(table.font.size = 26) \n```\n\n\n## Step 3: Assess change in coefficient\n\n::: columns\n::: {.column width=\"48%\"}\n-   This is where we start identifying covariates that we might remove\n\n \n\n-   I would start by using the p-value to guide me towards specific variables\n\n    -   Female literacy rate, but that's our main covariate\n    -   Intergovernmental group?\n    -   Maybe water source percent?\n\n \n\n-   Some people will say you can use the p-value alone\n\n    -   I like to double check that those variables do not have a large effect on the other coefficients\n:::\n\n::: {.column width=\"52%\"}\n```{r}\ntbl_regression(\n  init_model, \n  label = list(\n    FemaleLiteracyRate ~ \"Female literacy rate (%)\", \n    CO2emissions ~ \"CO2 emissions\", \n    IncomePP ~ \"Income  (GDP per capita)\", \n    four_regions ~ \"World region\",\n    WaterSourcePrct ~ \"Access to omproved water (%)\",\n    FoodSupplykcPPD ~ \"Food supply (kcal PPD)\",\n    members_oecd_g77 ~ \"Intergovernmental group\"\n    )) %>% \n  as_gt() %>% \n  tab_options(table.font.size = 26) \n```\n:::\n:::\n\n## Step 3: Assess change in coefficient\n\n-   Very similar to the process we used when looking at confounders\n\n \n\n-   One variable at a time, we run the multivariable model with and without a variable\n\n    -   We look at the p-value of the F-test for the coefficients of said variable\n    -   We look at the percent change for the coefficient ($\\Delta\\%$) of our **explanatory variable** (FLR in our example)\n\n \n\n-   General rule: We can remove a variable if...\n\n    -   p-value \\> 0.05 for the F-test of its own coefficients\n    -   AND change in coefficient ($\\Delta\\%$) of our explanatory variable is \\< 10%\n\n## F-test on dropping each covariate\n\n- Function `drop1()`: If we put in our initial model, the function will remove each covariate and perform the respective F-test to test if the coefficients are 0 (null) or not (alternative).\n```{r}\n#| echo: true\n\ndrop1(init_model, test=\"F\")\n```\n\n## Testing for percent change ( $\\Delta\\%$) in a coefficient\n\n-   Let's say we have $X_1$ and $X_2$, and we specifically want to see if $X_2$ is a confounder for $X_1$ (the explanatory variable or variable of interest)\n\n-   If we are only considering $X_1$ and $X_2$, then we need to run the following two models:\n\n    -   Fitted model 1 / reduced model (`mod1`): $\\widehat{Y} = \\widehat\\beta_0 + \\widehat\\beta_1X_1$\n\n        -   We call the above $\\widehat\\beta_1$ the reduced model coefficient: $\\widehat\\beta_{1, \\text{mod1}}$ or $\\widehat\\beta_{1, \\text{red}}$\n\n    -   Fitted model 2 / Full model (`mod2`): $\\widehat{Y} = \\widehat\\beta_0 + \\widehat\\beta_1X_1 +\\widehat\\beta_2X_2$\n\n        -   We call this $\\widehat\\beta_1$ the full model coefficient: $\\widehat\\beta_{1, \\text{mod2}}$ or $\\widehat\\beta_{1, \\text{full}}$\n\n::: columns\n::: {.column width=\"15%\"}\n:::\n\n::: {.column width=\"70%\"}\n::: fact\n::: fact-title\nCalculation for % change in coefficient\n:::\n\n::: fact-cont\n$$\n\\Delta\\% = 100\\% \\cdot\\frac{\\widehat\\beta_{1, \\text{mod1}} - \\widehat\\beta_{1, \\text{mod2}}}{\\widehat\\beta_{1, \\text{mod2}}} = 100\\% \\cdot \\frac{\\widehat\\beta_{1, \\text{red}} - \\widehat\\beta_{1, \\text{full}}}{\\widehat\\beta_{1, \\text{full}}}\n$$\n:::\n:::\n:::\n\n::: {.column width=\"15%\"}\n:::\n:::\n\n\n## Step 3: Assess change in coefficient\n\n-   Let's try this out on `members_oecd_g77`\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Display the ANOVA table with F-statistic and p-value\"\n\nmodel_full = init_model\nmodel_red = lm(LifeExpectancyYrs ~ FemaleLiteracyRate + CO2emissions + IncomePP +\n               four_regions + WaterSourcePrct + FoodSupplykcPPD, \n                 data = gapm2)\nanova(model_full, model_red) %>% tidy() %>% \n  gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Display the FLR coefficient for both models\"\n#| include: false\n\ntidy(model_full) %>% \n  gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\ntidy(model_red) %>% \n  gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n-   $\\widehat\\beta_{FLR, full} = `r round(tidy(model_full)[2,2], 4)`$, $\\widehat\\beta_{FLR, red} = `r round(tidy(model_red)[2,2], 4)`$\n\n$$\n\\Delta\\% = 100\\% \\cdot \\frac{\\widehat\\beta_{FLR, full} - \\widehat\\beta_{FLR, red}}{\\widehat\\beta_{FLR, full}} = 100\\% \\cdot \\frac{`r round(tidy(model_full)[2,2], 4)` - `r round(tidy(model_red)[2,2], 4)`}{`r round(tidy(model_full)[2,2], 4)`} = `r round(100*(tidy(model_full)[2,2] - tidy(model_red)[2,2])/tidy(model_full)[2,2], 2)`\\%\n$$\n\n-   Based off the percent change, I would keep this in the model\n\n## Step 3: Assess change in coefficient (Reference only)\n\n-   Let's try this out on water source percent (even though the p-value was \\< 0.05)\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Display the ANOVA table with F-statistic and p-value\"\n\nmodel_full = init_model\nmodel_red = lm(LifeExpectancyYrs ~ FemaleLiteracyRate + CO2emissions + IncomePP +\n               four_regions + members_oecd_g77 + FoodSupplykcPPD, \n                 data = gapm2)\nanova(model_full, model_red) %>% tidy() %>% \n  gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Display the FLR coefficient for both models\"\n#| include: false\n\ntidy(model_full) %>% \n  gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\ntidy(model_red) %>% \n  gt() %>% tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n-   $\\widehat\\beta_{FLR, full} = `r round(tidy(model_full)[2,2], 4)`$, $\\widehat\\beta_{FLR, red} = `r round(tidy(model_red)[2,2], 4)`$\n\n$$\n\\Delta\\% = 100\\% \\cdot \\frac{\\widehat\\beta_{FLR, full} - \\widehat\\beta_{FLR, red}}{\\widehat\\beta_{FLR, full}} = 100\\% \\cdot \\frac{`r round(tidy(model_full)[2,2], 4)` - `r round(tidy(model_red)[2,2], 4)`}{`r round(tidy(model_full)[2,2], 4)`} = `r round(100*(tidy(model_full)[2,2] - tidy(model_red)[2,2])/tidy(model_full)[2,2], 2)`\\%\n$$\n\n-   Based off the percent change (and p-value), I would keep this in the model\n\n## Poll Everywhere Question 5\n\n## Step 3: Assess change in coefficient: Summary\n\n-   At the end of this step, we have a **preliminary main effects model**\n\n-   Where the variables are excluded that met the following criteria:\n\n    -   P-value \\> 0.05 for the F-test of its own coefficients\n    -   Change in coefficient ($\\Delta\\%$) of our explanatory variable is \\< 10%\n\n-   In our example, the **preliminary main effects model** (end of Step 3) was the same as the **initial model** (end of Step 2)\n\n-   Preliminary main effects model includes:\n\n    -   `FemaleLiteracyRate`\n    -   `CO2emissions`\n    -   `IncomePP`\n    -   `four_regions`\n    -   `members_oecd_g77`\n    -   `FoodSupplykcPPD`\n    -   `WaterSupplePct`\n    \n    \n## Recap of Steps 1-3\n\n-   Pre-step: Exploratory data analysis\n\n-   Step 1: Simple linear regressions / analysis\n\n    -   Look at each covariate with outcome\n\n    -   Perform SLR for each covariate\n\n-   Step 2: Preliminary variable selection\n\n    -   From SLR, decide which variables go into the initial model\n\n    -   Use F-test to see if each covariate (on its own) explains enough variation in outcome\n\n    -   End with **initial model**\n        \n-   Step 3: Assess change in coefficients\n\n    -   From the initial model at end of step 2, we take a variable out of the model if:\n\n        -   P-value \\> 0.05 for the F-test of its own coefficients\n\n        -   Change in coefficient ($\\Delta\\%$) of our explanatory variable is \\< 10%\n        \n    -   End with **preliminary main effects model**\n\n# Learning Objectives\n\n1.  Understand the overall steps for purposeful selection as a model building strategy\n\n2.  Apply purposeful selection to a dataset using R\n\n::: lob\n3.  Use different approaches to assess the linear scale of continuous variables in logistic regression\n:::\n\n## Step 4: Assess scale for continuous variables\n\n-   We assume the linear regression model is linear for **each continuous variable**\n\n-   We need to assess linearity for continuous variables in the model\n\n    -   Do this through smoothed scatterplots that we introduced in Lesson 6 (SLR Diagnostics)\n    -   Residual plots (can be used in SLR) does not help us in MLR\n    -   Each term in MLR model needs to have linearity with outcome\n\n-   Three methods/approaches to address the violation of linearity assumption:\n\n    -   **Approach 1:** Categorize continuous variable\n    -   **Approach 2:** Fractional Polynomials\n    -   **Approach 3:** Spline functions\n    \n-   Approach will depend on the covariate!!\n\n-   For our class, only implement **Approach 1 or 2**\n\n-   Model at the end of Step 4 is the **main effects model**\n\n## Step 4: Assess scale for continuous variables {visibility=\"hidden\"}\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Residual plot does not help us with linearity in MLR\"\n#| fig-width: 10\n#| fig-height: 6\n#| fig-align: center\n\nlibrary(ggfortify)\nautoplot(model_full) + theme(text=element_text(size=14))\n```\n\n## Step 4: Assess scale for continuous variables: Smoothed scatterplots\n\n-   Smoother scatterplots **only check linearity**, not addressing linearity issues\n\n \n\n-   Can also identify extreme observations\n\n    -   Again, just want to flag these values \n\n    -   Can influence the assessment of linearity when using fractional polynomials or spline functions\n\n \n\n-   Helps us decide if the continuous variable can stay **as is** in the model\n\n    -   **Problem:** if not linear, then we need to represent the variable in a new way (Approaches 1-3)\n\n## Step 4: Assess scale for continuous variables: Smoothed scatterplots\n\n-   In Gapminder dataset, we have 5 continuous variables:\n\n    -   CO2 Emissions\n    -   Food Supply\n    -   Income\n    -   Female Literacy Rate\n    -   Water source percent\n\n-   Plot each of these agains the outcome, life expectancy\n\n## Step 4: Assess scale for continuous variables: Smoothed scatterplots\n\n```{r, fig.height=6, fig.width=11, fig.align='center'}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"We can quickly look at ggpairs() to identify variables\"\n\ngapm2 %>% select(where(is.numeric)) %>% \n  relocate(LifeExpectancyYrs, .after = last_col()) %>% ggpairs()\n\n```\n\n```{r}\n#| echo: false\n\ngapm2 = gapm_sub \n```\n\n## Step 4: Assess scale for continuous variables: Smoothed scatterplots\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Take a look at C02, Food Supply, and Income\"\n#| fig-width: 10\n#| fig-height: 3.5\n#| fig-align: center\n\nCO2 = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = CO2emissions)) + \n  geom_point() +\n  geom_smooth(se=F) + labs(x = \"CO2 Emissions (kt)\", y = \"Life Expectancy (yrs)\")\n\nFS = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = FoodSupplykcPPD)) + \n  geom_point() +\n  geom_smooth(se=F) + labs(x = \"Food Supply (kcal PPD)\", y = \"Life Expectancy (yrs)\")\n\nIncome = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = IncomePP)) + \n  geom_point() +\n  geom_smooth(se=F) + labs(x = \"Income (GDP per capita)\", y = \"Life Expectancy (yrs)\")\n\ngrid.arrange(CO2, FS, Income, nrow=1)\n```\n\n-   Food Supply looks admissible\n-   CO2 Emissions and Income do not look very linear, but I want to zoom into the area of the plots that have most of the data\n\n## Step 4: Assess scale for continuous variables: Smoothed scatterplots\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Zoom into areas on plots with more data\"\n#| fig-width: 10\n#| fig-height: 3.5\n#| fig-align: center\n\nCO2 = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = CO2emissions)) + \n  geom_point() + xlim(0,10) +\n  geom_smooth(se=F) + labs(x = \"CO2 Emissions (kt)\", y = \"Life Expectancy (yrs)\")\n\nFS = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = FoodSupplykcPPD)) + \n  geom_point() +\n  geom_smooth(se=F) + labs(x = \"Food Supply (kcal PPD)\", y = \"Life Expectancy (yrs)\")\n\nIncome = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = IncomePP)) + \n  geom_point() + xlim(0,40000) +\n  geom_smooth(se=F) + labs(x = \"Income (GDP per capita)\", y = \"Life Expectancy (yrs)\")\n\ngrid.arrange(CO2, FS, Income, nrow=1)\n```\n\n-   Food Supply still looks admissible\n-   CO2 Emissions and Income not linear: will address this!!\n\n## Step 4: Assess scale for continuous variables\n\n-   Three methods/approaches to address the violation of linearity assumption:\n\n     \n\n    -   **Approach 1:** Categorize continuous variable\n\n     \n\n    -   **Approach 2:** Fractional Polynomials\n    \n     \n\n    -   **Approach 3:** Spline functions\n    \n\n\n## Step 4: Approach 1: Categorize continuous variable\n\n-   Categorize continuous variables\n\n    -   Percentiles, quartiles, quantiles\n    \n        -   Create indicator variables corresponding to each quartile\n        \n    -   Meaningful thresholds\n    \n        -   Example: [income level groups](https://www.gapminder.org/fw/income-levels/) discussed by Gapminder\n        \n-   Disadvantages:\n\n    -   Takes some time to create new variables, especially with multiple continuous covariates\n\n    -   Start with quartiles, but might be more appropriate to use different splits\n\n        -   No set rules on this\n\n-   Advantage: graphical and visually helps\n\n## Step 4: Approach 1: Categorize continuous variable\n\n::: columns\n::: column\n-   For income, I would use [Gapminder's income level groups](https://www.gapminder.org/fw/income-levels/) \n\n    -   Discussed in Lesson 10 Categorical Covariates (slide 43)\n\n \n\n-   Experts in the field have developed these income groups\n\n    -   I think this is best solution for income (that was not meeting linearity as a continuous variable)\n:::\n\n::: column\n```{r fig.height=9, fig.width=8, warning=F, fig.align='center'}\n#| echo: false\nlevel_order <- c(\"Low income\", \"Lower middle income\", \n                 \"Upper middle income\", \"High income\") \nggplot(gapm2, aes(x = factor(income_levels1, level = level_order), y = LifeExpectancyYrs)) +\n  geom_jitter(size = 1, alpha = .6, width = 0.2) +\n  stat_summary(fun = mean, geom = \"point\", size = 8, shape = 18) +\n  labs(x = \"Income levels\", \n       y = \"Country life expectancy (years)\",\n       title = \"Life expectancy vs. income levels\",\n       caption = \"Diamonds = Income level averages\") +\n  theme(axis.title = element_text(size = 20), \n        axis.text = element_text(size = 20), \n        title = element_text(size = 20)) +\n  scale_x_discrete(labels = function(x) str_wrap(x, width = 10))\n```\n:::\n:::\n\n## Step 4: Approach 1: Categorize continuous variable\n\n::: columns\n::: {.column width=\"40%\"} \n-   Let's still try it out with CO2 Emissions (kt)\n\n-   I have plotted the quartile lines of food supply with red lines\n:::\n\n::: {.column width=\"60%\"} \n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Take a look at the quartiles within the scatterplot\"\n#| fig-width: 12\n#| fig-height: 8\n#| fig-align: center\n\nvline_coordinates= data.frame(Quantile_Name=names(quantile(gapm2$CO2emissions)),\n                          quantile_values=as.numeric(quantile(gapm2$CO2emissions)))\n\nggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = CO2emissions)) + \n  geom_point(size = 3) +\n  #geom_smooth(se=F) + \n  labs(x = \"CO2 Emissions (kt)\", y = \"Life Expectancy (yrs)\") +\n  geom_vline(data = vline_coordinates, aes(xintercept = quantile_values), \n             color = \"red\", linetype = \"dashed\", size = 2) +\n    theme(axis.title = element_text(size = 25), \n        axis.text = element_text(size = 25), \n        title = element_text(size = 25))\n  \n```\n\n```{r}\n#| echo: false\n#| eval: false\n#| \nvline_coordinates= data.frame(Quantile_Name=names(quantile(gapm2$IncomePP)),\n                          quantile_values=as.numeric(quantile(gapm2$IncomePP)))\n\nIncome = ggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = IncomePP)) +\n  geom_point(size = 1) +\n  #geom_smooth(se=F) +\n  labs(x = \"Income (GDP per capita)\", y = \"Life Expectancy (yrs)\")  +\n  geom_vline(data = vline_coordinates, aes(xintercept = quantile_values),\n             color = \"red\", linetype = \"dashed\", size = .9)\n\ngrid.arrange(CO2, Income, nrow=1)\n```\n:::\n\n:::\n\n## Step 4: Approach 1: Categorize continuous variable\n\n-   Let's make the quartiles for CO2 emissions:\n\n```{r}\n#| echo: true\nlibrary(dvmisc)\ngapm2 = gapm2 %>% \n  mutate(CO2_q = quant_groups(CO2emissions, groups = 4) %>% factor())\n```\n\n```{r}\n#| echo: true\n#| code-fold: true\n#| code-summary: \"Take a look at the quartile means within the scatterplot\"\n#| fig-width: 12\n#| fig-height: 8\n#| fig-align: center\n\n\nggplot(data = gapm2, aes(y = LifeExpectancyYrs, x = CO2_q)) + \n  # geom_point(size = 3, aes(y = LifeExpectancyYrs, x = CO2emissions)) +\n  stat_summary(fun = mean, geom = \"point\", size = 8, shape = 18) +\n  #geom_smooth(se=F) + \n  labs(x = \"CO2 Emissions (kt)\", y = \"Life Expectancy (yrs)\") +\n    theme(axis.title = element_text(size = 25), \n        axis.text = element_text(size = 25), \n        title = element_text(size = 25))\n```\n\n## Step 4: Approach 1: Categorize continuous variable\n\n::: columns\n::: {.column width=\"45%\"}\n\n \n\n-   Let's fit a new model with the two new representations for income and CO2 emissions\n\n \n\n-   Remember, this is the **main effects model** if we decide to make CO2 into quartiles\n\n```{r}\nmain_eff_model = lm(LifeExpectancyYrs ~ FemaleLiteracyRate + CO2_q + income_levels1 +\n               four_regions + WaterSourcePrct + FoodSupplykcPPD + members_oecd_g77, \n                 data = gapm2)\n```\n:::\n\n::: {.column width=\"55%\"}\n```{r}\ntbl_regression(\n  main_eff_model, \n  label = list(\n    FemaleLiteracyRate ~ \"Female literacy rate (%)\", \n    CO2_q ~ \"CO2 emissions quartiles\", \n    income_levels1 ~ \"Income levels\", \n    four_regions ~ \"World region\",\n    WaterSourcePrct ~ \"Access to omproved water (%)\",\n    FoodSupplykcPPD ~ \"Food supply (kcal PPD)\",\n    members_oecd_g77 ~ \"Intergovernmental group\"\n    )) %>% \n  as_gt() %>% \n  tab_options(table.font.size = 22) \n```\n:::\n:::\n\n## Step 4: Approach 2: Fractional Polynomials\n\n-   Main concepts and transformations presented in Lesson 7 SLR: Model Evaluation and Diagnostics (slide 33 on)\n\n-   Idea: test many transformations of a continuous covariate\n\n    -   [Based on Royston and Altman, Applied Statistics, 1994](https://www.jstor.org/stable/2986270)\n\n \n\n-   Recall Tukey's transformation (power) ladder\n\n    -   And can use `R`'s `gladder()` to see the transformations\n\n| Power p | -3              | -2              | -1            | -1/2                 | 0         | 1/2        | 1   | 2     | 3     |\n|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|\n|         | $\\frac{1}{x^3}$ | $\\frac{1}{x^2}$ | $\\frac{1}{x}$ | $\\frac{1}{\\sqrt{x}}$ | $\\log(x)$ | $\\sqrt{x}$ | $x$ | $x^2$ | $x^3$ |\n\n \n\n-   We can run through each and test different models, or use the approach from Lesson 7\n\n-   There is also a package we can use!\n\n    -   [mfp package in R](https://cran.r-project.org/web/packages/mfp/mfp.pdf) contains the fp() function\n\n## Step 4: Approach 2: Fractional Polynomials\n\n```{r}\n#| echo: true\n\nlibrary(mfp)\n\nfp_model_CO2 = mfp(LifeExpectancyYrs ~ FemaleLiteracyRate + \n                     fp(CO2emissions, df = 4) + income_levels1 + four_regions +\n                     WaterSourcePrct + FoodSupplykcPPD + members_oecd_g77,\n               data = gapm2, family = \"gaussian\")\n\nfp_model_CO2$fptable %>% gt(rownames_to_stub = T) %>% tab_options(table.font.size = 24)\n```\n\n## Step 4: Approach 2: Fractional Polynomials\n\n::: columns\n::: column\n```{r}\n#| echo: false\n\nlibrary(mfp)\n\nfp_model_CO2 = mfp(LifeExpectancyYrs ~ FemaleLiteracyRate + \n                     fp(CO2emissions, df = 4) + income_levels1 + four_regions +\n                     WaterSourcePrct + FoodSupplykcPPD + members_oecd_g77,\n               data = gapm2, family = \"gaussian\")\n\nfp_model_CO2$fptable %>% gt(rownames_to_stub = T) %>% tab_options(table.font.size = 24)\n```\n:::\n\n::: column \n\n-   Conclusion from fractional polynomial is that CO2 does not need to be transformed\n\n-   A little counter-intuitive to what we saw in quartiles\n\n-   Thus, I think leaving CO2 emissions as quartiles is best!\n:::\n\n:::\n\n## Step 4: Approach 3: Spline functions\n\n-   Spline function is to fit a series of smooth curves that joined at specific points (called knots)\n\n::: columns\n::: column \n![](../img_slides/spline1.png){fig-align=\"center\"}\n:::\n\n::: column \n![](../img_slides/spline2.png){fig-align=\"center\"}\n:::\n:::\n\n## Step 4: Approach 3: Spline functions\n\n-   Need to specify knots for spline functions\n\n    -   More knots are flexible, but requires more parameters to estimate\n    -   In most applications three to five knots are sufficient\n\n \n\n-   Within our class, fractional polynomials will be sufficient\n\n \n\n-   If you think this is cool, I highly suggest you look into Functional Data Analysis (FDA) or Functional Regression\n\n    -   Jeffrey Morris is a big name in that field\n\n \n\n-   In R there are a few options to incorporate splines\n\n    -   `pspline( )`: [More information](https://cran.r-project.org/web/packages/survival/vignettes/splines.pdf) \n\n    -   `smoothHR()`: [More information](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3876718/) \n\n## Step 4 Conclusion: main effects model\n\n::: columns\n::: {.column width=\"50%\"}\n-   We concluded that we will use:\n\n    -   Income levels (categorical) that Gapminder created\n    -   Quartiles for CO2 Emissions\n\n::: definition\n::: def-title\nNote\n:::\n::: def-cont\nThis is also a good step to decide if you would like to score a categorical variable (Lesson 5)\n:::\n:::\n:::\n\n- Question: Do you see any visual issues with my regression table?\n\n::: {.column width=\"50%\"}\n```{r}\ntbl_regression(\n  main_eff_model, \n  label = list(\n    FemaleLiteracyRate ~ \"Female literacy rate (%)\", \n    CO2_q ~ \"CO2 emissions quartiles\", \n    income_levels1 ~ \"Income levels\", \n    four_regions ~ \"World region\",\n    WaterSourcePrct ~ \"Access to omproved water (%)\",\n    FoodSupplykcPPD ~ \"Food supply (kcal PPD)\",\n    members_oecd_g77 ~ \"Intergovernmental group\"\n    )) %>% \n  as_gt() %>% \n  tab_options(table.font.size = 22) \n```\n:::\n:::\n\n\n# Learning Objectives\n\n1.  Understand the overall steps for purposeful selection as a model building strategy\n\n::: lob\n2.  Apply purposeful selection to a dataset using R\n:::\n\n3.  Use different approaches to assess the linear scale of continuous variables in logistic regression\n\n## Step 5: Check for interactions\n\n-   Create a list of interaction terms from variables in the \"main effects model\" that has clinical plausibility\n\n \n\n-   Add the interaction variables, one at a time, to the main effects model, and assess the significance using a F-test\n\n    -   May keep interaction terms with p-value \\< 0.10 (or 0.05)\n\n \n\n-   Keep the main effects untouched, only simplify the interaction terms\n\n \n\n-   Use methods from Step 2 (comparing model with all interactions to a smaller model with interactions) to determine which interactions to keep\n\n \n\n-   The model by the end of Step 5 is called the **preliminary final model**\n\n## Step 5: Check for interactions\n\n-   We test with $\\alpha = 0.10$\n\n-   Follow the F-test procedure in [Lesson 10 (MLR: Using the F-test)](.\\lessons\\10_MLR_F-test\\10_MLR_F-test.qmd)\n\n    -   This means we need to follow the 7 steps of the general F-test in previous slide (taken from Lesson 10)\n\n-   Use the hypothesis tests for the specific variable combo:\n\n::: columns\n::: column\n::: fact\n::: fact-title\nBinary & continuous variable (Lesson 11, LOB 2)\n:::\n\n::: fact-cont\nTesting a single coefficient for the interaction term using F-test comparing full model to reduced model\n:::\n:::\n:::\n\n::: column\n::: definition\n::: def-title\nMulti-level & continuous variables (Lesson 11, LOB 3)\n:::\n\n::: def-cont\nTesting group of coefficients for the interaction terms using F-test comparing full to reduced model\n:::\n:::\n:::\n:::\n\n::: columns\n::: column\n::: proposition\n::: prop-title\nBinary & multi-level variable (Lesson 12, LOB 4)\n:::\n\n::: prop-cont\nTesting group of coefficients for the interaction terms using F-test comparing full to reduced model\n:::\n:::\n:::\n\n::: column\n::: proof1\n::: proof-title\nTwo continuous variables (Lesson 12, LOB 5)\n:::\n\n::: proof-cont\nTesting a single coefficient for the interaction term using F-test comparing full to reduced model\n:::\n:::\n:::\n:::\n\n## Poll Everywhere Questions 6-8\n\n## Step 5: Check for interactions\n\n- Use `add1()` function to compare a full model (interactions with FLR) and reduced model (main effects model)\n\n```{r}\n#| echo: true\n\nadd1(main_eff_model, scope = ~ FemaleLiteracyRate * . ,  test = \"F\")\n```\n\n-   I went through all the ANOVA tables, and found the following significant interactions:\n\n    -   None!\n    \n-   **Think about it:** does that track with what we saw in our interactions lecture?\n\n## Step 6: Assess model fit\n\n-   Assess the adequacy of the model (diagnostics) and check its fit\n\n \n\n-   Methods for diagnostics will be discussed next class\n\n    -   Combination of diagnostics and model fit statistics!\n    \n    -   Looked at model fit statistics in last lesson\n    \n    -   Look at diagnostics in Lesson 15: MLR Diagnostics\n\n \n\n-   If the model is adequate and fits well, then it is the **Final model**\n\n## Step 6: Assess model fit\n\n```{r}\nfinal_model = main_eff_model\nprelim_me_model = model_full\nsave(final_model, prelim_me_model, gapm2, \n     file = here(\"./lessons/15_MLR_Diagnostics/final_mod.rda\"))\n```\n\n-   Our **final model** contains\n\n    -   Female Literacy Rate `FLR`\n    -   CO2 Emissions in quartiles `CO2_q`\n    -   Income levels in groups assigned by Gapminder `income_levels`\n    -   World regions `four_regions`\n    -   Membership of global and economic groups `members_oecd_g77`\n    \n        -   OECD: Organization for Economic Co-operation and Development\n        -   G77: Group of 77\n        -   Other\n        \n    -   Food Supply `FoodSupplykcPPD`\n    -   Clean Water Supply `WaterSupplePct`\n    \n## Step 6: Assess model fit: Model fit statistics\n\n-   Way I did it in the lab instructions (and last class)\n```{r}\n#| echo: true\n\nsum_fm = summary(final_model)\nmodel_fit_stats = data.frame(Model = \"Final model\", \n                             Adjusted_R_sq = sum_fm$adj.r.squared, \n                             AIC = AIC(final_model), BIC = BIC(final_model))\n\nmodel_fit_stats %>% gt() %>% \n  tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n-   Another (maybe faster?) way to do it (`glance()` in `broom` package)\n\n```{r}\n#| echo: true\nglance(final_model) %>% mutate(Model = \"Final model\") %>%\n  select(Model, adj.r.squared, AIC, BIC) %>% gt() %>% \n  tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n\n## Step 6: Assess model fit: Comparing model fits\n\n-   Remember the preliminary main effects model (at end of Step 3): same as final model but the continuous varaibles, income and CO2 emissions, were not categorized\n\n-   We can compare model fit statistics of the preliminary main effects model and the final model\n\n```{r}\n#| echo: true\nfm_glance = glance(final_model) %>% mutate(Model = \"Final model\") %>%\n  select(Model, `Adj R-squared` = adj.r.squared, AIC, BIC) \npmem_glance = glance(prelim_me_model) %>% \n  mutate(Model = \"Preliminary main effects model\") %>%\n  select(Model, `Adj R-squared` = adj.r.squared, AIC, BIC) \nrbind(fm_glance, pmem_glance) %>% gt() %>% \n  tab_options(table.font.size = 35) %>% fmt_number(decimals = 3)\n```\n\n-   Remember, adjusted $R^2$, AIC, and BIC penalize models for more coefficients\n\n-   Preliminary main effects model: better fit statistics, but violates linearity assumption\n\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":"mathjax","slide-level":2,"to":"revealjs","highlight-style":"ayu","output-file":"14_Purposeful_selection.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.8.25","auto-stretch":true,"title":"Lesson 14: Purposeful model selection","author":"Nicky Wakim","title-slide-attributes":{"data-background-color":"#213c96"},"date":"02/26/2025","theme":"../simple_NW.scss","chalkboard":true,"slideNumber":true,"showSlideNumber":"all","width":1955,"height":1100,"footer":"Lesson 14: Purposeful Selection"}}},"projectFormats":["html"]}