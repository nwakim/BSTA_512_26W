{"title":"Lesson 4: SLR Inference and Prediction","markdown":{"yaml":{"title":"Lesson 4: SLR Inference and Prediction","author":"Nicky Wakim","title-slide-attributes":{"data-background-color":"#213c96"},"date":"01/15/2025","categories":["Week 1"],"format":{"revealjs":{"theme":"../simple_NW.scss","chalkboard":true,"slide-number":true,"show-slide-number":"all","width":1955,"height":1100,"footer":"Lesson 4: SLR 2","html-math-method":"mathjax","highlight-style":"ayu"}},"execute":{"echo":true,"freeze":"auto"},"editor":{"markdown":{"wrap":72}}},"headingText":"terminal: for icons","containsRefs":false,"markdown":"\n\n```{r}\n#| label: \"setup\" \n#| include: false\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)    \nlibrary(openintro)\nlibrary(janitor)\nlibrary(rstatix)\nlibrary(knitr)\nlibrary(gtsummary)\nlibrary(moderndive)\nlibrary(gt)\nlibrary(broom) \nlibrary(here) \nlibrary(pwr) \nlibrary(gridExtra) # NEW!!!\nlibrary(readxl)\n\n# quarto install extension quarto-ext/fontawesome\n\n# set ggplot theme for slides \ntheme_set(theme_gray(base_size = 22))\n# theme_update(text = element_text(size=16))  # set global text size for ggplots\n\n```\n\n```{r}\n#| include: false\n#| message: false\n#| warning: false\ngapm1 <- read_excel(here(\"data/Gapminder_vars_2011.xlsx\"), na = \"NA\") \ngapm <- gapm1 %>% drop_na(LifeExpectancyYrs, FemaleLiteracyRate)\n```\n\n```{r}\n#| include: false\n#| message: false\n#| warning: false\n# Fit regression model:\nmodel1 <- gapm %>% lm(formula = LifeExpectancyYrs ~ FemaleLiteracyRate)\n\n# some output, but not complete\nmodel1\n```\n\n```{r}\n#| include: false\n#| message: false\n#| warning: false\nsummary(model1)\n\n# Regression table:\n# library(broom)  # for tidy() command\n# library(gt)  # for gt() command\ntidy(model1) %>% gt()\n```\n\n## Textbook readings\n\n- [Introduction to Regression Methods for Public Health Using R](https://bookdown.org/rwnahhas/RMPH/)\n  - [4.5 Interpreting p-values](https://bookdown.org/rwnahhas/RMPH/slr-pvalues.html#slr-pvalues)\n  - [4.6 Predictions from the model](https://bookdown.org/rwnahhas/RMPH/slr-prediction.html#slr-prediction)\n  - [4.7 Confidence intervals and prediction intervals](https://bookdown.org/rwnahhas/RMPH/slr-confints.html)\n  \n- [A Progressive Introduction to Linear Models](https://jfrench.github.io/LinearRegression/)\n  - Not really any good sections\n\n# Learning Objectives\n\n1.  Estimate the variance of the residuals\n2.  Using a hypothesis test, determine if there is enough evidence that\n    population slope $\\beta_1$ is not 0 (applies to $\\beta_0$ as well)\n3.  Calculate and report the estimate and confidence interval for the\n    population slope $\\beta_1$ (applies to $\\beta_0$ as well)\n4.  Calculate and report the estimate and confidence interval for the\n    expected/mean response given $X$\n    \n```{css, echo=FALSE}\n.reveal code {\n  max-height: 100% !important;\n}\n```\n    \n## Process of regression data analysis\n\n::: box\n![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"62.1%\" width=\"155\"} ![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"28.4%\" width=\"155\"}![](../img_slides/arrow_back4.png){.absolute top=\"7.5%\" right=\"30.5%\" width=\"820\"} ![](../img_slides/arrow_down.png){.absolute top=\"60.5%\" right=\"48%\" width=\"85\"}\n\n::: columns\n::: {.column width=\"30%\"}\n::: RAP1\n::: RAP1-title\nModel Selection\n:::\n\n::: RAP1-cont\n-   Building a model\n\n-   Selecting variables\n\n-   Prediction vs interpretation\n\n-   Comparing potential models\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP2\n::: RAP2-title\nModel Fitting\n:::\n\n::: RAP2-cont\n-   Find best fit line\n\n-   Using OLS in this class\n\n-   Parameter estimation\n\n-   Categorical covariates\n\n-   Interactions\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP3\n::: RAP3-title\nModel Evaluation\n:::\n\n::: RAP3-cont\n-   Evaluation of model fit\n-   Testing model assumptions\n-   Residuals\n-   Transformations\n-   Influential points\n-   Multicollinearity\n:::\n:::\n:::\n:::\n:::\n\n::: RAP4\n::: RAP4-title\nModel Use (Inference)\n:::\n\n::: RAP4-cont\n::: columns\n::: {.column width=\"50%\"}\n-   Inference for coefficients\n-   Hypothesis testing for coefficients\n:::\n\n::: {.column width=\"50%\"}\n-   Inference for expected $Y$ given $X$\n-   Prediction of new $Y$ given $X$\n:::\n:::\n:::\n:::\n\n\n## Let's remind ourselves of the model that we fit last lesson\n\n-   We fit Gapminder data with female literacy rate as our independent\n    variable and life expectancy as our dependent variable\n\n-   We used OLS to find the coefficient estimates of our best-fit line\n\n::: columns\n::: {.column width=\"58%\"}\n```{r}\nmodel1 <- gapm %>% lm(formula = LifeExpectancyYrs ~ FemaleLiteracyRate)\n# Get regression table:\ntidy(model1) %>% gt() %>% \n tab_options(table.font.size = 40) %>%\n fmt_number(decimals = 2)\n```\n\n```{=tex}\n\\begin{aligned}\n\\widehat{Y} &= \\widehat\\beta_0 + \\widehat\\beta_1 \\cdot X\\\\\n\\widehat{\\text{life expectancy}} &= 50.9 + 0.232 \\cdot \\text{female literacy rate}\n\\end{aligned}\n```\n:::\n\n::: {.column width=\"2%\"}\n:::\n\n::: {.column width=\"40%\"}\n```{r}\n#| fig-height: 8\n#| fig-width: 11\n#| echo: false\n\ngapm_slr_plot = gapm %>%\n  ggplot(aes(x = FemaleLiteracyRate,\n             y = LifeExpectancyYrs)) +\n  geom_point(size = 4) +\n  geom_smooth(method = \"lm\", se = FALSE, size = 3, colour=\"#F14124\") +\n  labs(x = \"Female literacy rate (%)\", \n       y = \"Life expectancy (years)\",\n       title = \"Relationship between life expectancy and \\n the female literacy rate in 2011\") +\n    theme(axis.title = element_text(size = 30), \n        axis.text = element_text(size = 25), \n        title = element_text(size = 30))\n\ngapm_slr_plot\n```\n:::\n:::\n\n## Fitted line is derived from the population SLR model\n\n \n\nThe (population) regression model is denoted by:\n\n::: heq\n$$Y =  \\beta_0 + \\beta_1X + \\epsilon$$\n:::\n\n-   $\\beta_0$ and $\\beta_1$ are **unknown** population parameters\n\n-   $\\epsilon$ (epsilon) is the error about the line\n\n    -   It is assumed to be a random variable with a...\n\n        -   Normal distribution with mean 0 and constant variance\n            $\\sigma^2$\n\n        -   i.e. $\\epsilon \\sim N(0, \\sigma^2)$\n\n## Poll Everywhere Question 1\n\n# Learning Objectives\n\n::: lob\n1.  Estimate the variance of the residuals\n:::\n\n2.  Using a hypothesis test, determine if there is enough evidence that\n    population slope $\\beta_1$ is not 0 (applies to $\\beta_0$ as well)\n3.  Calculate and report the estimate and confidence interval for the\n    population slope $\\beta_1$ (applies to $\\beta_0$ as well)\n4.  Calculate and report the estimate and confidence interval for the\n    expected/mean response given $X$\n\n## $\\widehat\\sigma^2$: Needed ingredient for inference\n\n-   Recall our population model residuals are distributed by\n    $\\epsilon \\sim N(0, \\sigma^2)$\n    -   And our estimated residuals are\n        $\\widehat\\epsilon \\sim N(0, \\widehat\\sigma^2)$\n-   Hence, the *variance* of the errors (residuals) is estimated by\n    $\\widehat{\\sigma}^2$\n\n::: heq\n$$\\widehat{\\sigma}^2 = S_{y|x}^2= \\frac{1}{n-2}\\sum_{i=1}^n (Y_i - \\widehat{Y}_i)^2 =\\frac{1}{n-2}SSE = MSE$$\n:::\n\n## $\\widehat\\sigma^2$: I hope R can calculate that for me... (1/2)\n\n-   The *standard deviation* $\\widehat{\\sigma}$ is given in the R output\n    as the `Residual standard error`\n\n    -   $4^{th}$ line from the bottom in the `summary()` output of the\n        model:\n\n\n```{r}\nsummary(model1)\n```\n\n## $\\widehat\\sigma^2$: I hope R can calculate that for me... (2/2)\n\n- It can!!\n\n```{r}\nm1_sum = summary(model1)\nm1_sum$sigma\n# number of observations (pairs of data) used to run the model\nnobs(model1) \n```\n\n## $\\widehat\\sigma^2$ to SSE\n\n-   Recall how we minimized the SSE to find our line of best fit\n-   SSE and $\\widehat\\sigma^2$ are closely related:\n\n$$\\begin{aligned}\n\\widehat{\\sigma}^2 & = \\frac{1}{n-2}SSE\\\\\n6.142^2 & = \\frac{1}{80-2}SSE\\\\\nSSE & = 78 \\cdot 6.142^2 = 2942.48 \n\\end{aligned}$$\n\n-   2942.48 is the smallest sums of squares of all possible regression\n    lines through the data\n\n# Learning Objectives\n\n1.  Estimate the variance of the residuals\n\n::: lob\n2.  Using a hypothesis test, determine if there is enough evidence\n        that population slope $\\beta_1$ is not 0 (applies to $\\beta_0$\n        as well)\n\n3.  Calculate and report the estimate and confidence interval for\n        the population slope $\\beta_1$ (applies to $\\beta_0$ as well)\n:::\n\n4.  Calculate and report the estimate and confidence interval for the\n    expected/mean response given $X$\n\n## Do we trust our estimate $\\widehat\\beta_1$?\n\n-   So far, we have shown that we think the estimate is 0.232 \n\n \n\n-   $\\widehat\\beta_1$ (coefficient estimate) uses our sample data to estimate the population parameter $\\beta_1$\n\n \n\n-   Inference helps us figure out *mathematically* how much we trust our best-fit line \n\n \n\n-   Are we certain that the relationship between $X$ and $Y$ that we estimated reflects the true, underlying relationship?\n\n## Poll Everywhere Question 2\n\n## Inference for the population **slope**: hypothesis test and CI\n\n::: columns\n::: {.column width=\"45%\"}\n::: fact\n::: fact-title\nPopulation model\n:::\n\n::: fact-cont\n*line + random \"noise\"*\n\n$$Y = \\beta_0 + \\beta_1 \\cdot X + \\varepsilon$$ with\n$\\varepsilon \\sim N(0,\\sigma^2)$\\\n$\\sigma^2$ is the variance of the residuals\n:::\n:::\n\n::: proposition\n::: prop-title\nSample best-fit (least-squares) line\n:::\n\n::: prop-cont\n$$\\widehat{Y} = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X $$\n\nNote: Some sources use $b$ instead of $\\widehat{\\beta}$\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"50%\"}\n \n\nWe have two options for inference:\n\n1.  Conduct the **hypothesis test**\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1 = 0\\\\\n\\text{vs. } H_A&: \\beta_1 \\neq 0\n\\end{align}\n```\n<br>\n\n*Note: R reports p-values for 2-sided tests*\n\n2.  Construct a **95% confidence interval** for the **population slope**\n    $\\beta_1$\n\n<br>\n:::\n:::\n\n# Learning Objectives\n\n1.  Estimate the variance of the residuals\n\n::: lob\n2.  Using a hypothesis test, determine if there is enough evidence that\n    population slope $\\beta_1$ is not 0 (applies to $\\beta_0$ as well)\n:::\n\n3.  Calculate and report the estimate and confidence interval for the\n    population slope $\\beta_1$ (applies to $\\beta_0$ as well)\n4.  Calculate and report the estimate and confidence interval for the\n    expected/mean response given $X$\n\n## Reference: Steps in a Hypothesis Test\n\n1.  Check the [**assumptions**]{style=\"color:#4FADF3\"}\n\n    - What sampling distribution are you using? What assumptions are required for it?\n\n2.  Set the [**level of significance**]{style=\"color:#4FADF3\"} $\\alpha$\n\n3.  Specify the [**null**]{style=\"color:#4FADF3\"} ( $H_0$ ) and [**alternative**]{style=\"color:#4FADF3\"} ( $H_A$ ) [**hypotheses**]{style=\"color:#4FADF3\"}\n\n    -  In symbols and/or in words\n    -  Alternative: one- or two-sided?\n\n4.  Specify the test statistic and its [**distribution under the null**]{style=\"color:#4FADF3\"}\n\n5.  Calculate the [**test statistic**]{style=\"color:#4FADF3\"}.\n\n6.  Calculate the [**p-value**]{style=\"color:#4FADF3\"} based on the observed test statistic and its sampling distribution\n\n7.  Write a [**conclusion**]{style=\"color:#4FADF3\"} to the hypothesis test\n\n    -  Do we reject or fail to reject $H_0$?\n    -  Write a conclusion in the context of the problem\n    \n\n\n## Steps for hypothesis test for population **slope** $\\beta_1$ (using t-test)\n\n::: columns\n::: {.column width=\"48%\"}\n\n1.  Check the [**assumptions**]{style=\"color:#4FADF3\"}\n\n2.  Set the [**level of significance**]{style=\"color:#4FADF3\"}\n\n    - Often we use $\\alpha = 0.05$\n\n3.  Specify the [**null**]{style=\"color:#4FADF3\"} ( $H_0$ ) and [**alternative**]{style=\"color:#4FADF3\"} ( $H_A$ ) [**hypotheses**]{style=\"color:#4FADF3\"}\n\n    - Often, we are curious if the coefficient is 0 or not:\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1 = 0\\\\\n\\text{vs. } H_A&: \\beta_1 \\neq 0\n\\end{align}\n```\n\n4.  Specify the test statistic and its [**distribution under the null**]{style=\"color:#4FADF3\"}\n\n    - The test statistic is $t$, and follows a Student's t-distribution.\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n\n5.  Calculate the [**test statistic**]{style=\"color:#4FADF3\"}.\n\n    - The calculated **test statistic** for $\\widehat\\beta_1$ is $$t = \\frac{ \\widehat\\beta_1 - \\beta_1}{ \\text{SE}_{\\widehat\\beta_1}} = \\frac{ \\widehat\\beta_1}{ \\text{SE}_{\\widehat\\beta_1}}$$ when we assume $H_0: \\beta_1 = 0$ is true.\n\n6.  Calculate the [**p-value**]{style=\"color:#4FADF3\"}\n\n    - We are generally calculating: $2\\cdot P(T > t)$\n\n7.  Write a [**conclusion**]{style=\"color:#4FADF3\"}\n\n    - We (reject/fail to reject) the null hypothesis that the slope is 0 at the $100\\alpha\\%$ significiance level. There is (sufficient/insufficient) evidence that there is significant association between ($Y$) and ($X$) (p-value = $P(T > t)$).\n:::\n:::\n\n## Standard error of fitted slope $\\widehat\\beta_1$\n\n![](../img_slides/pause.png){.absolute top=\"1%\" right=\"0%\" width=\"120\" height=\"120\"}\n\n   \n\n::: columns\n::: {.column width=\"50%\"}\n$$\\text{SE}_{\\widehat\\beta_1} = \\frac{s_{\\textrm{residuals}}}{s_x\\sqrt{n-1}}$$\n:::\n\n::: {.column width=\"50%\"}\n$\\text{SE}_{\\widehat\\beta_1}$ is the **variability** of the statistic\n$\\widehat\\beta_1$\n:::\n:::\n\n   \n\n::: {style=\"font-size: 90%;\"}\n::: columns\n::: {.column width=\"32%\"}\n-   $s_{\\textrm{residuals}}^2$ is the sd of the residuals\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"32%\"}\n-   $s_x$ is the sample sd of the explanatory variable $x$\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"32%\"}\n-   $n$ is the sample size, or the number of (complete) pairs of points\n:::\n:::\n:::\n\n## Calculating standard error for $\\widehat\\beta_1$ (1/2)\n\n![](../img_slides/pause.png){.absolute top=\"1%\" right=\"0%\" width=\"120\" height=\"120\"}\n\n-   **Option 1:** Calculate using the formula\n\n```{r}\nglance(model1)\n\n# standard deviation of the residuals (Residual standard error in summary() output)\n(s_resid <- glance(model1)$sigma)\n\n# standard deviation of x's\n(s_x <- sd(gapm$FemaleLiteracyRate, na.rm=T))\n\n# number of pairs of complete observations\n(n <- nobs(model1))\n\n(se_b1 <- s_resid/(s_x * sqrt(n-1))) # compare to SE in regression output\n```\n\n## Calculating standard error for $\\widehat\\beta_1$ (2/2)\n\n![](../img_slides/pause.png){.absolute top=\"1%\" right=\"0%\" width=\"120\" height=\"120\"}\n\n-   **Option 2:** Use regression table\n\n```{r}\n# recall model1_b1 is regression table restricted to b1 row\nmodel1_b1 <-tidy(model1) %>% filter(term == \"FemaleLiteracyRate\")\nmodel1_b1 %>% gt() %>%\n  tab_options(table.font.size = 45) %>% fmt_number(decimals = 4)\n```\n\n## Some important notes\n\n-   Today we are discussing the hypothesis test for a **single**\n    coefficient\n\n \n\n-   The test statistic for a single coefficient follows a Student's\n    t-distribution\n\n     \n\n    -   It can also follow an F-distribution, but we will discuss this\n        more with multiple linear regression and multi-level categorical\n        covariates\n\n \n\n-   Single coefficient testing can be done on any coefficient, but it is\n    most useful for continuous covariates or binary covariates\n\n     \n\n    -   This is because testing the single coefficient will still tell\n        us something about the overall relationship between the\n        covariate and the outcome\n\n     \n\n    -   We will talk more about this with multiple linear regression and\n        multi-level categorical covariates\n\n## Poll Everywhere Question 3\n\n## Life expectancy example: hypothesis test for population **slope** $\\beta_1$ (1/4)\n\n-   Steps 1-4 are setting up our hypothesis test: not much change from\n    the general steps\n\n::: highlight-container\n::: highlight\n1.  For today's class, we are assuming that we have met the underlying\n    assumptions (checked in our Model Evaluation step)\n:::\n:::\n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis.\n:::\n:::\n\nWe are testing if the slope is 0 or not:\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1 = 0\\\\\n\\text{vs. } H_A&: \\beta_1 \\neq 0\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level.\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $t$, and follows a Student's t-distribution.\n\n## Life expectancy example: hypothesis test for population **slope** $\\beta_1$ (2/4)\n\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic\n:::\n:::\n\n-   **Option 1:** Calculate the test statistic using the values in the\n    regression table\n\n```{r}\n# recall model1_b1 is regression table restricted to b1 row\nmodel1_b1 <-tidy(model1) %>% filter(term == \"FemaleLiteracyRate\")\nmodel1_b1 %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 2)\n(TestStat_b1 <- model1_b1$estimate / model1_b1$std.error)\n```\n\n-   **Option 2:** Get the test statistic value ($t^*$) from `R`\n\n```{r}\nmodel1_b1 %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 2)\n```\n\n## Life expectancy example: hypothesis test for population **slope** $\\beta_1$ (3/4)\n\n::: highlight-container\n::: highlight\n6.  Calculate the p-value\n:::\n:::\n\n-   The $p$-value is the *probability of obtaining a test statistic*\n    **just as extreme or more extreme** *than the **observed** test\n    statistic assuming the null hypothesis* $H_0$ *is true*\n\n-   We know the probability distribution of the test statistic (the\n    *null distribution*) assuming $H_0$ is true\n\n-   Statistical theory tells us that the test statistic $t$ can be\n    modeled by a $t$-distribution with $df = n-2$.\n\n    -   We had 80 countries' data, so $n=80$\n\n-   **Option 1:** Use `pt()` and our calculated test statistic\n\n```{r}\n(pv = 2*pt(TestStat_b1, df=80-2, lower.tail=F))\n```\n\n-   **Option 2:** Use the regression table output\n\n```{r}\nmodel1_b1 %>% gt() %>%\n  tab_options(table.font.size = 40)\n```\n\n## Life expectancy example: hypothesis test for population **slope** $\\beta_1$ (4/4)\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for the hypothesis test\n:::\n:::\n\nWe reject the null hypothesis that the slope is 0 at the $5\\%$\nsignificance level. There is sufficient evidence that there is\nsignificant association between female life expectancy and female\nliteracy rates (p-value \\< 0.0001).\n\n## Note on hypothesis testing using `R`\n\n-   We can basically skip Step 5 if we are using the \"Option 2\" route\n\n \n\n-   In our assignments: if you use Option 2, Step 5 is optional\n\n    -   Unless I specifically ask for the test statistic!!\n\n## Life expectancy ex: hypothesis test for population **intercept** $\\beta_0$ (1/4)\n\n-   Steps 1-4 are setting up our hypothesis test: not much change from\n    the general steps\n\n::: highlight-container\n::: highlight\n1.  For today's class, we are assuming that we have met the underlying\n    assumptions (checked in our Model Evaluation step)\n:::\n:::\n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis.\n:::\n:::\n\nWe are testing if the intercept is 0 or not:\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_0 = 0\\\\\n\\text{vs. } H_A&: \\beta_0 \\neq 0\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThis is the same as the slope. The test statistic is $t$, and follows a\nStudent's t-distribution.\n\n## Life expectancy ex: hypothesis test for population **intercept** $\\beta_0$ (2/4)\n\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic\n:::\n:::\n\n-   **Option 1:** Calculate the test statistic using the values in the\n    regression table\n\n```{r}\n# recall model1_b1 is regression table restricted to b1 row\nmodel1_b0 <-tidy(model1) %>% filter(term == \"(Intercept)\")\nmodel1_b0 %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 2)\n(TestStat_b0 <- model1_b0$estimate / model1_b0$std.error)\n```\n\n-   **Option 2:** Get the test statistic value ($t^*$) from `R`\n\n```{r}\nmodel1_b0 %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 2)\n```\n\n## Life expectancy ex: hypothesis test for population **intercept** $\\beta_0$ (3/4)\n\n::: highlight-container\n::: highlight\n6.  Calculate the p-value\n:::\n:::\n\n \n\n-   **Option 1:** Use `pt()` and our calculated test statistic\n\n```{r}\n(pv = 2*pt(TestStat_b0, df=80-2, lower.tail=F))\n```\n\n \n\n-   **Option 2:** Use the regression table output\n\n```{r}\nmodel1_b0 %>% gt() %>%\n  tab_options(table.font.size = 40)\n```\n\n## Life expectancy ex: hypothesis test for population **intercept** $\\beta_0$ (4/4)\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for the hypothesis test\n:::\n:::\n\nWe reject the null hypothesis that the intercept is 0 at the $5\\%$\nsignificance level. There is sufficient evidence that the intercept for\nthe association between average female life expectancy and female\nliteracy rates is different from 0 (p-value \\< 0.0001).\n\n   \n\n-   Note: if we fail to reject $H_0$, then we could decide to remove the\n    intercept from the model to force the regression line to go through\n    the origin (0,0) if it makes sense to do so for the application.\n\n# Learning Objectives\n\n1.  Estimate the variance of the residuals\n2.  Using a hypothesis test, determine if there is enough evidence that\n    population slope $\\beta_1$ is not 0 (applies to $\\beta_0$ as well)\n    \n::: lob\n3.  Calculate and report the estimate and confidence interval for the\n    population slope $\\beta_1$ (applies to $\\beta_0$ as well)\n:::\n\n4.  Calculate and report the estimate and confidence interval for the\n    expected/mean response given $X$\n\n## Inference for the population **slope**: hypothesis test and CI\n\n::: columns\n::: {.column width=\"45%\"}\n::: fact\n::: fact-title\nPopulation model\n:::\n\n::: fact-cont\n*line + random \"noise\"*\n\n$$Y = \\beta_0 + \\beta_1 \\cdot X + \\varepsilon$$ with\n$\\varepsilon \\sim N(0,\\sigma^2)$\\\n$\\sigma^2$ is the variance of the residuals\n:::\n:::\n\n::: proposition\n::: prop-title\nSample best-fit (least-squares) line\n:::\n\n::: prop-cont\n$$\\widehat{Y} = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X $$\n\nNote: Some sources use $b$ instead of $\\widehat{\\beta}$\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"50%\"}\n \n\nWe have two options for inference:\n\n1.  Conduct the **hypothesis test**\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1 = 0\\\\\n\\text{vs. } H_A&: \\beta_1 \\neq 0\n\\end{align}\n```\n<br>\n\n*Note: R reports p-values for 2-sided tests*\n\n2.  Construct a **95% confidence interval** for the **population slope**\n    $\\beta_1$\n\n<br>\n:::\n:::\n\n## Confidence interval for population **slope** $\\beta_1$\n\nRecall the general CI formula:\n\n$$\\widehat{\\beta}_1 \\pm t_{\\alpha, n-2}^* \\cdot SE_{\\widehat{\\beta}_1}$$\n\nTo construct the confidence interval, we need to:\n\n-   Set our $\\alpha$-level\n\n-   Find $\\widehat\\beta_1$\n\n-   Calculate the $t_{n-2}^*$\n\n-   Calculate $SE_{\\widehat{\\beta}_1}$\n\n## Calculate CI for population **slope** $\\beta_1$ (1/2)\n\n::: columns\n::: {.column width=\"50%\"}\n$$\\widehat{\\beta}_1  \\pm t^*\\cdot SE_{\\beta_1}$$\n:::\n\n::: {.column width=\"50%\"}\nwhere $t^*$ is the $t$-distribution critical value with $df = n -2$.\n:::\n:::\n\n-   **Option 1:** Calculate using each value\n\nSave values needed for CI:\n\n```{r}\nb1 <- model1_b1$estimate\nSE_b1 <- model1_b1$std.error\n```\n\n```{r}\nnobs(model1) # sample size n\n(tstar <- qt(.975, df = 80-2))\n```\n\nUse formula to calculate each bound\n\n```{r}\n(CI_LB <- b1 - tstar*SE_b1)\n(CI_UB <- b1 + tstar*SE_b1)\n```\n\n## Calculate CI for population **slope** $\\beta_1$ (2/2)\n\n::: columns\n::: {.column width=\"50%\"}\n$$\\widehat{\\beta}_1  \\pm t^*\\cdot SE_{\\beta_1}$$\n:::\n\n::: {.column width=\"50%\"}\nwhere $t^*$ is the $t$-distribution critical value with $df = n -2$.\n:::\n:::\n\n-   **Option 2:** Use the regression table\n\n```{r}\ntidy(model1, conf.int = T) %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 3)\n```\n\n## Interpreting the coefficient estimate of the population slope with CIs\n\n-   When we report our results to someone else, we don't usually show\n    them our full hypothesis test\n\n    -   In an informal setting, someone may want to see it\n\n-   Typically, we report the estimate with the confidence interval\n\n    -   From the confidence interval, your audience can also deduce the\n        results of a hypothesis test\n\n-   Once we found our CI, we often just write the interpretation of the\n    coefficient estimate:\n\n::: definition\n::: def-title\nGeneral statement for population slope inference\n:::\n\n::: def-cont\nFor every increase of 1 unit in the $X$-variable, there is an expected/average (pick one) increase of $\\widehat\\beta_1$ units in the $Y$-variable (95%:\nLB, UB).\n:::\n:::\n\n-   **In our example:** For every 1% increase in female literacy rate, life expectancy increases, on average,\n    0.232 years (95% CI: 0.170, 0.295).\n    \n## Usually three options for your interpretations\n\n- **Option 1:** For every 1% increase in female literacy rate, life expectancy increases, **on average**,\n    0.232 years (95% CI: 0.170, 0.295).\n    \n \n\n- **Option 2:** For every 1% increase in female literacy rate, **average** life expectancy increases\n    0.232 years (95% CI: 0.170, 0.295).\n    \n \n\n- **Option 3:** For every 1% increase in female literacy rate, **expected** life expectancy increases\n    0.232 years (95% CI: 0.170, 0.295).\n\n## Poll Everywhere Question 4\n\n## For reference: quick CI for $\\beta_0$\n\n-   Calculate CI for population **intercept** $\\beta_0$:\n    $\\widehat{\\beta}_0 \\pm t^*\\cdot SE_{\\beta_0}$\n\nwhere $t^*$ is the $t$-distribution critical value with $df = n -2$\n\n-   Use the regression table\n\n```{r}\ntidy(model1, conf.int = T) %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 3)\n```\n\n::: definition\n::: def-title\nGeneral statement for population intercept inference\n:::\n\n::: def-cont\nThe expected outcome for the $Y$-variable is ($\\widehat\\beta_0$) when\nthe $X$-variable is 0 (95% CI: LB, UB).\n:::\n:::\n\n-   **For example:** The expected/average life expectancy is 50.9 years\n    when the female literacy rate is 0 (95% CI: 45.63, 56.22).\n\n# Learning Objectives\n\n1.  Estimate the variance of the residuals\n2.  Using a hypothesis test, determine if there is enough evidence that\n    population slope $\\beta_1$ is not 0 (applies to $\\beta_0$ as well)\n3.  Calculate and report the estimate and confidence interval for the\n    population slope $\\beta_1$ (applies to $\\beta_0$ as well)\n\n::: lob\n4.  Calculate and report the estimate and confidence interval for the\n    expected/mean response given $X$\n:::\n\n## Finding a mean response given a value of our independent variable\n\n```{r}\n#| echo: false\ntidy(model1) %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 3)\n```\n\n$$\\widehat{\\textrm{life expectancy}} = 50.9 + 0.232 \\cdot \\textrm{female literacy rate} $$\n\n-   What is the expected/predicted life expectancy for a country with\n    female literacy rate 60%?\n\n$$\\widehat{\\textrm{life expectancy}} = 50.9 + 0.232 \\cdot 60 = `r 50.9 + 0.232*60`$$\n\n```{r}\n(y_60 <- 50.9 + 0.232*60)\n```\n\n-   How do we interpret the expected value?\n\n    -   We sometimes call this \"predicted\" value, since we can\n        technically use a literacy rate that is not in our sample\n\n-   How variable is it?\n\n## Mean response/prediction with regression line\n\n::: columns\n::: {.column width=\"55%\"}\nRecall the population model:\n\n*line + random \"noise\"*\n\n$$Y = \\beta_0 + \\beta_1 \\cdot X + \\varepsilon$$ with\n$\\varepsilon \\sim N(0,\\sigma^2)$\n\n<br>\n\n-   When we take the expected value, at a given value $X^*$, the average\n    expected response at $X^*$ is:\n\n$$\\widehat{E}[Y|X^*] = \\widehat\\beta_0 + \\widehat\\beta_1 X^*$$\n:::\n\n::: {.column width=\"45%\"}\n```{r}\n#| echo: false\n#| fig.height: 8.0\n#| fig.width: 8.0\n\ngapm %>%\n  ggplot(aes(x = FemaleLiteracyRate,\n                 y = LifeExpectancyYrs)) +\n  geom_point(size=2) +\n  labs(x = \"Female literacy rate (%)\", \n       y = \"Life expectancy (years)\",\n       title = \"Life expectancy vs. female literacy rate\") +  \n  geom_smooth(method = \"lm\", se = TRUE, size =3, color = \"#F14124\") +\n  geom_vline(xintercept = 60, color = \"#A7EA52\", size = 3)\n```\n:::\n:::\n\n-   These are the points on the regression line\n-   The mean responses have variability, and we can calculate a CI for\n    it, for every value of $X^*$\n\n## CI for population mean response ($E[Y|X^*]$ or $\\mu_{Y|X^*})$\n\n$$\\widehat{E}[Y|X^*] \\pm t_{n-2}^* \\cdot SE_{\\widehat{E}[Y|X^*]}$$\n\n$$SE_{\\widehat{E}[Y|X^*]} = s_{\\text{residuals}} \\sqrt{\\frac{1}{n} + \\frac{(X^* - \\overline{X})^2}{(n-1)s_X^2}}$$\n\n-   $\\widehat{E}[Y|X^*]$ is the predicted value at the specified point\n    $X^*$ of the explanatory variable\n-   $s_{\\textrm{residuals}}^2$ is the sd of the residuals\n-   $n$ is the sample size, or the number of (complete) pairs of points\n-   $\\overline{X}$ is the sample mean of the explanatory variable $x$\n-   $s_X$ is the sample sd of the explanatory variable $X$\n\n<br>\n\n-   Recall that $t_{n-2}^*$ is calculated using `qt()` and depends on\n    the confidence level ($1-\\alpha$)\n\n## Example Option 1: CI for mean response $\\mu_{Y|X^*}$\n\n**Find the 95% CI for the mean life expectancy when the female literacy\nrate is 60.**\n\n::: {style=\"font-size: 70%;\"}\n```{=tex}\n\\begin{align}\n\\widehat{E}[Y|X^*] &\\pm t_{n-2}^* \\cdot SE_{\\widehat{E}[Y|X^*]}\\\\\n64.8596 &\\pm 1.990847 \\cdot s_{residuals} \\sqrt{\\frac{1}{n} + \\frac{(X^* - \\bar{x})^2}{(n-1)s_x^2}}\\\\\n64.8596 &\\pm 1.990847 \\cdot 6.142157 \\sqrt{\\frac{1}{80} + \\frac{(60 - 81.65375)^2}{(80-1)21.95371^2}}\\\\\n64.8596 &\\pm 1.990847 \\cdot 0.9675541\\\\\n64.8596 &\\pm 1.926252\\\\\n(62.93335 &, 66.78586)\n\\end{align}\n```\n:::\n\n::: {style=\"font-size: 90%;\"}\n::: columns\n::: {.column width=\"50%\"}\n```{r}\n(Y60 <- 50.9278981 + 0.2321951 * 60)\n(tstar <- qt(.975, df = 78))\n(s_resid <- glance(model1)$sigma)\n```\n:::\n\n::: {.column width=\"50%\"}\n```{r}\n(n <- nobs(model1))\n(mx <- mean(gapm$FemaleLiteracyRate, na.rm=T))\n(s_x <- sd(gapm$FemaleLiteracyRate, na.rm=T))\n```\n:::\n:::\n\n```{r}\n(SE_Yx <- s_resid *sqrt(1/n + (60 - mx)^2/((n-1)*s_x^2)))\n```\n\n::: columns\n::: {.column width=\"32%\"}\n```{r}\n(MOE_Yx <- SE_Yx*tstar)\n```\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"32%\"}\n```{r}\nY60 - MOE_Yx\n```\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"32%\"}\n```{r}\nY60 + MOE_Yx\n```\n:::\n:::\n:::\n\n## Example Option 2: CI for mean response $\\mu_{Y|X^*}$\n\n**Find the 95% CI's for the mean life expectancy when the female\nliteracy rate is 60 and 80.**\n\n-   Use the base R `predict()` function\n-   Requires specification of a `newdata` \"value\"\n    -   The `newdata` value is $X^*$\n    -   This has to be in the format of a data frame though\n    -   with column name identical to the predictor variable in the\n        model\n\n```{r}\nnewdata <- data.frame(FemaleLiteracyRate = c(60, 80)) \nnewdata\n```\n\n::: columns\n::: {.column width=\"50%\"}\n```{r}\npredict(model1, \n        newdata=newdata, \n        interval=\"confidence\")\n```\n:::\n\n::: {.column width=\"50%\"}\n::: fact\n::: fact-title\nInterpretation\n:::\n\n::: fact-cont\nWe are 95% confident that the **average** life expectancy for a country\nwith a 60% female literacy rate will be between 62.9 and 66.8 years.\n:::\n:::\n:::\n:::\n\n## Poll Everywhere Question 5\n\n\n## Confidence bands for mean response $\\mu_{Y|X^*}$\n\n-   Often we plot the CI for many values of X, creating **confidence\n    bands**\n-   The confidence bands are what ggplot creates when we set `se = TRUE`\n    within `geom_smooth`\n-   Think about it: for what values of X are the confidence bands\n    (intervals) narrowest?\n\n```{r}\n#| fig-align: center\n\ngapm %>%\n  ggplot(aes(x=FemaleLiteracyRate, \n             y=LifeExpectancyYrs)) +\n  geom_point()+\n  geom_smooth(method = lm, se=TRUE)+\n  ggtitle(\"Life expectancy vs. female literacy rate\") \n```\n\n## Width of confidence bands for mean response $\\mu_{Y|X^*}$\n\n-   For what values of $X^*$ are the confidence bands (intervals)\n    narrowest? widest?\n\n```{=tex}\n\\begin{align}\n\\widehat{E}[Y|X^*] &\\pm t_{n-2}^* \\cdot SE_{\\widehat{E}[Y|X^*]}\\\\\n\\widehat{E}[Y|X^*] &\\pm t_{n-2}^* \\cdot s_{residuals} \\sqrt{\\frac{1}{n} + \\frac{(X^* - \\bar{x})^2}{(n-1)s_x^2}}\n\\end{align}\n```\n```{r}\n#| echo: false\n#| fig-align: center\n\ngapm %>%\n  ggplot(aes(x = FemaleLiteracyRate,\n                 y = LifeExpectancyYrs)) +\n  geom_point(size = 4) +\n  geom_smooth(method = \"lm\", se = TRUE, size = 3, colour=\"#F14124\") +\n  labs(x = \"Female literacy rate (%)\", \n       y = \"Life expectancy (years)\",\n       title = \"Relationship between life expectancy and female literacy rate in 2011\") +\n    theme(axis.title = element_text(size = 20), \n        axis.text = element_text(size = 20), \n        title = element_text(size = 17)) +\n  geom_vline(xintercept = mx, color = \"purple\", size = 3)\n\n```\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: \"setup\" \n#| include: false\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)    \nlibrary(openintro)\nlibrary(janitor)\nlibrary(rstatix)\nlibrary(knitr)\nlibrary(gtsummary)\nlibrary(moderndive)\nlibrary(gt)\nlibrary(broom) \nlibrary(here) \nlibrary(pwr) \nlibrary(gridExtra) # NEW!!!\nlibrary(readxl)\n\n# terminal: for icons\n# quarto install extension quarto-ext/fontawesome\n\n# set ggplot theme for slides \ntheme_set(theme_gray(base_size = 22))\n# theme_update(text = element_text(size=16))  # set global text size for ggplots\n\n```\n\n```{r}\n#| include: false\n#| message: false\n#| warning: false\ngapm1 <- read_excel(here(\"data/Gapminder_vars_2011.xlsx\"), na = \"NA\") \ngapm <- gapm1 %>% drop_na(LifeExpectancyYrs, FemaleLiteracyRate)\n```\n\n```{r}\n#| include: false\n#| message: false\n#| warning: false\n# Fit regression model:\nmodel1 <- gapm %>% lm(formula = LifeExpectancyYrs ~ FemaleLiteracyRate)\n\n# some output, but not complete\nmodel1\n```\n\n```{r}\n#| include: false\n#| message: false\n#| warning: false\nsummary(model1)\n\n# Regression table:\n# library(broom)  # for tidy() command\n# library(gt)  # for gt() command\ntidy(model1) %>% gt()\n```\n\n## Textbook readings\n\n- [Introduction to Regression Methods for Public Health Using R](https://bookdown.org/rwnahhas/RMPH/)\n  - [4.5 Interpreting p-values](https://bookdown.org/rwnahhas/RMPH/slr-pvalues.html#slr-pvalues)\n  - [4.6 Predictions from the model](https://bookdown.org/rwnahhas/RMPH/slr-prediction.html#slr-prediction)\n  - [4.7 Confidence intervals and prediction intervals](https://bookdown.org/rwnahhas/RMPH/slr-confints.html)\n  \n- [A Progressive Introduction to Linear Models](https://jfrench.github.io/LinearRegression/)\n  - Not really any good sections\n\n# Learning Objectives\n\n1.  Estimate the variance of the residuals\n2.  Using a hypothesis test, determine if there is enough evidence that\n    population slope $\\beta_1$ is not 0 (applies to $\\beta_0$ as well)\n3.  Calculate and report the estimate and confidence interval for the\n    population slope $\\beta_1$ (applies to $\\beta_0$ as well)\n4.  Calculate and report the estimate and confidence interval for the\n    expected/mean response given $X$\n    \n```{css, echo=FALSE}\n.reveal code {\n  max-height: 100% !important;\n}\n```\n    \n## Process of regression data analysis\n\n::: box\n![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"62.1%\" width=\"155\"} ![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"28.4%\" width=\"155\"}![](../img_slides/arrow_back4.png){.absolute top=\"7.5%\" right=\"30.5%\" width=\"820\"} ![](../img_slides/arrow_down.png){.absolute top=\"60.5%\" right=\"48%\" width=\"85\"}\n\n::: columns\n::: {.column width=\"30%\"}\n::: RAP1\n::: RAP1-title\nModel Selection\n:::\n\n::: RAP1-cont\n-   Building a model\n\n-   Selecting variables\n\n-   Prediction vs interpretation\n\n-   Comparing potential models\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP2\n::: RAP2-title\nModel Fitting\n:::\n\n::: RAP2-cont\n-   Find best fit line\n\n-   Using OLS in this class\n\n-   Parameter estimation\n\n-   Categorical covariates\n\n-   Interactions\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP3\n::: RAP3-title\nModel Evaluation\n:::\n\n::: RAP3-cont\n-   Evaluation of model fit\n-   Testing model assumptions\n-   Residuals\n-   Transformations\n-   Influential points\n-   Multicollinearity\n:::\n:::\n:::\n:::\n:::\n\n::: RAP4\n::: RAP4-title\nModel Use (Inference)\n:::\n\n::: RAP4-cont\n::: columns\n::: {.column width=\"50%\"}\n-   Inference for coefficients\n-   Hypothesis testing for coefficients\n:::\n\n::: {.column width=\"50%\"}\n-   Inference for expected $Y$ given $X$\n-   Prediction of new $Y$ given $X$\n:::\n:::\n:::\n:::\n\n\n## Let's remind ourselves of the model that we fit last lesson\n\n-   We fit Gapminder data with female literacy rate as our independent\n    variable and life expectancy as our dependent variable\n\n-   We used OLS to find the coefficient estimates of our best-fit line\n\n::: columns\n::: {.column width=\"58%\"}\n```{r}\nmodel1 <- gapm %>% lm(formula = LifeExpectancyYrs ~ FemaleLiteracyRate)\n# Get regression table:\ntidy(model1) %>% gt() %>% \n tab_options(table.font.size = 40) %>%\n fmt_number(decimals = 2)\n```\n\n```{=tex}\n\\begin{aligned}\n\\widehat{Y} &= \\widehat\\beta_0 + \\widehat\\beta_1 \\cdot X\\\\\n\\widehat{\\text{life expectancy}} &= 50.9 + 0.232 \\cdot \\text{female literacy rate}\n\\end{aligned}\n```\n:::\n\n::: {.column width=\"2%\"}\n:::\n\n::: {.column width=\"40%\"}\n```{r}\n#| fig-height: 8\n#| fig-width: 11\n#| echo: false\n\ngapm_slr_plot = gapm %>%\n  ggplot(aes(x = FemaleLiteracyRate,\n             y = LifeExpectancyYrs)) +\n  geom_point(size = 4) +\n  geom_smooth(method = \"lm\", se = FALSE, size = 3, colour=\"#F14124\") +\n  labs(x = \"Female literacy rate (%)\", \n       y = \"Life expectancy (years)\",\n       title = \"Relationship between life expectancy and \\n the female literacy rate in 2011\") +\n    theme(axis.title = element_text(size = 30), \n        axis.text = element_text(size = 25), \n        title = element_text(size = 30))\n\ngapm_slr_plot\n```\n:::\n:::\n\n## Fitted line is derived from the population SLR model\n\n \n\nThe (population) regression model is denoted by:\n\n::: heq\n$$Y =  \\beta_0 + \\beta_1X + \\epsilon$$\n:::\n\n-   $\\beta_0$ and $\\beta_1$ are **unknown** population parameters\n\n-   $\\epsilon$ (epsilon) is the error about the line\n\n    -   It is assumed to be a random variable with a...\n\n        -   Normal distribution with mean 0 and constant variance\n            $\\sigma^2$\n\n        -   i.e. $\\epsilon \\sim N(0, \\sigma^2)$\n\n## Poll Everywhere Question 1\n\n# Learning Objectives\n\n::: lob\n1.  Estimate the variance of the residuals\n:::\n\n2.  Using a hypothesis test, determine if there is enough evidence that\n    population slope $\\beta_1$ is not 0 (applies to $\\beta_0$ as well)\n3.  Calculate and report the estimate and confidence interval for the\n    population slope $\\beta_1$ (applies to $\\beta_0$ as well)\n4.  Calculate and report the estimate and confidence interval for the\n    expected/mean response given $X$\n\n## $\\widehat\\sigma^2$: Needed ingredient for inference\n\n-   Recall our population model residuals are distributed by\n    $\\epsilon \\sim N(0, \\sigma^2)$\n    -   And our estimated residuals are\n        $\\widehat\\epsilon \\sim N(0, \\widehat\\sigma^2)$\n-   Hence, the *variance* of the errors (residuals) is estimated by\n    $\\widehat{\\sigma}^2$\n\n::: heq\n$$\\widehat{\\sigma}^2 = S_{y|x}^2= \\frac{1}{n-2}\\sum_{i=1}^n (Y_i - \\widehat{Y}_i)^2 =\\frac{1}{n-2}SSE = MSE$$\n:::\n\n## $\\widehat\\sigma^2$: I hope R can calculate that for me... (1/2)\n\n-   The *standard deviation* $\\widehat{\\sigma}$ is given in the R output\n    as the `Residual standard error`\n\n    -   $4^{th}$ line from the bottom in the `summary()` output of the\n        model:\n\n\n```{r}\nsummary(model1)\n```\n\n## $\\widehat\\sigma^2$: I hope R can calculate that for me... (2/2)\n\n- It can!!\n\n```{r}\nm1_sum = summary(model1)\nm1_sum$sigma\n# number of observations (pairs of data) used to run the model\nnobs(model1) \n```\n\n## $\\widehat\\sigma^2$ to SSE\n\n-   Recall how we minimized the SSE to find our line of best fit\n-   SSE and $\\widehat\\sigma^2$ are closely related:\n\n$$\\begin{aligned}\n\\widehat{\\sigma}^2 & = \\frac{1}{n-2}SSE\\\\\n6.142^2 & = \\frac{1}{80-2}SSE\\\\\nSSE & = 78 \\cdot 6.142^2 = 2942.48 \n\\end{aligned}$$\n\n-   2942.48 is the smallest sums of squares of all possible regression\n    lines through the data\n\n# Learning Objectives\n\n1.  Estimate the variance of the residuals\n\n::: lob\n2.  Using a hypothesis test, determine if there is enough evidence\n        that population slope $\\beta_1$ is not 0 (applies to $\\beta_0$\n        as well)\n\n3.  Calculate and report the estimate and confidence interval for\n        the population slope $\\beta_1$ (applies to $\\beta_0$ as well)\n:::\n\n4.  Calculate and report the estimate and confidence interval for the\n    expected/mean response given $X$\n\n## Do we trust our estimate $\\widehat\\beta_1$?\n\n-   So far, we have shown that we think the estimate is 0.232 \n\n \n\n-   $\\widehat\\beta_1$ (coefficient estimate) uses our sample data to estimate the population parameter $\\beta_1$\n\n \n\n-   Inference helps us figure out *mathematically* how much we trust our best-fit line \n\n \n\n-   Are we certain that the relationship between $X$ and $Y$ that we estimated reflects the true, underlying relationship?\n\n## Poll Everywhere Question 2\n\n## Inference for the population **slope**: hypothesis test and CI\n\n::: columns\n::: {.column width=\"45%\"}\n::: fact\n::: fact-title\nPopulation model\n:::\n\n::: fact-cont\n*line + random \"noise\"*\n\n$$Y = \\beta_0 + \\beta_1 \\cdot X + \\varepsilon$$ with\n$\\varepsilon \\sim N(0,\\sigma^2)$\\\n$\\sigma^2$ is the variance of the residuals\n:::\n:::\n\n::: proposition\n::: prop-title\nSample best-fit (least-squares) line\n:::\n\n::: prop-cont\n$$\\widehat{Y} = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X $$\n\nNote: Some sources use $b$ instead of $\\widehat{\\beta}$\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"50%\"}\n \n\nWe have two options for inference:\n\n1.  Conduct the **hypothesis test**\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1 = 0\\\\\n\\text{vs. } H_A&: \\beta_1 \\neq 0\n\\end{align}\n```\n<br>\n\n*Note: R reports p-values for 2-sided tests*\n\n2.  Construct a **95% confidence interval** for the **population slope**\n    $\\beta_1$\n\n<br>\n:::\n:::\n\n# Learning Objectives\n\n1.  Estimate the variance of the residuals\n\n::: lob\n2.  Using a hypothesis test, determine if there is enough evidence that\n    population slope $\\beta_1$ is not 0 (applies to $\\beta_0$ as well)\n:::\n\n3.  Calculate and report the estimate and confidence interval for the\n    population slope $\\beta_1$ (applies to $\\beta_0$ as well)\n4.  Calculate and report the estimate and confidence interval for the\n    expected/mean response given $X$\n\n## Reference: Steps in a Hypothesis Test\n\n1.  Check the [**assumptions**]{style=\"color:#4FADF3\"}\n\n    - What sampling distribution are you using? What assumptions are required for it?\n\n2.  Set the [**level of significance**]{style=\"color:#4FADF3\"} $\\alpha$\n\n3.  Specify the [**null**]{style=\"color:#4FADF3\"} ( $H_0$ ) and [**alternative**]{style=\"color:#4FADF3\"} ( $H_A$ ) [**hypotheses**]{style=\"color:#4FADF3\"}\n\n    -  In symbols and/or in words\n    -  Alternative: one- or two-sided?\n\n4.  Specify the test statistic and its [**distribution under the null**]{style=\"color:#4FADF3\"}\n\n5.  Calculate the [**test statistic**]{style=\"color:#4FADF3\"}.\n\n6.  Calculate the [**p-value**]{style=\"color:#4FADF3\"} based on the observed test statistic and its sampling distribution\n\n7.  Write a [**conclusion**]{style=\"color:#4FADF3\"} to the hypothesis test\n\n    -  Do we reject or fail to reject $H_0$?\n    -  Write a conclusion in the context of the problem\n    \n\n\n## Steps for hypothesis test for population **slope** $\\beta_1$ (using t-test)\n\n::: columns\n::: {.column width=\"48%\"}\n\n1.  Check the [**assumptions**]{style=\"color:#4FADF3\"}\n\n2.  Set the [**level of significance**]{style=\"color:#4FADF3\"}\n\n    - Often we use $\\alpha = 0.05$\n\n3.  Specify the [**null**]{style=\"color:#4FADF3\"} ( $H_0$ ) and [**alternative**]{style=\"color:#4FADF3\"} ( $H_A$ ) [**hypotheses**]{style=\"color:#4FADF3\"}\n\n    - Often, we are curious if the coefficient is 0 or not:\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1 = 0\\\\\n\\text{vs. } H_A&: \\beta_1 \\neq 0\n\\end{align}\n```\n\n4.  Specify the test statistic and its [**distribution under the null**]{style=\"color:#4FADF3\"}\n\n    - The test statistic is $t$, and follows a Student's t-distribution.\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"48%\"}\n\n5.  Calculate the [**test statistic**]{style=\"color:#4FADF3\"}.\n\n    - The calculated **test statistic** for $\\widehat\\beta_1$ is $$t = \\frac{ \\widehat\\beta_1 - \\beta_1}{ \\text{SE}_{\\widehat\\beta_1}} = \\frac{ \\widehat\\beta_1}{ \\text{SE}_{\\widehat\\beta_1}}$$ when we assume $H_0: \\beta_1 = 0$ is true.\n\n6.  Calculate the [**p-value**]{style=\"color:#4FADF3\"}\n\n    - We are generally calculating: $2\\cdot P(T > t)$\n\n7.  Write a [**conclusion**]{style=\"color:#4FADF3\"}\n\n    - We (reject/fail to reject) the null hypothesis that the slope is 0 at the $100\\alpha\\%$ significiance level. There is (sufficient/insufficient) evidence that there is significant association between ($Y$) and ($X$) (p-value = $P(T > t)$).\n:::\n:::\n\n## Standard error of fitted slope $\\widehat\\beta_1$\n\n![](../img_slides/pause.png){.absolute top=\"1%\" right=\"0%\" width=\"120\" height=\"120\"}\n\n   \n\n::: columns\n::: {.column width=\"50%\"}\n$$\\text{SE}_{\\widehat\\beta_1} = \\frac{s_{\\textrm{residuals}}}{s_x\\sqrt{n-1}}$$\n:::\n\n::: {.column width=\"50%\"}\n$\\text{SE}_{\\widehat\\beta_1}$ is the **variability** of the statistic\n$\\widehat\\beta_1$\n:::\n:::\n\n   \n\n::: {style=\"font-size: 90%;\"}\n::: columns\n::: {.column width=\"32%\"}\n-   $s_{\\textrm{residuals}}^2$ is the sd of the residuals\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"32%\"}\n-   $s_x$ is the sample sd of the explanatory variable $x$\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"32%\"}\n-   $n$ is the sample size, or the number of (complete) pairs of points\n:::\n:::\n:::\n\n## Calculating standard error for $\\widehat\\beta_1$ (1/2)\n\n![](../img_slides/pause.png){.absolute top=\"1%\" right=\"0%\" width=\"120\" height=\"120\"}\n\n-   **Option 1:** Calculate using the formula\n\n```{r}\nglance(model1)\n\n# standard deviation of the residuals (Residual standard error in summary() output)\n(s_resid <- glance(model1)$sigma)\n\n# standard deviation of x's\n(s_x <- sd(gapm$FemaleLiteracyRate, na.rm=T))\n\n# number of pairs of complete observations\n(n <- nobs(model1))\n\n(se_b1 <- s_resid/(s_x * sqrt(n-1))) # compare to SE in regression output\n```\n\n## Calculating standard error for $\\widehat\\beta_1$ (2/2)\n\n![](../img_slides/pause.png){.absolute top=\"1%\" right=\"0%\" width=\"120\" height=\"120\"}\n\n-   **Option 2:** Use regression table\n\n```{r}\n# recall model1_b1 is regression table restricted to b1 row\nmodel1_b1 <-tidy(model1) %>% filter(term == \"FemaleLiteracyRate\")\nmodel1_b1 %>% gt() %>%\n  tab_options(table.font.size = 45) %>% fmt_number(decimals = 4)\n```\n\n## Some important notes\n\n-   Today we are discussing the hypothesis test for a **single**\n    coefficient\n\n \n\n-   The test statistic for a single coefficient follows a Student's\n    t-distribution\n\n     \n\n    -   It can also follow an F-distribution, but we will discuss this\n        more with multiple linear regression and multi-level categorical\n        covariates\n\n \n\n-   Single coefficient testing can be done on any coefficient, but it is\n    most useful for continuous covariates or binary covariates\n\n     \n\n    -   This is because testing the single coefficient will still tell\n        us something about the overall relationship between the\n        covariate and the outcome\n\n     \n\n    -   We will talk more about this with multiple linear regression and\n        multi-level categorical covariates\n\n## Poll Everywhere Question 3\n\n## Life expectancy example: hypothesis test for population **slope** $\\beta_1$ (1/4)\n\n-   Steps 1-4 are setting up our hypothesis test: not much change from\n    the general steps\n\n::: highlight-container\n::: highlight\n1.  For today's class, we are assuming that we have met the underlying\n    assumptions (checked in our Model Evaluation step)\n:::\n:::\n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis.\n:::\n:::\n\nWe are testing if the slope is 0 or not:\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1 = 0\\\\\n\\text{vs. } H_A&: \\beta_1 \\neq 0\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level.\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThe test statistic is $t$, and follows a Student's t-distribution.\n\n## Life expectancy example: hypothesis test for population **slope** $\\beta_1$ (2/4)\n\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic\n:::\n:::\n\n-   **Option 1:** Calculate the test statistic using the values in the\n    regression table\n\n```{r}\n# recall model1_b1 is regression table restricted to b1 row\nmodel1_b1 <-tidy(model1) %>% filter(term == \"FemaleLiteracyRate\")\nmodel1_b1 %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 2)\n(TestStat_b1 <- model1_b1$estimate / model1_b1$std.error)\n```\n\n-   **Option 2:** Get the test statistic value ($t^*$) from `R`\n\n```{r}\nmodel1_b1 %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 2)\n```\n\n## Life expectancy example: hypothesis test for population **slope** $\\beta_1$ (3/4)\n\n::: highlight-container\n::: highlight\n6.  Calculate the p-value\n:::\n:::\n\n-   The $p$-value is the *probability of obtaining a test statistic*\n    **just as extreme or more extreme** *than the **observed** test\n    statistic assuming the null hypothesis* $H_0$ *is true*\n\n-   We know the probability distribution of the test statistic (the\n    *null distribution*) assuming $H_0$ is true\n\n-   Statistical theory tells us that the test statistic $t$ can be\n    modeled by a $t$-distribution with $df = n-2$.\n\n    -   We had 80 countries' data, so $n=80$\n\n-   **Option 1:** Use `pt()` and our calculated test statistic\n\n```{r}\n(pv = 2*pt(TestStat_b1, df=80-2, lower.tail=F))\n```\n\n-   **Option 2:** Use the regression table output\n\n```{r}\nmodel1_b1 %>% gt() %>%\n  tab_options(table.font.size = 40)\n```\n\n## Life expectancy example: hypothesis test for population **slope** $\\beta_1$ (4/4)\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for the hypothesis test\n:::\n:::\n\nWe reject the null hypothesis that the slope is 0 at the $5\\%$\nsignificance level. There is sufficient evidence that there is\nsignificant association between female life expectancy and female\nliteracy rates (p-value \\< 0.0001).\n\n## Note on hypothesis testing using `R`\n\n-   We can basically skip Step 5 if we are using the \"Option 2\" route\n\n \n\n-   In our assignments: if you use Option 2, Step 5 is optional\n\n    -   Unless I specifically ask for the test statistic!!\n\n## Life expectancy ex: hypothesis test for population **intercept** $\\beta_0$ (1/4)\n\n-   Steps 1-4 are setting up our hypothesis test: not much change from\n    the general steps\n\n::: highlight-container\n::: highlight\n1.  For today's class, we are assuming that we have met the underlying\n    assumptions (checked in our Model Evaluation step)\n:::\n:::\n\n::: highlight-container\n::: highlight\n2.  State the null hypothesis.\n:::\n:::\n\nWe are testing if the intercept is 0 or not:\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_0 = 0\\\\\n\\text{vs. } H_A&: \\beta_0 \\neq 0\n\\end{align}\n```\n::: highlight-container\n::: highlight\n3.  Specify the significance level\n:::\n:::\n\nOften we use $\\alpha = 0.05$\n\n::: highlight-container\n::: highlight\n4.  Specify the test statistic and its distribution under the null\n:::\n:::\n\nThis is the same as the slope. The test statistic is $t$, and follows a\nStudent's t-distribution.\n\n## Life expectancy ex: hypothesis test for population **intercept** $\\beta_0$ (2/4)\n\n::: highlight-container\n::: highlight\n5.  Compute the value of the test statistic\n:::\n:::\n\n-   **Option 1:** Calculate the test statistic using the values in the\n    regression table\n\n```{r}\n# recall model1_b1 is regression table restricted to b1 row\nmodel1_b0 <-tidy(model1) %>% filter(term == \"(Intercept)\")\nmodel1_b0 %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 2)\n(TestStat_b0 <- model1_b0$estimate / model1_b0$std.error)\n```\n\n-   **Option 2:** Get the test statistic value ($t^*$) from `R`\n\n```{r}\nmodel1_b0 %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 2)\n```\n\n## Life expectancy ex: hypothesis test for population **intercept** $\\beta_0$ (3/4)\n\n::: highlight-container\n::: highlight\n6.  Calculate the p-value\n:::\n:::\n\n \n\n-   **Option 1:** Use `pt()` and our calculated test statistic\n\n```{r}\n(pv = 2*pt(TestStat_b0, df=80-2, lower.tail=F))\n```\n\n \n\n-   **Option 2:** Use the regression table output\n\n```{r}\nmodel1_b0 %>% gt() %>%\n  tab_options(table.font.size = 40)\n```\n\n## Life expectancy ex: hypothesis test for population **intercept** $\\beta_0$ (4/4)\n\n::: highlight-container\n::: highlight\n7.  Write conclusion for the hypothesis test\n:::\n:::\n\nWe reject the null hypothesis that the intercept is 0 at the $5\\%$\nsignificance level. There is sufficient evidence that the intercept for\nthe association between average female life expectancy and female\nliteracy rates is different from 0 (p-value \\< 0.0001).\n\n   \n\n-   Note: if we fail to reject $H_0$, then we could decide to remove the\n    intercept from the model to force the regression line to go through\n    the origin (0,0) if it makes sense to do so for the application.\n\n# Learning Objectives\n\n1.  Estimate the variance of the residuals\n2.  Using a hypothesis test, determine if there is enough evidence that\n    population slope $\\beta_1$ is not 0 (applies to $\\beta_0$ as well)\n    \n::: lob\n3.  Calculate and report the estimate and confidence interval for the\n    population slope $\\beta_1$ (applies to $\\beta_0$ as well)\n:::\n\n4.  Calculate and report the estimate and confidence interval for the\n    expected/mean response given $X$\n\n## Inference for the population **slope**: hypothesis test and CI\n\n::: columns\n::: {.column width=\"45%\"}\n::: fact\n::: fact-title\nPopulation model\n:::\n\n::: fact-cont\n*line + random \"noise\"*\n\n$$Y = \\beta_0 + \\beta_1 \\cdot X + \\varepsilon$$ with\n$\\varepsilon \\sim N(0,\\sigma^2)$\\\n$\\sigma^2$ is the variance of the residuals\n:::\n:::\n\n::: proposition\n::: prop-title\nSample best-fit (least-squares) line\n:::\n\n::: prop-cont\n$$\\widehat{Y} = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 \\cdot X $$\n\nNote: Some sources use $b$ instead of $\\widehat{\\beta}$\n:::\n:::\n:::\n\n::: {.column width=\"5%\"}\n:::\n\n::: {.column width=\"50%\"}\n \n\nWe have two options for inference:\n\n1.  Conduct the **hypothesis test**\n\n```{=tex}\n\\begin{align}\nH_0 &: \\beta_1 = 0\\\\\n\\text{vs. } H_A&: \\beta_1 \\neq 0\n\\end{align}\n```\n<br>\n\n*Note: R reports p-values for 2-sided tests*\n\n2.  Construct a **95% confidence interval** for the **population slope**\n    $\\beta_1$\n\n<br>\n:::\n:::\n\n## Confidence interval for population **slope** $\\beta_1$\n\nRecall the general CI formula:\n\n$$\\widehat{\\beta}_1 \\pm t_{\\alpha, n-2}^* \\cdot SE_{\\widehat{\\beta}_1}$$\n\nTo construct the confidence interval, we need to:\n\n-   Set our $\\alpha$-level\n\n-   Find $\\widehat\\beta_1$\n\n-   Calculate the $t_{n-2}^*$\n\n-   Calculate $SE_{\\widehat{\\beta}_1}$\n\n## Calculate CI for population **slope** $\\beta_1$ (1/2)\n\n::: columns\n::: {.column width=\"50%\"}\n$$\\widehat{\\beta}_1  \\pm t^*\\cdot SE_{\\beta_1}$$\n:::\n\n::: {.column width=\"50%\"}\nwhere $t^*$ is the $t$-distribution critical value with $df = n -2$.\n:::\n:::\n\n-   **Option 1:** Calculate using each value\n\nSave values needed for CI:\n\n```{r}\nb1 <- model1_b1$estimate\nSE_b1 <- model1_b1$std.error\n```\n\n```{r}\nnobs(model1) # sample size n\n(tstar <- qt(.975, df = 80-2))\n```\n\nUse formula to calculate each bound\n\n```{r}\n(CI_LB <- b1 - tstar*SE_b1)\n(CI_UB <- b1 + tstar*SE_b1)\n```\n\n## Calculate CI for population **slope** $\\beta_1$ (2/2)\n\n::: columns\n::: {.column width=\"50%\"}\n$$\\widehat{\\beta}_1  \\pm t^*\\cdot SE_{\\beta_1}$$\n:::\n\n::: {.column width=\"50%\"}\nwhere $t^*$ is the $t$-distribution critical value with $df = n -2$.\n:::\n:::\n\n-   **Option 2:** Use the regression table\n\n```{r}\ntidy(model1, conf.int = T) %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 3)\n```\n\n## Interpreting the coefficient estimate of the population slope with CIs\n\n-   When we report our results to someone else, we don't usually show\n    them our full hypothesis test\n\n    -   In an informal setting, someone may want to see it\n\n-   Typically, we report the estimate with the confidence interval\n\n    -   From the confidence interval, your audience can also deduce the\n        results of a hypothesis test\n\n-   Once we found our CI, we often just write the interpretation of the\n    coefficient estimate:\n\n::: definition\n::: def-title\nGeneral statement for population slope inference\n:::\n\n::: def-cont\nFor every increase of 1 unit in the $X$-variable, there is an expected/average (pick one) increase of $\\widehat\\beta_1$ units in the $Y$-variable (95%:\nLB, UB).\n:::\n:::\n\n-   **In our example:** For every 1% increase in female literacy rate, life expectancy increases, on average,\n    0.232 years (95% CI: 0.170, 0.295).\n    \n## Usually three options for your interpretations\n\n- **Option 1:** For every 1% increase in female literacy rate, life expectancy increases, **on average**,\n    0.232 years (95% CI: 0.170, 0.295).\n    \n \n\n- **Option 2:** For every 1% increase in female literacy rate, **average** life expectancy increases\n    0.232 years (95% CI: 0.170, 0.295).\n    \n \n\n- **Option 3:** For every 1% increase in female literacy rate, **expected** life expectancy increases\n    0.232 years (95% CI: 0.170, 0.295).\n\n## Poll Everywhere Question 4\n\n## For reference: quick CI for $\\beta_0$\n\n-   Calculate CI for population **intercept** $\\beta_0$:\n    $\\widehat{\\beta}_0 \\pm t^*\\cdot SE_{\\beta_0}$\n\nwhere $t^*$ is the $t$-distribution critical value with $df = n -2$\n\n-   Use the regression table\n\n```{r}\ntidy(model1, conf.int = T) %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 3)\n```\n\n::: definition\n::: def-title\nGeneral statement for population intercept inference\n:::\n\n::: def-cont\nThe expected outcome for the $Y$-variable is ($\\widehat\\beta_0$) when\nthe $X$-variable is 0 (95% CI: LB, UB).\n:::\n:::\n\n-   **For example:** The expected/average life expectancy is 50.9 years\n    when the female literacy rate is 0 (95% CI: 45.63, 56.22).\n\n# Learning Objectives\n\n1.  Estimate the variance of the residuals\n2.  Using a hypothesis test, determine if there is enough evidence that\n    population slope $\\beta_1$ is not 0 (applies to $\\beta_0$ as well)\n3.  Calculate and report the estimate and confidence interval for the\n    population slope $\\beta_1$ (applies to $\\beta_0$ as well)\n\n::: lob\n4.  Calculate and report the estimate and confidence interval for the\n    expected/mean response given $X$\n:::\n\n## Finding a mean response given a value of our independent variable\n\n```{r}\n#| echo: false\ntidy(model1) %>% gt() %>%\n  tab_options(table.font.size = 40) %>% fmt_number(decimals = 3)\n```\n\n$$\\widehat{\\textrm{life expectancy}} = 50.9 + 0.232 \\cdot \\textrm{female literacy rate} $$\n\n-   What is the expected/predicted life expectancy for a country with\n    female literacy rate 60%?\n\n$$\\widehat{\\textrm{life expectancy}} = 50.9 + 0.232 \\cdot 60 = `r 50.9 + 0.232*60`$$\n\n```{r}\n(y_60 <- 50.9 + 0.232*60)\n```\n\n-   How do we interpret the expected value?\n\n    -   We sometimes call this \"predicted\" value, since we can\n        technically use a literacy rate that is not in our sample\n\n-   How variable is it?\n\n## Mean response/prediction with regression line\n\n::: columns\n::: {.column width=\"55%\"}\nRecall the population model:\n\n*line + random \"noise\"*\n\n$$Y = \\beta_0 + \\beta_1 \\cdot X + \\varepsilon$$ with\n$\\varepsilon \\sim N(0,\\sigma^2)$\n\n<br>\n\n-   When we take the expected value, at a given value $X^*$, the average\n    expected response at $X^*$ is:\n\n$$\\widehat{E}[Y|X^*] = \\widehat\\beta_0 + \\widehat\\beta_1 X^*$$\n:::\n\n::: {.column width=\"45%\"}\n```{r}\n#| echo: false\n#| fig.height: 8.0\n#| fig.width: 8.0\n\ngapm %>%\n  ggplot(aes(x = FemaleLiteracyRate,\n                 y = LifeExpectancyYrs)) +\n  geom_point(size=2) +\n  labs(x = \"Female literacy rate (%)\", \n       y = \"Life expectancy (years)\",\n       title = \"Life expectancy vs. female literacy rate\") +  \n  geom_smooth(method = \"lm\", se = TRUE, size =3, color = \"#F14124\") +\n  geom_vline(xintercept = 60, color = \"#A7EA52\", size = 3)\n```\n:::\n:::\n\n-   These are the points on the regression line\n-   The mean responses have variability, and we can calculate a CI for\n    it, for every value of $X^*$\n\n## CI for population mean response ($E[Y|X^*]$ or $\\mu_{Y|X^*})$\n\n$$\\widehat{E}[Y|X^*] \\pm t_{n-2}^* \\cdot SE_{\\widehat{E}[Y|X^*]}$$\n\n$$SE_{\\widehat{E}[Y|X^*]} = s_{\\text{residuals}} \\sqrt{\\frac{1}{n} + \\frac{(X^* - \\overline{X})^2}{(n-1)s_X^2}}$$\n\n-   $\\widehat{E}[Y|X^*]$ is the predicted value at the specified point\n    $X^*$ of the explanatory variable\n-   $s_{\\textrm{residuals}}^2$ is the sd of the residuals\n-   $n$ is the sample size, or the number of (complete) pairs of points\n-   $\\overline{X}$ is the sample mean of the explanatory variable $x$\n-   $s_X$ is the sample sd of the explanatory variable $X$\n\n<br>\n\n-   Recall that $t_{n-2}^*$ is calculated using `qt()` and depends on\n    the confidence level ($1-\\alpha$)\n\n## Example Option 1: CI for mean response $\\mu_{Y|X^*}$\n\n**Find the 95% CI for the mean life expectancy when the female literacy\nrate is 60.**\n\n::: {style=\"font-size: 70%;\"}\n```{=tex}\n\\begin{align}\n\\widehat{E}[Y|X^*] &\\pm t_{n-2}^* \\cdot SE_{\\widehat{E}[Y|X^*]}\\\\\n64.8596 &\\pm 1.990847 \\cdot s_{residuals} \\sqrt{\\frac{1}{n} + \\frac{(X^* - \\bar{x})^2}{(n-1)s_x^2}}\\\\\n64.8596 &\\pm 1.990847 \\cdot 6.142157 \\sqrt{\\frac{1}{80} + \\frac{(60 - 81.65375)^2}{(80-1)21.95371^2}}\\\\\n64.8596 &\\pm 1.990847 \\cdot 0.9675541\\\\\n64.8596 &\\pm 1.926252\\\\\n(62.93335 &, 66.78586)\n\\end{align}\n```\n:::\n\n::: {style=\"font-size: 90%;\"}\n::: columns\n::: {.column width=\"50%\"}\n```{r}\n(Y60 <- 50.9278981 + 0.2321951 * 60)\n(tstar <- qt(.975, df = 78))\n(s_resid <- glance(model1)$sigma)\n```\n:::\n\n::: {.column width=\"50%\"}\n```{r}\n(n <- nobs(model1))\n(mx <- mean(gapm$FemaleLiteracyRate, na.rm=T))\n(s_x <- sd(gapm$FemaleLiteracyRate, na.rm=T))\n```\n:::\n:::\n\n```{r}\n(SE_Yx <- s_resid *sqrt(1/n + (60 - mx)^2/((n-1)*s_x^2)))\n```\n\n::: columns\n::: {.column width=\"32%\"}\n```{r}\n(MOE_Yx <- SE_Yx*tstar)\n```\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"32%\"}\n```{r}\nY60 - MOE_Yx\n```\n:::\n\n::: {.column width=\"1%\"}\n:::\n\n::: {.column width=\"32%\"}\n```{r}\nY60 + MOE_Yx\n```\n:::\n:::\n:::\n\n## Example Option 2: CI for mean response $\\mu_{Y|X^*}$\n\n**Find the 95% CI's for the mean life expectancy when the female\nliteracy rate is 60 and 80.**\n\n-   Use the base R `predict()` function\n-   Requires specification of a `newdata` \"value\"\n    -   The `newdata` value is $X^*$\n    -   This has to be in the format of a data frame though\n    -   with column name identical to the predictor variable in the\n        model\n\n```{r}\nnewdata <- data.frame(FemaleLiteracyRate = c(60, 80)) \nnewdata\n```\n\n::: columns\n::: {.column width=\"50%\"}\n```{r}\npredict(model1, \n        newdata=newdata, \n        interval=\"confidence\")\n```\n:::\n\n::: {.column width=\"50%\"}\n::: fact\n::: fact-title\nInterpretation\n:::\n\n::: fact-cont\nWe are 95% confident that the **average** life expectancy for a country\nwith a 60% female literacy rate will be between 62.9 and 66.8 years.\n:::\n:::\n:::\n:::\n\n## Poll Everywhere Question 5\n\n\n## Confidence bands for mean response $\\mu_{Y|X^*}$\n\n-   Often we plot the CI for many values of X, creating **confidence\n    bands**\n-   The confidence bands are what ggplot creates when we set `se = TRUE`\n    within `geom_smooth`\n-   Think about it: for what values of X are the confidence bands\n    (intervals) narrowest?\n\n```{r}\n#| fig-align: center\n\ngapm %>%\n  ggplot(aes(x=FemaleLiteracyRate, \n             y=LifeExpectancyYrs)) +\n  geom_point()+\n  geom_smooth(method = lm, se=TRUE)+\n  ggtitle(\"Life expectancy vs. female literacy rate\") \n```\n\n## Width of confidence bands for mean response $\\mu_{Y|X^*}$\n\n-   For what values of $X^*$ are the confidence bands (intervals)\n    narrowest? widest?\n\n```{=tex}\n\\begin{align}\n\\widehat{E}[Y|X^*] &\\pm t_{n-2}^* \\cdot SE_{\\widehat{E}[Y|X^*]}\\\\\n\\widehat{E}[Y|X^*] &\\pm t_{n-2}^* \\cdot s_{residuals} \\sqrt{\\frac{1}{n} + \\frac{(X^* - \\bar{x})^2}{(n-1)s_x^2}}\n\\end{align}\n```\n```{r}\n#| echo: false\n#| fig-align: center\n\ngapm %>%\n  ggplot(aes(x = FemaleLiteracyRate,\n                 y = LifeExpectancyYrs)) +\n  geom_point(size = 4) +\n  geom_smooth(method = \"lm\", se = TRUE, size = 3, colour=\"#F14124\") +\n  labs(x = \"Female literacy rate (%)\", \n       y = \"Life expectancy (years)\",\n       title = \"Relationship between life expectancy and female literacy rate in 2011\") +\n    theme(axis.title = element_text(size = 20), \n        axis.text = element_text(size = 20), \n        title = element_text(size = 17)) +\n  geom_vline(xintercept = mx, color = \"purple\", size = 3)\n\n```\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":"mathjax","slide-level":2,"to":"revealjs","highlight-style":"ayu","output-file":"04_SLR_Inf_Pred.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.8.25","auto-stretch":true,"title":"Lesson 4: SLR Inference and Prediction","author":"Nicky Wakim","title-slide-attributes":{"data-background-color":"#213c96"},"date":"01/15/2025","categories":["Week 1"],"editor":{"markdown":{"wrap":72}},"theme":"../simple_NW.scss","chalkboard":true,"slideNumber":true,"showSlideNumber":"all","width":1955,"height":1100,"footer":"Lesson 4: SLR 2"}}},"projectFormats":["html"]}