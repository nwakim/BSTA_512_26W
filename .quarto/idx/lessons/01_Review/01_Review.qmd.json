{"title":"Lesson 1: Review","markdown":{"yaml":{"title":"Lesson 1: Review","author":"Nicky Wakim","title-slide-attributes":{"data-background-color":"#213c96"},"date":"`r library(here); source(here('class_dates.R')); w1d1`","format":{"revealjs":{"theme":"../simple_NW.scss","chalkboard":true,"slide-number":true,"show-slide-number":"all","width":1955,"height":1100,"footer":"Lesson 1: Review","html-math-method":"mathjax","highlight-style":"ayu"}}},"headingText":"What did we learn in 511/611? (1/2)","containsRefs":false,"markdown":"\n\n```{r}\n#| label: \"setup\" \n#| include: false\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)    \nlibrary(oibiostat)\nlibrary(janitor)\nlibrary(rstatix)\nlibrary(knitr)\nlibrary(gtsummary)\nlibrary(moderndive)\nlibrary(gt)\nlibrary(broom) # NEW!!\n\nset.seed(456)\n\ndata(\"dds.discr\")\n```\n\n\n-   In 511, we talked about *categorical* and *continuous* outcomes (dependent variables)\n\n     \n\n-   We also talked about their relationship with 1-2 *continuous* or *categorical* exposure (independent variables or predictor)\n\n     \n\n-   We had many good ways to assess the relationship between an outcome and exposure:\n\n     \n\n|                      |                                                  |                                                                                                                  |\n|----------------------|--------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n|                      | Continuous Outcome                               | Categorical Outcome                                                                                              |\n| Continuous Exposure  | Correlation, simple linear regression            | ??                                                                                                               |\n| Categorical Exposure | t-tests, paired t-tests, 2 sample t-tests, ANOVA | proportion t-test, Chi-squared goodness of fit test, Fisher's Exact test, Chi-squared test of independence, etc. |\n\n: {tbl-colwidths=\"\\[15, 35,35\\]\"}\n\n## What did we learn in 511/611? (2/2)\n\n-   You set up a really **important foundation**\n\n    -   Including distributions, mathematical definitions, hypothesis testing, and more!\n\n     \n\n-   Tests and statistical approaches learned are incredibly helpful!\n\n     \n\n-   While you had to learn a lot of different tests and approaches for each combination of categorical/continuous exposure with categorical/continuous outcome\n\n    -   **Those tests cannot handle more complicated data**\n\n     \n\n-   **What happens when other variables influence the relationship between your exposure and outcome?**\n\n    -   Do we just ignore them?\n\n```{css, echo=FALSE}\n.reveal code {\n  max-height: 100% !important;\n}\n```\n\n## What will we learn in this class?\n\n-   We will be building towards models that can handle many variables!\n\n     \n\n    -   **Regression** is the building block for modeling multivariable relationships\n\n     \n\n-   In Linear Models we will *build, interpret, and evaluate* **linear regression models**\n\n## Process of regression data analysis\n\n::: box\n![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"62.1%\" width=\"155\"} ![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"28.4%\" width=\"155\"}![](../img_slides/arrow_back4.png){.absolute top=\"7.5%\" right=\"30.5%\" width=\"820\"} ![](../img_slides/arrow_down.png){.absolute top=\"60.5%\" right=\"48%\" width=\"85\"}\n\n::: columns\n::: {.column width=\"30%\"}\n::: RAP1\n::: RAP1-title\nModel Selection\n:::\n\n::: RAP1-cont\n-   Building a model\n\n-   Selecting variables\n\n-   Prediction vs interpretation\n\n-   Comparing potential models\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP2\n::: RAP2-title\nModel Fitting\n:::\n\n::: RAP2-cont\n-   Find best fit line\n\n-   Using OLS in this class\n\n-   Parameter estimation\n\n-   Categorical covariates\n\n-   Interactions\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP3\n::: RAP3-title\nModel Evaluation\n:::\n\n::: RAP3-cont\n-   Evaluation of model fit\n-   Testing model assumptions\n-   Residuals\n-   Transformations\n-   Influential points\n-   Multicollinearity\n:::\n:::\n:::\n:::\n:::\n\n::: RAP4\n::: RAP4-title\nModel Use (Inference)\n:::\n\n::: RAP4-cont\n::: columns\n::: {.column width=\"50%\"}\n-   Inference for coefficients\n-   Hypothesis testing for coefficients\n:::\n\n::: {.column width=\"50%\"}\n-   Inference for expected $Y$ given $X$\n-   Prediction of new $Y$ given $X$\n:::\n:::\n:::\n:::\n\n## Main sections of the course\n\n1.  Review\n\n2.  Simple Linear Regression\n\n    -   [Model evaluation]{style=\"color:#A7EA52;\"} and [Model use]{style=\"color:#4FADF3;\"}\n\n3.  Intro to MLR: estimation and testing\n\n    -   [Model use]{style=\"color:#4FADF3;\"}\n\n4.  Diving into our predictors: categorical variables, interactions between variable\n\n    -   [Model fitting]{style=\"color:#34AC8B;\"}\n\n5.  Key ingredients: model evaluation, diagnostics, selection, and building\n\n    -   [Model evaluation]{style=\"color:#A7EA52;\"} and [Model selection]{style=\"color:#FF8021;\"}\n\n```{r}\nlibrary(ggplot2)\n```\n\n## Main sections of the course\n\n::: lob\n1.  Review\n:::\n\n2.  Intro to SLR: estimation and testing\n\n    -   [Model fitting]{style=\"color:#34AC8B;\"}\n\n3.  Intro to MLR: estimation and testing\n\n    -   [Model fitting]{style=\"color:#34AC8B;\"}\n\n4.  Diving into our predictors: categorical variables, interactions between variable\n\n    -   [Model fitting]{style=\"color:#34AC8B;\"}\n\n5.  Key ingredients: model evaluation, diagnostics, selection, and building\n\n    -   [Model evaluation]{style=\"color:#A7EA52;\"} and [Model selection]{style=\"color:#FF8021;\"}\n\n## Before we begin\n\n- Feel free to visit my or Meike's Introducation to Biostatistics\n\n-   [Meike's BSTA 511 page](https://niederhausen.github.io/BSTA_511_F24/)\n\n-   [Nicky's BSTA 525 page](https://nwakim.github.io/F24_EPI_525/)\n\n## Learning Objectives\n\n1.  Identify important descriptive statistics and visualize data from a continuous variable\n\n2.  Identify important distributions that will be used in 512/612\n\n3.  Use our previous tools in 511 to estimate a parameter and construct a confidence interval\n\n4.  Use our previous tools in 511 to conduct a hypothesis test\n\n5.  Define error rates and power\n\n## Learning Objectives\n\n::: lob\n1.  Identify important descriptive statistics and visualize data from a continuous variable\n:::\n\n2.  Identify important distributions that will be used in 512/612\n\n3.  Use our previous tools in 511 to estimate a parameter and construct a confidence interval\n\n4.  Use our previous tools in 511 to conduct a hypothesis test\n\n5.  Define error rates and power\n\n\n## Some Basic Statistics \"Talk\"\n\n::: columns\n::: column\n-   Random variable $Y$\n\n    -   Sample $Y_i, i=1,\\dots, n$\n\n-   Summation:\n\n    $\\sum_{i=1}^n Y_i =Y_1 + Y_2 + \\ldots + Y_n$\n\n-   Product:\n\n    $\\prod_{i=1}^n Y_i = Y_1 \\times Y_2 \\times \\ldots \\times Y_n$\n:::\n\n::: column\n:::\n:::\n\n## Descriptive Statistics: continuous variables\n\n::: columns\n::: {.column width=\"40%\"}\n**Measures of central tendency**\n\n-   Sample mean\n\n    $$\n    \\overline{x} = \\dfrac{x_1+x_2+...+x_n}{n}=\\dfrac{\\sum_{i=1}^nx_i}{n}\n    $$\n\n-   Median\n:::\n\n::: column\n**Measures of variability (or dispersion)**\n\n-   Sample variance\n\n    -   Average of the squared deviations from the sample mean\n\n-   Sample standard deviation\n\n    $$\n    \\begin{aligned}\n    s = & \\sqrt{\\dfrac{(x_1-\\overline{x})^2+(x_2-\\overline{x})^2+...+(x_n-\\overline{x})^2}{n-1}} \\\\\n    = & \\sqrt{\\dfrac{\\sum_{i=1}^n(x_i-\\overline{x})^2}{n-1}}\n    \\end{aligned}\n    $$\n\n-   IQR\n\n    -   Range from 1st to 3rd quartile\n:::\n:::\n\n## Descriptive Statistics: continuous variables (R code)\n\n::: columns\n::: {.column width=\"40%\"}\n**Measures of central tendency**\n\n-   Sample mean\n\n    ```{r}\n    #| eval: false\n    #| echo: true\n\n    mean( sample )\n    ```\n\n-   Median\n\n    ```{r}\n    #| eval: false\n    #| echo: true\n\n    median( sample )\n    ```\n:::\n\n::: column\n**Measures of variability (or dispersion)**\n\n-   Sample variance\n\n    ```{r}\n    #| eval: false\n    #| echo: true\n\n    var( sample )\n    ```\n\n-   Sample standard deviation\n\n    ```{r}\n    #| eval: false\n    #| echo: true\n\n    sd( sample )\n    ```\n\n-   IQR\n\n    ```{r}\n    #| eval: false\n    #| echo: true\n\n    IQR( sample )\n    ```\n:::\n:::\n\n- Or all together!!\n\n```{r}\n#| echo: true\ndds.discr %>% get_summary_stats(age)\n```\n\n## Data visualization\n\n-   Using the library `ggplot2` to visualize data\n\n-   We will load the package:\n\n```{r}\n#| echo: true\n\nlibrary(ggplot2)\n```\n\n## Histogram using `ggplot2`\n\nWe can make a basic graph for a continuous variable:\n\n::: columns\n```{r}\ndata(\"dds.discr\")\n```\n\n::: {.column width=\"50%\"}\n```{r}\n#| echo: true\n#| fig-align: center\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_histogram()\n```\n:::\n\n::: {.column width=\"50%\"}\n```{r}\n#| echo: true\n#| fig-align: center\n\nggplot() +\n  geom_histogram(data = dds.discr, \n       aes(x = age))\n```\n:::\n:::\n\n[Some more information](https://www.sharpsightlabs.com/blog/histogram-r-ggplot2/) on histograms using `ggplot2`\n\n## Spruced up histogram using `ggplot2`\n\nWe can make a more formal, presentable graph:\n\n```{r}\n#| echo: true\n#| fig-align: center\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_histogram() +\n  theme(text = element_text(size=20)) +\n  labs(x = \"Age\", \n       y = \"Count\", \n       title = \"Distribution of Age in Sample\")\n```\n\nI would like you to turn in homework, labs, and project reports with graphs like these.\n\n## Other basic plots from `ggplot2`\n\nWe can also make a density and boxplot for the continuous variable with `ggplot2`\n\n::: columns\n::: {.column width=\"50%\"}\n```{r}\n#| echo: true\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_density()\n```\n:::\n\n::: {.column width=\"50%\"}\n```{r}\n#| echo: true\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_boxplot()\n```\n:::\n:::\n\n## Learning Objectives\n\n1.  Identify important descriptive statistics and visualize data from a continuous variable\n\n::: lob\n2.  Identify important distributions that will be used in 512/612\n:::\n\n3.  Use our previous tools in 511 to estimate a parameter and construct a confidence interval\n\n4.  Use our previous tools in 511 to conduct a hypothesis test\n\n5.  Define error rates and power\n\n\n## Distributions that will be used in this class\n\n-   Normal distribution\n\n-   Chi-square distribution\n\n-   Student's t distribution\n\n-   F distribution\n\n## Normal Distribution\n\n::: columns\n::: column\n\n- Where did we see this? \n\n    - Basically everywhere! Think Central Limit Theorem\n    \n \n    \n-   Notation: $Y\\sim N(\\mu,\\sigma^2)$\n\n-   Arguably the most important distribution in statistics\n\n-   If we know $E(Y)=\\mu$, $Var(Y)=\\sigma^2$ then\n\n    -   2/3 of $Y$'s distribution lies within 1 $\\sigma$ of $\\mu$\n\n    -   95% is within $\\mu\\pm 2\\sigma$\n\n    -   $>99$% lies within $\\mu\\pm 3\\sigma$\n\n \n\n-   Linear combinations of Normal's are Normal\\\n    e.g., $(aY+b)\\sim \\mbox{N}(a\\mu+b,\\;a^2\\sigma^2)$\n\n-   Standard normal: $Z=\\frac{Y-\\mu}{\\sigma} \\sim \\mbox{N}(0,1)$\n:::\n\n::: column\n![](../img_slides/normal.png)\n:::\n:::\n\n## Chi-squared distribution\n\n::: columns\n::: column\n- Where did we see this? \n\n    - Hypothesis test if two categorical variables were independent\n\n \n\n-   Notation: $X \\sim \\chi^2_{df}$ OR $X \\sim \\chi^2_{\\nu}$\n\n    -   Degrees of freedom (df): $df=n-1$\n\n    -   $X$ takes on only positive values\n    \n \n\n-   If $Z_i\\sim \\mbox{N}(0,1)$, then $Z_i^2\\sim \\chi^2_1$\n\n    -   A standard normal distribution squared is the Chi squared distribution with df of 1.\n\n:::\n\n::: column\n![](../img_slides/chi_squared.png)\n:::\n:::\n\n## Student's t Distribution\n\n::: columns\n::: column\n\n- Where did we see this? \n\n    - Inference of means: single sample, paired, two independent samples\n\n \n    \n-   Notation: $T \\sim t_{df}$ OR $T \\sim t_{n-1}$\n\n    -   Degrees of freedom (df): $df=n-1$\n\n    -   $T = \\dfrac{\\overline{x} - \\mu_x}{\\dfrac{s}{\\sqrt{n}}}\\sim t_{n-1}$\n\n \n\n-   In linear modeling, used for inference on individual regression parameters\n\n    -   Think: our estimated coefficients ( $\\hat{\\beta_{}}$ )\n:::\n\n::: column\n![](../img_slides/student_t.png)\n:::\n:::\n\n## F-Distribution\n\n::: columns\n::: column\n\n- Where did we see this? \n\n    - Inference for 2+ means: ANOVA test\n    \n-   Model ratio of sample variances (and is a ratio of Chi-squared RVs)\n\n-   If $X_1^2\\sim \\chi^2_{df1}$ and $X_2^2\\sim \\chi^2_{df2}$, where $X_1^2\\perp X_2^2$, then:\n\n$$\\dfrac{X_1^2/df1}{X_2^2/df2} \\sim F_{df1,df2}$$ \n\n-   Important relationship with $t$ distribution: $T^2 \\sim F_{1,\\nu}$\n\n    -   The square of a t-distribution with $df=\\nu$\n\n    -   is an F-distribution with numerator df ($df_1 = 1$) and denominator df ($df_2 = \\nu$)\n:::\n\n::: column\n![](../img_slides/f_dist.png)\n:::\n:::\n\n\n## R code for probability distributions\n\n::: columns\n::: column\n[Here is a site](https://www.stat.umn.edu/geyer/5101/examp/rlook.html) with the various probability distributions and their R code.\n\n-   It also includes practice with R code to see what each function outputs\n:::\n\n::: column\n![](../img_slides/r_code_prob_dist.png){fig-align=\"center\" width=\"785\"}\n:::\n:::\n\n## Learning Objectives\n\n1.  Identify important descriptive statistics and visualize data from a continuous variable\n\n2.  Identify important distributions that will be used in 512/612\n\n::: lob\n3.  Use our previous tools in 511 to estimate a parameter and construct a confidence interval\n:::\n\n4.  Use our previous tools in 511 to conduct a hypothesis test\n\n5.  Define error rates and power\n\n\n## Confidence interval for one mean\n\n::: columns\n::: column\nThe confidence interval for population mean $\\mu$:\n\n$$\n\\overline{x} \\pm t^{*}\\dfrac{s}{\\sqrt{n}}\n$$\n\n-   where $t^*$ is the critical value for the 95% (or other percent) corresponding to the t-distribution and dependent on $df=n-1$\n\n::: proposition\n::: prop-title\nWe can use `R` to find the critical t-value, $t^*$\n:::\n\n::: prop-cont\nFor example the critical value for the 95% CI with $n=10$ subjects is...\n\n```{r}\n#| echo: true\n\nqt(0.975, df=9)\n```\n\n-   Recall, that as the $df$ increases, the t-distribution converges towards the Normal distribution\n:::\n:::\n:::\n\n::: column\n:::\n:::\n\n## Confidence interval for one mean\n\n::: columns\n::: column\nThe confidence interval for population mean $\\mu$:\n\n$$\n\\overline{x} \\pm t^{*}\\dfrac{s}{\\sqrt{n}}\n$$\n\n-   where $t^*$ is the critical value for the 95% (or other percent) corresponding to the t-distribution and dependent on $df=n-1$\n\n::: proposition\n::: prop-title\nWe can use `R` to find the critical t-value, $t^*$\n:::\n\n::: prop-cont\nFor example the critical value for the 95% CI with $n=10$ subjects is...\n\n```{r}\n#| echo: true\n\nqt(0.975, df=9)\n```\n\n-   Recall, that as the $df$ increases, the t-distribution converges towards the Normal distribution\n:::\n:::\n:::\n\n::: column\nWe can also use `t.test` in R to calculate the confidence interval if we have a dataset.\n\n```{r}\n#| echo: true \n\nt.test(dds.discr$age)\n```\n:::\n:::\n\n## Confidence interval for two independent means\n\n::: columns\n::: column\nThe confidence interval for difference in independent population means, $\\mu_1$ and $\\mu_2$:\n\n$$\n\\overline{x}_1 - \\overline{x}_2 \\pm t^{*}\\sqrt{\\dfrac{s_1^2}{n_1} + \\dfrac{s_2^2}{n_2}}\n$$\n\n-   where $t^*$ is the critical value for the 95% (or other percent) corresponding to the t-distribution and dependent on $df=n_1 + n_2 -2$\n:::\n\n::: column\n:::\n:::\n\n \n\n- Please check out my notes on this if you'd like: <https://nwakim.github.io/F24_EPI_525/schedule.html>\n  - It's under Lesson 13\n\n## Here's a decent source for other R code for tests in 511\n\n[Website from UCLA](https://stats.oarc.ucla.edu/r/whatstat/what-statistical-analysis-should-i-usestatistical-analyses-using-r/)\n\n## Learning Objectives\n\n1.  Identify important descriptive statistics and visualize data from a continuous variable\n\n2.  Identify important distributions that will be used in 512/612\n\n3.  Use our previous tools in 511 to estimate a parameter and construct a confidence interval\n\n::: lob\n4.  Use our previous tools in 511 to conduct a hypothesis test\n:::\n\n5.  Define error rates and power\n\n\n## Reference: Steps in a Hypothesis Test\n\n1.  Check the [**assumptions**]{style=\"color:#4FADF3\"}\n\n    - What sampling distribution are you using? What assumptions are required for it?\n\n2.  Set the [**level of significance**]{style=\"color:#4FADF3\"} $\\alpha$\n\n3.  Specify the [**null**]{style=\"color:#4FADF3\"} ( $H_0$ ) and [**alternative**]{style=\"color:#4FADF3\"} ( $H_A$ ) [**hypotheses**]{style=\"color:#4FADF3\"}\n\n    -  In symbols and/or in words\n    -  Alternative: one- or two-sided?\n\n4.  Calculate the [**test statistic**]{style=\"color:#4FADF3\"}.\n\n5.  Calculate the [**p-value**]{style=\"color:#4FADF3\"} based on the observed test statistic and its sampling distribution\n\n6.  Write a [**conclusion**]{style=\"color:#4FADF3\"} to the hypothesis test\n\n    -  Do we reject or fail to reject $H_0$?\n    -  Write a conclusion in the context of the problem\n    \n## Another view: Steps in a Hypothesis Test\n\n![](../img_slides/hypothesis_test_steps.png){fig-align=\"center\"}\n\n## Example: one sample t-test\n\n```{r}\n#| echo: true\n#| fig-align: center\n\nBodyTemps = read.csv(\"data/BodyTemperatures.csv\")\n\nggplot(data = BodyTemps, \n       aes(x = Temperature)) +\n  geom_histogram() +\n  theme(text = element_text(size=20)) +\n  labs(x = \"Temperature\", y = \"Count\", \n       title = \"Distribution of Body Temperature in Sample\") +\n  geom_vline(aes(xintercept = mean(BodyTemps$Temperature, na.rm = T)), \n             color = \"red\", linewidth = 2)\n```\n\n## Reference: what does it all look like together?\n\n::::: example\n::: ex-title\nExample of hypothesis test based on the 1992 JAMA data\n:::\n\n::: ex-cont\nIs there evidence to support that the population mean body temperature is different from 98.6°F?\n:::\n:::::\n\n:::::: columns\n::: {.column width=\"50%\"}\n1.  **Assumptions:** The individual observations are independent and the number of individuals in our sample is 130. Thus, we can use CLT to approximate the sampling distribution.\n\n4-5. Test statistic and p-value\n:::\n\n::: {.column width=\"25%\"}\n2.  Set $\\alpha = 0.05$\n:::\n\n::: {.column width=\"25%\"}\n3.  **Hypothesis:**\n\n    \\begin{aligned}\n    H_0 &: \\mu = 98.6\\\\\n    \\text{vs. } H_A&: \\mu \\neq 98.6\n    \\end{aligned}\n:::\n::::::\n\n```{r}\n#| echo: true\n#| code-fold: true\n\n\ntemps_ttest <- t.test(x = BodyTemps$Temperature, mu = 98.6)\ntidy(temps_ttest) %>% gt() %>% tab_options(table.font.size = 36)\n```\n\n\n6.  **Conclusion:** We reject the null hypothesis. The average body temperature in the sample was 98.25°F (95% CI 98.12, 98.38°F), which is discernibly different from 98.6°F ( $p$-value \\< 0.001).\n\n## How did we get the 95% CI?\n\n-   The `t.test` function can help us answer this, and give us the needed information for both approaches.\n\n```{r}\n#| echo: true\n\nBodyTemps = read.csv(\"data/BodyTemperatures.csv\")\n\nt.test(x = BodyTemps$Temperature, \n       # alternative = \"two-sided\", \n       mu = 98.6)\n```\n\n## Learning Objectives\n\n1.  Identify important descriptive statistics and visualize data from a continuous variable\n\n2.  Identify important distributions that will be used in 512/612\n\n3.  Use our previous tools in 511 to estimate a parameter and construct a confidence interval\n\n4.  Use our previous tools in 511 to conduct a hypothesis test\n\n::: lob\n5.  Define error rates and power\n:::\n\n## Outcomes of our hypothesis test\n\n![](../img_slides/Type_1_2_error.png){fig-align=\"center\"}\n\n## Prabilities of outcomes\n\n-   Type 1 error is $\\alpha$\n\n    -   The probability that we falsely reject the null hypothesis (but the null is true!!)\n\n-   Power is $1-\\beta$\n\n    -   The probability of correctly rejecting the null hypothesis\n\n![](../img_slides/Power.png){fig-align=\"center\"}\n\n## What I think is the most intuitive way to look at it\n\n![](../img_slides/type-i-and-type-ii-error.png){fig-align=\"center\"}\n\n## Do your exit ticket!!\n\n- Don't forget to go online and fill it out!\n\n  - This will count as your attendance\n  \n \n  \n- I look forward to the quarter with you!\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: \"setup\" \n#| include: false\n#| message: false\n#| warning: false\n\nlibrary(tidyverse)    \nlibrary(oibiostat)\nlibrary(janitor)\nlibrary(rstatix)\nlibrary(knitr)\nlibrary(gtsummary)\nlibrary(moderndive)\nlibrary(gt)\nlibrary(broom) # NEW!!\n\nset.seed(456)\n\ndata(\"dds.discr\")\n```\n\n## What did we learn in 511/611? (1/2)\n\n-   In 511, we talked about *categorical* and *continuous* outcomes (dependent variables)\n\n     \n\n-   We also talked about their relationship with 1-2 *continuous* or *categorical* exposure (independent variables or predictor)\n\n     \n\n-   We had many good ways to assess the relationship between an outcome and exposure:\n\n     \n\n|                      |                                                  |                                                                                                                  |\n|----------------------|--------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n|                      | Continuous Outcome                               | Categorical Outcome                                                                                              |\n| Continuous Exposure  | Correlation, simple linear regression            | ??                                                                                                               |\n| Categorical Exposure | t-tests, paired t-tests, 2 sample t-tests, ANOVA | proportion t-test, Chi-squared goodness of fit test, Fisher's Exact test, Chi-squared test of independence, etc. |\n\n: {tbl-colwidths=\"\\[15, 35,35\\]\"}\n\n## What did we learn in 511/611? (2/2)\n\n-   You set up a really **important foundation**\n\n    -   Including distributions, mathematical definitions, hypothesis testing, and more!\n\n     \n\n-   Tests and statistical approaches learned are incredibly helpful!\n\n     \n\n-   While you had to learn a lot of different tests and approaches for each combination of categorical/continuous exposure with categorical/continuous outcome\n\n    -   **Those tests cannot handle more complicated data**\n\n     \n\n-   **What happens when other variables influence the relationship between your exposure and outcome?**\n\n    -   Do we just ignore them?\n\n```{css, echo=FALSE}\n.reveal code {\n  max-height: 100% !important;\n}\n```\n\n## What will we learn in this class?\n\n-   We will be building towards models that can handle many variables!\n\n     \n\n    -   **Regression** is the building block for modeling multivariable relationships\n\n     \n\n-   In Linear Models we will *build, interpret, and evaluate* **linear regression models**\n\n## Process of regression data analysis\n\n::: box\n![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"62.1%\" width=\"155\"} ![](../img_slides/arrow2.png){.absolute top=\"13.5%\" right=\"28.4%\" width=\"155\"}![](../img_slides/arrow_back4.png){.absolute top=\"7.5%\" right=\"30.5%\" width=\"820\"} ![](../img_slides/arrow_down.png){.absolute top=\"60.5%\" right=\"48%\" width=\"85\"}\n\n::: columns\n::: {.column width=\"30%\"}\n::: RAP1\n::: RAP1-title\nModel Selection\n:::\n\n::: RAP1-cont\n-   Building a model\n\n-   Selecting variables\n\n-   Prediction vs interpretation\n\n-   Comparing potential models\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP2\n::: RAP2-title\nModel Fitting\n:::\n\n::: RAP2-cont\n-   Find best fit line\n\n-   Using OLS in this class\n\n-   Parameter estimation\n\n-   Categorical covariates\n\n-   Interactions\n:::\n:::\n:::\n\n::: {.column width=\"4%\"}\n:::\n\n::: {.column width=\"30%\"}\n::: RAP3\n::: RAP3-title\nModel Evaluation\n:::\n\n::: RAP3-cont\n-   Evaluation of model fit\n-   Testing model assumptions\n-   Residuals\n-   Transformations\n-   Influential points\n-   Multicollinearity\n:::\n:::\n:::\n:::\n:::\n\n::: RAP4\n::: RAP4-title\nModel Use (Inference)\n:::\n\n::: RAP4-cont\n::: columns\n::: {.column width=\"50%\"}\n-   Inference for coefficients\n-   Hypothesis testing for coefficients\n:::\n\n::: {.column width=\"50%\"}\n-   Inference for expected $Y$ given $X$\n-   Prediction of new $Y$ given $X$\n:::\n:::\n:::\n:::\n\n## Main sections of the course\n\n1.  Review\n\n2.  Simple Linear Regression\n\n    -   [Model evaluation]{style=\"color:#A7EA52;\"} and [Model use]{style=\"color:#4FADF3;\"}\n\n3.  Intro to MLR: estimation and testing\n\n    -   [Model use]{style=\"color:#4FADF3;\"}\n\n4.  Diving into our predictors: categorical variables, interactions between variable\n\n    -   [Model fitting]{style=\"color:#34AC8B;\"}\n\n5.  Key ingredients: model evaluation, diagnostics, selection, and building\n\n    -   [Model evaluation]{style=\"color:#A7EA52;\"} and [Model selection]{style=\"color:#FF8021;\"}\n\n```{r}\nlibrary(ggplot2)\n```\n\n## Main sections of the course\n\n::: lob\n1.  Review\n:::\n\n2.  Intro to SLR: estimation and testing\n\n    -   [Model fitting]{style=\"color:#34AC8B;\"}\n\n3.  Intro to MLR: estimation and testing\n\n    -   [Model fitting]{style=\"color:#34AC8B;\"}\n\n4.  Diving into our predictors: categorical variables, interactions between variable\n\n    -   [Model fitting]{style=\"color:#34AC8B;\"}\n\n5.  Key ingredients: model evaluation, diagnostics, selection, and building\n\n    -   [Model evaluation]{style=\"color:#A7EA52;\"} and [Model selection]{style=\"color:#FF8021;\"}\n\n## Before we begin\n\n- Feel free to visit my or Meike's Introducation to Biostatistics\n\n-   [Meike's BSTA 511 page](https://niederhausen.github.io/BSTA_511_F24/)\n\n-   [Nicky's BSTA 525 page](https://nwakim.github.io/F24_EPI_525/)\n\n## Learning Objectives\n\n1.  Identify important descriptive statistics and visualize data from a continuous variable\n\n2.  Identify important distributions that will be used in 512/612\n\n3.  Use our previous tools in 511 to estimate a parameter and construct a confidence interval\n\n4.  Use our previous tools in 511 to conduct a hypothesis test\n\n5.  Define error rates and power\n\n## Learning Objectives\n\n::: lob\n1.  Identify important descriptive statistics and visualize data from a continuous variable\n:::\n\n2.  Identify important distributions that will be used in 512/612\n\n3.  Use our previous tools in 511 to estimate a parameter and construct a confidence interval\n\n4.  Use our previous tools in 511 to conduct a hypothesis test\n\n5.  Define error rates and power\n\n\n## Some Basic Statistics \"Talk\"\n\n::: columns\n::: column\n-   Random variable $Y$\n\n    -   Sample $Y_i, i=1,\\dots, n$\n\n-   Summation:\n\n    $\\sum_{i=1}^n Y_i =Y_1 + Y_2 + \\ldots + Y_n$\n\n-   Product:\n\n    $\\prod_{i=1}^n Y_i = Y_1 \\times Y_2 \\times \\ldots \\times Y_n$\n:::\n\n::: column\n:::\n:::\n\n## Descriptive Statistics: continuous variables\n\n::: columns\n::: {.column width=\"40%\"}\n**Measures of central tendency**\n\n-   Sample mean\n\n    $$\n    \\overline{x} = \\dfrac{x_1+x_2+...+x_n}{n}=\\dfrac{\\sum_{i=1}^nx_i}{n}\n    $$\n\n-   Median\n:::\n\n::: column\n**Measures of variability (or dispersion)**\n\n-   Sample variance\n\n    -   Average of the squared deviations from the sample mean\n\n-   Sample standard deviation\n\n    $$\n    \\begin{aligned}\n    s = & \\sqrt{\\dfrac{(x_1-\\overline{x})^2+(x_2-\\overline{x})^2+...+(x_n-\\overline{x})^2}{n-1}} \\\\\n    = & \\sqrt{\\dfrac{\\sum_{i=1}^n(x_i-\\overline{x})^2}{n-1}}\n    \\end{aligned}\n    $$\n\n-   IQR\n\n    -   Range from 1st to 3rd quartile\n:::\n:::\n\n## Descriptive Statistics: continuous variables (R code)\n\n::: columns\n::: {.column width=\"40%\"}\n**Measures of central tendency**\n\n-   Sample mean\n\n    ```{r}\n    #| eval: false\n    #| echo: true\n\n    mean( sample )\n    ```\n\n-   Median\n\n    ```{r}\n    #| eval: false\n    #| echo: true\n\n    median( sample )\n    ```\n:::\n\n::: column\n**Measures of variability (or dispersion)**\n\n-   Sample variance\n\n    ```{r}\n    #| eval: false\n    #| echo: true\n\n    var( sample )\n    ```\n\n-   Sample standard deviation\n\n    ```{r}\n    #| eval: false\n    #| echo: true\n\n    sd( sample )\n    ```\n\n-   IQR\n\n    ```{r}\n    #| eval: false\n    #| echo: true\n\n    IQR( sample )\n    ```\n:::\n:::\n\n- Or all together!!\n\n```{r}\n#| echo: true\ndds.discr %>% get_summary_stats(age)\n```\n\n## Data visualization\n\n-   Using the library `ggplot2` to visualize data\n\n-   We will load the package:\n\n```{r}\n#| echo: true\n\nlibrary(ggplot2)\n```\n\n## Histogram using `ggplot2`\n\nWe can make a basic graph for a continuous variable:\n\n::: columns\n```{r}\ndata(\"dds.discr\")\n```\n\n::: {.column width=\"50%\"}\n```{r}\n#| echo: true\n#| fig-align: center\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_histogram()\n```\n:::\n\n::: {.column width=\"50%\"}\n```{r}\n#| echo: true\n#| fig-align: center\n\nggplot() +\n  geom_histogram(data = dds.discr, \n       aes(x = age))\n```\n:::\n:::\n\n[Some more information](https://www.sharpsightlabs.com/blog/histogram-r-ggplot2/) on histograms using `ggplot2`\n\n## Spruced up histogram using `ggplot2`\n\nWe can make a more formal, presentable graph:\n\n```{r}\n#| echo: true\n#| fig-align: center\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_histogram() +\n  theme(text = element_text(size=20)) +\n  labs(x = \"Age\", \n       y = \"Count\", \n       title = \"Distribution of Age in Sample\")\n```\n\nI would like you to turn in homework, labs, and project reports with graphs like these.\n\n## Other basic plots from `ggplot2`\n\nWe can also make a density and boxplot for the continuous variable with `ggplot2`\n\n::: columns\n::: {.column width=\"50%\"}\n```{r}\n#| echo: true\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_density()\n```\n:::\n\n::: {.column width=\"50%\"}\n```{r}\n#| echo: true\n\nggplot(data = dds.discr, \n       aes(x = age)) +\n  geom_boxplot()\n```\n:::\n:::\n\n## Learning Objectives\n\n1.  Identify important descriptive statistics and visualize data from a continuous variable\n\n::: lob\n2.  Identify important distributions that will be used in 512/612\n:::\n\n3.  Use our previous tools in 511 to estimate a parameter and construct a confidence interval\n\n4.  Use our previous tools in 511 to conduct a hypothesis test\n\n5.  Define error rates and power\n\n\n## Distributions that will be used in this class\n\n-   Normal distribution\n\n-   Chi-square distribution\n\n-   Student's t distribution\n\n-   F distribution\n\n## Normal Distribution\n\n::: columns\n::: column\n\n- Where did we see this? \n\n    - Basically everywhere! Think Central Limit Theorem\n    \n \n    \n-   Notation: $Y\\sim N(\\mu,\\sigma^2)$\n\n-   Arguably the most important distribution in statistics\n\n-   If we know $E(Y)=\\mu$, $Var(Y)=\\sigma^2$ then\n\n    -   2/3 of $Y$'s distribution lies within 1 $\\sigma$ of $\\mu$\n\n    -   95% is within $\\mu\\pm 2\\sigma$\n\n    -   $>99$% lies within $\\mu\\pm 3\\sigma$\n\n \n\n-   Linear combinations of Normal's are Normal\\\n    e.g., $(aY+b)\\sim \\mbox{N}(a\\mu+b,\\;a^2\\sigma^2)$\n\n-   Standard normal: $Z=\\frac{Y-\\mu}{\\sigma} \\sim \\mbox{N}(0,1)$\n:::\n\n::: column\n![](../img_slides/normal.png)\n:::\n:::\n\n## Chi-squared distribution\n\n::: columns\n::: column\n- Where did we see this? \n\n    - Hypothesis test if two categorical variables were independent\n\n \n\n-   Notation: $X \\sim \\chi^2_{df}$ OR $X \\sim \\chi^2_{\\nu}$\n\n    -   Degrees of freedom (df): $df=n-1$\n\n    -   $X$ takes on only positive values\n    \n \n\n-   If $Z_i\\sim \\mbox{N}(0,1)$, then $Z_i^2\\sim \\chi^2_1$\n\n    -   A standard normal distribution squared is the Chi squared distribution with df of 1.\n\n:::\n\n::: column\n![](../img_slides/chi_squared.png)\n:::\n:::\n\n## Student's t Distribution\n\n::: columns\n::: column\n\n- Where did we see this? \n\n    - Inference of means: single sample, paired, two independent samples\n\n \n    \n-   Notation: $T \\sim t_{df}$ OR $T \\sim t_{n-1}$\n\n    -   Degrees of freedom (df): $df=n-1$\n\n    -   $T = \\dfrac{\\overline{x} - \\mu_x}{\\dfrac{s}{\\sqrt{n}}}\\sim t_{n-1}$\n\n \n\n-   In linear modeling, used for inference on individual regression parameters\n\n    -   Think: our estimated coefficients ( $\\hat{\\beta_{}}$ )\n:::\n\n::: column\n![](../img_slides/student_t.png)\n:::\n:::\n\n## F-Distribution\n\n::: columns\n::: column\n\n- Where did we see this? \n\n    - Inference for 2+ means: ANOVA test\n    \n-   Model ratio of sample variances (and is a ratio of Chi-squared RVs)\n\n-   If $X_1^2\\sim \\chi^2_{df1}$ and $X_2^2\\sim \\chi^2_{df2}$, where $X_1^2\\perp X_2^2$, then:\n\n$$\\dfrac{X_1^2/df1}{X_2^2/df2} \\sim F_{df1,df2}$$ \n\n-   Important relationship with $t$ distribution: $T^2 \\sim F_{1,\\nu}$\n\n    -   The square of a t-distribution with $df=\\nu$\n\n    -   is an F-distribution with numerator df ($df_1 = 1$) and denominator df ($df_2 = \\nu$)\n:::\n\n::: column\n![](../img_slides/f_dist.png)\n:::\n:::\n\n\n## R code for probability distributions\n\n::: columns\n::: column\n[Here is a site](https://www.stat.umn.edu/geyer/5101/examp/rlook.html) with the various probability distributions and their R code.\n\n-   It also includes practice with R code to see what each function outputs\n:::\n\n::: column\n![](../img_slides/r_code_prob_dist.png){fig-align=\"center\" width=\"785\"}\n:::\n:::\n\n## Learning Objectives\n\n1.  Identify important descriptive statistics and visualize data from a continuous variable\n\n2.  Identify important distributions that will be used in 512/612\n\n::: lob\n3.  Use our previous tools in 511 to estimate a parameter and construct a confidence interval\n:::\n\n4.  Use our previous tools in 511 to conduct a hypothesis test\n\n5.  Define error rates and power\n\n\n## Confidence interval for one mean\n\n::: columns\n::: column\nThe confidence interval for population mean $\\mu$:\n\n$$\n\\overline{x} \\pm t^{*}\\dfrac{s}{\\sqrt{n}}\n$$\n\n-   where $t^*$ is the critical value for the 95% (or other percent) corresponding to the t-distribution and dependent on $df=n-1$\n\n::: proposition\n::: prop-title\nWe can use `R` to find the critical t-value, $t^*$\n:::\n\n::: prop-cont\nFor example the critical value for the 95% CI with $n=10$ subjects is...\n\n```{r}\n#| echo: true\n\nqt(0.975, df=9)\n```\n\n-   Recall, that as the $df$ increases, the t-distribution converges towards the Normal distribution\n:::\n:::\n:::\n\n::: column\n:::\n:::\n\n## Confidence interval for one mean\n\n::: columns\n::: column\nThe confidence interval for population mean $\\mu$:\n\n$$\n\\overline{x} \\pm t^{*}\\dfrac{s}{\\sqrt{n}}\n$$\n\n-   where $t^*$ is the critical value for the 95% (or other percent) corresponding to the t-distribution and dependent on $df=n-1$\n\n::: proposition\n::: prop-title\nWe can use `R` to find the critical t-value, $t^*$\n:::\n\n::: prop-cont\nFor example the critical value for the 95% CI with $n=10$ subjects is...\n\n```{r}\n#| echo: true\n\nqt(0.975, df=9)\n```\n\n-   Recall, that as the $df$ increases, the t-distribution converges towards the Normal distribution\n:::\n:::\n:::\n\n::: column\nWe can also use `t.test` in R to calculate the confidence interval if we have a dataset.\n\n```{r}\n#| echo: true \n\nt.test(dds.discr$age)\n```\n:::\n:::\n\n## Confidence interval for two independent means\n\n::: columns\n::: column\nThe confidence interval for difference in independent population means, $\\mu_1$ and $\\mu_2$:\n\n$$\n\\overline{x}_1 - \\overline{x}_2 \\pm t^{*}\\sqrt{\\dfrac{s_1^2}{n_1} + \\dfrac{s_2^2}{n_2}}\n$$\n\n-   where $t^*$ is the critical value for the 95% (or other percent) corresponding to the t-distribution and dependent on $df=n_1 + n_2 -2$\n:::\n\n::: column\n:::\n:::\n\n \n\n- Please check out my notes on this if you'd like: <https://nwakim.github.io/F24_EPI_525/schedule.html>\n  - It's under Lesson 13\n\n## Here's a decent source for other R code for tests in 511\n\n[Website from UCLA](https://stats.oarc.ucla.edu/r/whatstat/what-statistical-analysis-should-i-usestatistical-analyses-using-r/)\n\n## Learning Objectives\n\n1.  Identify important descriptive statistics and visualize data from a continuous variable\n\n2.  Identify important distributions that will be used in 512/612\n\n3.  Use our previous tools in 511 to estimate a parameter and construct a confidence interval\n\n::: lob\n4.  Use our previous tools in 511 to conduct a hypothesis test\n:::\n\n5.  Define error rates and power\n\n\n## Reference: Steps in a Hypothesis Test\n\n1.  Check the [**assumptions**]{style=\"color:#4FADF3\"}\n\n    - What sampling distribution are you using? What assumptions are required for it?\n\n2.  Set the [**level of significance**]{style=\"color:#4FADF3\"} $\\alpha$\n\n3.  Specify the [**null**]{style=\"color:#4FADF3\"} ( $H_0$ ) and [**alternative**]{style=\"color:#4FADF3\"} ( $H_A$ ) [**hypotheses**]{style=\"color:#4FADF3\"}\n\n    -  In symbols and/or in words\n    -  Alternative: one- or two-sided?\n\n4.  Calculate the [**test statistic**]{style=\"color:#4FADF3\"}.\n\n5.  Calculate the [**p-value**]{style=\"color:#4FADF3\"} based on the observed test statistic and its sampling distribution\n\n6.  Write a [**conclusion**]{style=\"color:#4FADF3\"} to the hypothesis test\n\n    -  Do we reject or fail to reject $H_0$?\n    -  Write a conclusion in the context of the problem\n    \n## Another view: Steps in a Hypothesis Test\n\n![](../img_slides/hypothesis_test_steps.png){fig-align=\"center\"}\n\n## Example: one sample t-test\n\n```{r}\n#| echo: true\n#| fig-align: center\n\nBodyTemps = read.csv(\"data/BodyTemperatures.csv\")\n\nggplot(data = BodyTemps, \n       aes(x = Temperature)) +\n  geom_histogram() +\n  theme(text = element_text(size=20)) +\n  labs(x = \"Temperature\", y = \"Count\", \n       title = \"Distribution of Body Temperature in Sample\") +\n  geom_vline(aes(xintercept = mean(BodyTemps$Temperature, na.rm = T)), \n             color = \"red\", linewidth = 2)\n```\n\n## Reference: what does it all look like together?\n\n::::: example\n::: ex-title\nExample of hypothesis test based on the 1992 JAMA data\n:::\n\n::: ex-cont\nIs there evidence to support that the population mean body temperature is different from 98.6°F?\n:::\n:::::\n\n:::::: columns\n::: {.column width=\"50%\"}\n1.  **Assumptions:** The individual observations are independent and the number of individuals in our sample is 130. Thus, we can use CLT to approximate the sampling distribution.\n\n4-5. Test statistic and p-value\n:::\n\n::: {.column width=\"25%\"}\n2.  Set $\\alpha = 0.05$\n:::\n\n::: {.column width=\"25%\"}\n3.  **Hypothesis:**\n\n    \\begin{aligned}\n    H_0 &: \\mu = 98.6\\\\\n    \\text{vs. } H_A&: \\mu \\neq 98.6\n    \\end{aligned}\n:::\n::::::\n\n```{r}\n#| echo: true\n#| code-fold: true\n\n\ntemps_ttest <- t.test(x = BodyTemps$Temperature, mu = 98.6)\ntidy(temps_ttest) %>% gt() %>% tab_options(table.font.size = 36)\n```\n\n\n6.  **Conclusion:** We reject the null hypothesis. The average body temperature in the sample was 98.25°F (95% CI 98.12, 98.38°F), which is discernibly different from 98.6°F ( $p$-value \\< 0.001).\n\n## How did we get the 95% CI?\n\n-   The `t.test` function can help us answer this, and give us the needed information for both approaches.\n\n```{r}\n#| echo: true\n\nBodyTemps = read.csv(\"data/BodyTemperatures.csv\")\n\nt.test(x = BodyTemps$Temperature, \n       # alternative = \"two-sided\", \n       mu = 98.6)\n```\n\n## Learning Objectives\n\n1.  Identify important descriptive statistics and visualize data from a continuous variable\n\n2.  Identify important distributions that will be used in 512/612\n\n3.  Use our previous tools in 511 to estimate a parameter and construct a confidence interval\n\n4.  Use our previous tools in 511 to conduct a hypothesis test\n\n::: lob\n5.  Define error rates and power\n:::\n\n## Outcomes of our hypothesis test\n\n![](../img_slides/Type_1_2_error.png){fig-align=\"center\"}\n\n## Prabilities of outcomes\n\n-   Type 1 error is $\\alpha$\n\n    -   The probability that we falsely reject the null hypothesis (but the null is true!!)\n\n-   Power is $1-\\beta$\n\n    -   The probability of correctly rejecting the null hypothesis\n\n![](../img_slides/Power.png){fig-align=\"center\"}\n\n## What I think is the most intuitive way to look at it\n\n![](../img_slides/type-i-and-type-ii-error.png){fig-align=\"center\"}\n\n## Do your exit ticket!!\n\n- Don't forget to go online and fill it out!\n\n  - This will count as your attendance\n  \n \n  \n- I look forward to the quarter with you!\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":"mathjax","slide-level":2,"to":"revealjs","highlight-style":"ayu","output-file":"01_Review.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.8.25","auto-stretch":true,"title":"Lesson 1: Review","author":"Nicky Wakim","title-slide-attributes":{"data-background-color":"#213c96"},"date":"`r library(here); source(here('class_dates.R')); w1d1`","theme":"../simple_NW.scss","chalkboard":true,"slideNumber":true,"showSlideNumber":"all","width":1955,"height":1100,"footer":"Lesson 1: Review"}}},"projectFormats":["html"]}